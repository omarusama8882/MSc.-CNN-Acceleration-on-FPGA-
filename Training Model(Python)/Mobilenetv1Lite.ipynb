{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense,Conv2D,MaxPool2D,Flatten,BatchNormalization,Reshape,InputLayer,GlobalAveragePooling2D,DepthwiseConv2D,Dropout,MaxPooling2D,ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='train'\n",
    "test_path='test'\n",
    "valid_path='valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"Air Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2244 images belonging to 4 classes.\n",
      "Found 120 images belonging to 4 classes.\n",
      "Found 120 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=train_path,target_size=(512,512),batch_size=32)\n",
    "valid_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=valid_path,target_size=(512,512),batch_size=4)\n",
    "test_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=test_path,target_size=(512,512),batch_size=4,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile=tf.keras.applications.mobilenet.MobileNet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet v1Lite without Bitshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(InputLayer(shape=(512, 512, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv2d is a Conv2D layer with 8 filters and (2, 2) strides and (3, 3) kernel_size\n",
      "Layer conv_dw_1 is a DepthConv2D layer with  (1, 1) strides and (3, 3) kernel size\n",
      "Layer conv2d_1 is a Conv2D layer with 16 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "1\n",
      "Layer conv_dw_2 is a DepthConv2D layer with  (2, 2) strides and (3, 3) kernel size\n",
      "Layer conv2d_2 is a Conv2D layer with 32 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "Layer conv_dw_3 is a DepthConv2D layer with  (1, 1) strides and (3, 3) kernel size\n",
      "Layer conv2d_3 is a Conv2D layer with 32 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "1\n",
      "Layer conv_dw_4 is a DepthConv2D layer with  (2, 2) strides and (3, 3) kernel size\n",
      "Layer conv2d_4 is a Conv2D layer with 64 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "Layer conv_dw_5 is a DepthConv2D layer with  (1, 1) strides and (3, 3) kernel size\n",
      "Layer conv2d_5 is a Conv2D layer with 64 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "1\n",
      "Layer conv_dw_6 is a DepthConv2D layer with  (2, 2) strides and (3, 3) kernel size\n",
      "Layer conv2d_6 is a Conv2D layer with 128 filters and (1, 1) strides and (1, 1) kernel_size\n"
     ]
    }
   ],
   "source": [
    "for layer in mobile.layers[1:43]:\n",
    "     if isinstance(layer, Conv2D):\n",
    "        \n",
    "        #print(f'Layer {layer.name} is a Conv2D layer with {layer.filters} filters')\n",
    "        newfilters=(int)(layer.filters/4)\n",
    "        newlayer=Conv2D(newfilters, layer.kernel_size, strides=layer.strides,\n",
    "                      padding=layer.padding, activation=layer.activation,\n",
    "                      use_bias=layer.use_bias, kernel_initializer=layer.kernel_initializer,\n",
    "                      bias_initializer=layer.bias_initializer)\n",
    "        model.add(newlayer)\n",
    "        print(f'Layer {newlayer.name} is a Conv2D layer with {newlayer.filters} filters and {newlayer.strides} strides and {newlayer.kernel_size} kernel_size')\n",
    "     elif isinstance(layer, BatchNormalization) :\n",
    "        model.add(BatchNormalization(axis=getattr(layer, 'axis', -1),\n",
    "    momentum=getattr(layer, 'momentum', 0.99),\n",
    "    epsilon=getattr(layer, 'epsilon', 1e-3),\n",
    "    center=getattr(layer, 'center', True),\n",
    "    scale=getattr(layer, 'scale', True),\n",
    "    beta_initializer=getattr(layer, 'beta_initializer', 'zeros'),\n",
    "    gamma_initializer=getattr(layer, 'gamma_initializer', 'ones'),\n",
    "    moving_mean_initializer=getattr(layer, 'moving_mean_initializer', 'zeros'),\n",
    "    moving_variance_initializer=getattr(layer, 'moving_variance_initializer', 'ones'),\n",
    "    beta_regularizer=getattr(layer, 'beta_regularizer', None),\n",
    "    gamma_regularizer=getattr(layer, 'gamma_regularizer', None),\n",
    "    beta_constraint=getattr(layer, 'beta_constraint', None),\n",
    "    gamma_constraint=getattr(layer, 'gamma_constraint', None)))\n",
    "     elif isinstance(layer,DepthwiseConv2D):\n",
    "         print(f'Layer {layer.name} is a DepthConv2D layer with  {layer.strides} strides and {layer.kernel_size} kernel size')\n",
    "         model.add(DepthwiseConv2D(kernel_size=getattr(layer, 'kernel_size', (3, 3)),\n",
    "    strides=getattr(layer, 'strides', (1, 1)),\n",
    "    padding=getattr(layer, 'padding', 'valid'),\n",
    "    depth_multiplier=getattr(layer, 'depth_multiplier', 1),\n",
    "    activation=getattr(layer, 'activation', None),\n",
    "    use_bias=getattr(layer, 'use_bias', True),\n",
    "    bias_initializer=getattr(layer, 'bias_initializer', 'zeros'),\n",
    "    depthwise_initializer=getattr(layer, 'depthwise_initializer', 'glorot_uniform')\n",
    "))\n",
    "     #elif(isinstance(layer,DepthwiseConv2D)):\n",
    "        #     print('hellooooooooooo')\n",
    "       #      print(f'Layer {layer.name} is a DepthConv2D layer with  {layer.strides} strides')\n",
    "             #model.add(layer)\n",
    "     elif (isinstance(layer,ZeroPadding2D)):\n",
    "         print(1)\n",
    "\n",
    "     else:\n",
    "          #print(layer.name)\n",
    "          model.add(layer)\n",
    "     \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,400</span> (79.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,400\u001b[0m (79.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,280</span> (75.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,280\u001b[0m (75.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120</span> (4.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,120\u001b[0m (4.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Layer conv_dw_12 is a DepthConv2D layer with  (2, 2) strides and (3, 3) kernel size\n",
      "Layer conv2d_7 is a Conv2D layer with 256 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "Layer conv_dw_13 is a DepthConv2D layer with  (1, 1) strides and (3, 3) kernel size\n",
      "Layer conv2d_8 is a Conv2D layer with 256 filters and (1, 1) strides and (1, 1) kernel_size\n"
     ]
    }
   ],
   "source": [
    "for layer in mobile.layers[73:86]:\n",
    "     if isinstance(layer, Conv2D):\n",
    "        \n",
    "        #print(f'Layer {layer.name} is a Conv2D layer with {layer.filters} filters')\n",
    "        newfilters=(int)(layer.filters/4)\n",
    "        newlayer=Conv2D(newfilters, layer.kernel_size, strides=layer.strides,\n",
    "                      padding=layer.padding, activation=layer.activation,\n",
    "                      use_bias=layer.use_bias, kernel_initializer=layer.kernel_initializer,\n",
    "                      bias_initializer=layer.bias_initializer)\n",
    "        model.add(newlayer)\n",
    "        print(f'Layer {newlayer.name} is a Conv2D layer with {newlayer.filters} filters and {newlayer.strides} strides and {newlayer.kernel_size} kernel_size')\n",
    "     elif isinstance(layer, BatchNormalization) :\n",
    "        model.add(BatchNormalization(axis=getattr(layer, 'axis', -1),\n",
    "    momentum=getattr(layer, 'momentum', 0.99),\n",
    "    epsilon=getattr(layer, 'epsilon', 1e-3),\n",
    "    center=getattr(layer, 'center', True),\n",
    "    scale=getattr(layer, 'scale', True),\n",
    "    beta_initializer=getattr(layer, 'beta_initializer', 'zeros'),\n",
    "    gamma_initializer=getattr(layer, 'gamma_initializer', 'ones'),\n",
    "    moving_mean_initializer=getattr(layer, 'moving_mean_initializer', 'zeros'),\n",
    "    moving_variance_initializer=getattr(layer, 'moving_variance_initializer', 'ones'),\n",
    "    beta_regularizer=getattr(layer, 'beta_regularizer', None),\n",
    "    gamma_regularizer=getattr(layer, 'gamma_regularizer', None),\n",
    "    beta_constraint=getattr(layer, 'beta_constraint', None),\n",
    "    gamma_constraint=getattr(layer, 'gamma_constraint', None)))\n",
    "     elif isinstance(layer,DepthwiseConv2D):\n",
    "         print(f'Layer {layer.name} is a DepthConv2D layer with  {layer.strides} strides and {layer.kernel_size} kernel size')\n",
    "\n",
    "         model.add(DepthwiseConv2D(kernel_size=getattr(layer, 'kernel_size', (3, 3)),\n",
    "    strides=getattr(layer, 'strides', (1, 1)),\n",
    "    padding=getattr(layer, 'padding', 'valid'),\n",
    "    depth_multiplier=getattr(layer, 'depth_multiplier', 1),\n",
    "    activation=getattr(layer, 'activation', None),\n",
    "    use_bias=getattr(layer, 'use_bias', True),\n",
    "    bias_initializer=getattr(layer, 'bias_initializer', 'zeros'),\n",
    "    depthwise_initializer=getattr(layer, 'depthwise_initializer', 'glorot_uniform')\n",
    "))\n",
    "     elif (isinstance(layer,ZeroPadding2D)):\n",
    "         print(1) \n",
    "     else:\n",
    "         model.add(layer)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GlobalAveragePooling2D(name='global_average_pooling2d'))\n",
    "model.add(Dense(units=4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m32,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m65,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,028\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,772</span> (495.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m126,772\u001b[0m (495.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,860</span> (483.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,860\u001b[0m (483.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,912</span> (11.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,912\u001b[0m (11.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=train_batches,validation_data=valid_batches,epochs=20,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Documents\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 - 253s - 4s/step - accuracy: 0.6872 - loss: 0.7596 - val_accuracy: 0.2500 - val_loss: 1.5832\n",
      "Epoch 2/20\n",
      "71/71 - 221s - 3s/step - accuracy: 0.7736 - loss: 0.5615 - val_accuracy: 0.2500 - val_loss: 2.1149\n",
      "Epoch 3/20\n",
      "71/71 - 223s - 3s/step - accuracy: 0.7981 - loss: 0.4750 - val_accuracy: 0.2500 - val_loss: 2.7135\n",
      "Epoch 4/20\n",
      "71/71 - 225s - 3s/step - accuracy: 0.8191 - loss: 0.4346 - val_accuracy: 0.2500 - val_loss: 3.4659\n",
      "Epoch 5/20\n",
      "71/71 - 219s - 3s/step - accuracy: 0.8258 - loss: 0.4037 - val_accuracy: 0.2500 - val_loss: 3.5441\n",
      "Epoch 6/20\n",
      "71/71 - 224s - 3s/step - accuracy: 0.8373 - loss: 0.3888 - val_accuracy: 0.2500 - val_loss: 3.6216\n",
      "Epoch 7/20\n",
      "71/71 - 220s - 3s/step - accuracy: 0.8454 - loss: 0.3495 - val_accuracy: 0.2917 - val_loss: 3.0772\n",
      "Epoch 8/20\n",
      "71/71 - 229s - 3s/step - accuracy: 0.8614 - loss: 0.3237 - val_accuracy: 0.6083 - val_loss: 0.9164\n",
      "Epoch 9/20\n",
      "71/71 - 207s - 3s/step - accuracy: 0.8739 - loss: 0.2971 - val_accuracy: 0.7417 - val_loss: 0.6955\n",
      "Epoch 10/20\n",
      "71/71 - 207s - 3s/step - accuracy: 0.8694 - loss: 0.3021 - val_accuracy: 0.8250 - val_loss: 0.5788\n",
      "Epoch 11/20\n",
      "71/71 - 204s - 3s/step - accuracy: 0.8926 - loss: 0.2610 - val_accuracy: 0.8750 - val_loss: 0.4609\n",
      "Epoch 12/20\n",
      "71/71 - 204s - 3s/step - accuracy: 0.8980 - loss: 0.2601 - val_accuracy: 0.8417 - val_loss: 0.4376\n",
      "Epoch 13/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9086 - loss: 0.2405 - val_accuracy: 0.8750 - val_loss: 0.3529\n",
      "Epoch 14/20\n",
      "71/71 - 204s - 3s/step - accuracy: 0.9193 - loss: 0.2231 - val_accuracy: 0.8583 - val_loss: 0.4643\n",
      "Epoch 15/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9135 - loss: 0.2303 - val_accuracy: 0.8667 - val_loss: 0.3355\n",
      "Epoch 16/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9140 - loss: 0.2391 - val_accuracy: 0.8667 - val_loss: 0.4559\n",
      "Epoch 17/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9251 - loss: 0.1934 - val_accuracy: 0.8833 - val_loss: 0.3400\n",
      "Epoch 18/20\n",
      "71/71 - 198s - 3s/step - accuracy: 0.9434 - loss: 0.1612 - val_accuracy: 0.9083 - val_loss: 0.4399\n",
      "Epoch 19/20\n",
      "71/71 - 204s - 3s/step - accuracy: 0.9452 - loss: 0.1510 - val_accuracy: 0.7333 - val_loss: 1.5938\n",
      "Epoch 20/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9510 - loss: 0.1330 - val_accuracy: 0.8917 - val_loss: 0.4912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25f8f1172f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,validation_data=valid_batches,epochs=20,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(x=test_batches,verbose=0)\n",
    "rounded_pred=np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=np.argmax(rounded_pred,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.66666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "test_labels=test_batches.classes\n",
    "\n",
    "f1_micro = f1_score(test_labels, predict,average='micro')\n",
    "f1_micro*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mobilenetv1lite\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mobilenetv1lite\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'mobilenetv1lite'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name='keras_tensor_91')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2609415171024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415172368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415171216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415172176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415172560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415174288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415174096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415175056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415174864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415173712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415176016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445913040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445912848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415175248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445912656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445914384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445913616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445915536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445915344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445913424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445914960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445917072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445915728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445916880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445916688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445918416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445919952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445918800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445920144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445919760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445923408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445925136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445924368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445925328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445924176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446781392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446783120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446782736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446783312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446782928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446785616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446787152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446785808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446788112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446788880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415171408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446788496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446789840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446783696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446789072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446790800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446790032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446792912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446791952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446790608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446792336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446793104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446787344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446794448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446793872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446785424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446796752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446796176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446794256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446794832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454481872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454481488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454482832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446795792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454481680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454483408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454482448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454484560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454482256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454483024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454483984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454486288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454484752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454486096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454485520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454486672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454487824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export('mobilenetv1lite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mobilenetv1lite.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet v1 Lite with bitshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "mobilenetv1lite=load_model('mobilenetv1lite.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16436005, -0.15154105, -0.18714835,  0.06735396],\n",
       "       [ 0.02512901, -0.07903466,  0.08077965, -0.1139873 ],\n",
       "       [ 0.15105017,  0.03615137,  0.06673397, -0.05782771],\n",
       "       ...,\n",
       "       [ 0.09227933,  0.06480524,  0.16097234, -0.02970978],\n",
       "       [ 0.07203227, -0.0595542 , -0.03374214, -0.13438588],\n",
       "       [ 0.1369904 ,  0.12464586, -0.1388945 , -0.16122779]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_weights=mobilenetv1lite.layers[-1].get_weights()[0]\n",
    "dense_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantizeweights(weights):\n",
    "    #weights=weights.numpy()\n",
    "    weights_absolute=tf.abs(weights)\n",
    "    maxweight=tf.reduce_max(weights_absolute)\n",
    "    #print(maxweight)\n",
    "    scaled_weights=weights/maxweight\n",
    "    #print(scaled_weights)\n",
    "    lq=LQ(scaled_weights,16)\n",
    "    #print(f'aloha {lq}')\n",
    "    return lq\n",
    "def LQ(tensor, bitwidth):\n",
    "    # Create a mask for weights equal to 0\n",
    "    #rounded_tensor=tf.where(tensor>0,tf.my u4xdcvp]\n",
    "    # [6ath.floor(tensor),tf.math.ceil(tensor))\n",
    "    rounded_weights=tensor*100\n",
    "    rounded_weights=tf.where(rounded_weights>0,tf.math.floor(rounded_weights),tf.math.ceil(rounded_weights))\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    # Compute weight_log using log2\n",
    "    weight_log = tf.math.log(tf.math.abs(tensor)+epsilon) / tf.math.log(2.0)\n",
    "    #print(weight_log)\n",
    "    weight_log=tf.where(weight_log<0,tf.math.ceil(weight_log),tf.math.floor(weight_log))\n",
    "    bit_pot = -2 ** bitwidth\n",
    "    mask_condition = weight_log >= bit_pot\n",
    "    \n",
    "    # Initialize the result tensor with zeros\n",
    "    result = tf.zeros_like(tensor, dtype=tf.float32)\n",
    "    \n",
    "    # Apply the condition where weight_log is valid\n",
    "    result = tf.where(rounded_weights!=0,tf.where(mask_condition, tf.where(tensor > 0, tf.math.abs(weight_log), weight_log), result),result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_dense_weights=Quantizeweights(dense_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -0., -0.,  2.],\n",
       "       [ 3., -1.,  1., -1.],\n",
       "       [ 0.,  3.,  2., -2.],\n",
       "       ...,\n",
       "       [ 1.,  2.,  0., -3.],\n",
       "       [ 2., -2., -3., -1.],\n",
       "       [ 1.,  1., -1., -0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_dense_weights=quantized_dense_weights.numpy()\n",
    "quantized_dense_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  2],\n",
       "       [ 3, -1,  1, -1],\n",
       "       [ 0,  3,  2, -2],\n",
       "       ...,\n",
       "       [ 1,  2,  0, -3],\n",
       "       [ 2, -2, -3, -1],\n",
       "       [ 1,  1, -1,  0]], dtype=int16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qds_int=quantized_dense_weights.astype(np.int16)\n",
    "qds_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3,  0, ...,  1,  2,  1],\n",
       "       [ 0, -1,  3, ...,  2, -2,  1],\n",
       "       [ 0,  1,  2, ...,  0, -3, -1],\n",
       "       [ 2, -1, -2, ..., -3, -1,  0]], dtype=int16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_dense_weights_transp=np.transpose(qds_int)\n",
    "quantized_dense_weights_transp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  0, ..., -3, -1,  0], dtype=int16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_dense=quantized_dense_weights_transp.flatten()\n",
    "flattened_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0x3'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(flattened_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_twos_complement_hex(x, bit_width=4):\n",
    "    if x >= 0:\n",
    "        return format(x, 'x')  # Hexadecimal without '0x' prefix\n",
    "    else:\n",
    "        return format((1 << bit_width) + x, 'x')  # Two's complement hex without '0x' prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_twos_complement_hex(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '3', '0', ..., 'd', 'f', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_hex=np.vectorize(int_to_twos_complement_hex)\n",
    "hex_dense=v_hex(flattened_dense)\n",
    "hex_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dense_weights.txt', 'w') as cf:\n",
    "\n",
    " \n",
    " np.savetxt(cf,hex_dense,delimiter=\" \",fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"weights.txt\", qds_int, delimiter=\" \", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00117536,  0.00042983,  0.00199678,  0.00135183], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_bias=mobilenetv1lite.layers[-1].get_weights()[1]\n",
    "dense_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float32_to_fixed16(value, fractional_bits=8):\n",
    "    # Scale by 2^fractional_bits\n",
    "    scaled_value = value * (2 ** fractional_bits)\n",
    "    \n",
    "    # Round to the nearest integer\n",
    "    fixed_value = np.round(scaled_value).astype(np.int16)\n",
    "    \n",
    "    # Handle overflow (for 16-bit signed integers)\n",
    "    #max_val = 2**15 - 1\n",
    "    #min_val = -2**15\n",
    "    #fixed_value = np.clip(fixed_value, min_val, max_val)\n",
    "    \n",
    "    return fixed_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftf=np.vectorize(float32_to_fixed16)\n",
    "\n",
    "#np.savetxt(\"weights.txt\", d_bias, delimiter=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0], dtype=int16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_dense_bias=ftf(dense_bias)\n",
    "fixed_dense_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '1', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_bias=v_hex(fixed_dense_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(mobilenetv1lite.layers):\n",
    "    if isinstance(layer,Conv2D):\n",
    "        if layer.use_bias==True:\n",
    "            print(i)\n",
    "            x=np.array(layer.get_weights())\n",
    "            y=ftf(x)\n",
    "            print(x.shape)\n",
    "            print(f'weights {y}')\n",
    "        \n",
    "            #print(f'biases {layer.get_weights()[1]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hayhay\n",
      "(1, 3, 3, 8, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 16, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 32, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 32, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 64, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 64, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 128, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(mobilenetv1lite.layers):\n",
    "    if isinstance(layer,DepthwiseConv2D):\n",
    "        if layer.use_bias==False:\n",
    "            print('hayhay')\n",
    "            x=np.array(layer.get_weights())\n",
    "            #y=ftf(x)\n",
    "            print(x.shape)\n",
    "        else:\n",
    "           print('hoyhoy')\n",
    "           x=np.array(layer.get_weights()[0])\n",
    "           y=np.array(layer.get_weights()[1])\n",
    "           print(x.shape)\n",
    "           print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            #print(f'weights {y}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.39815469, 0.99627766, 0.41200907],\n",
       "         [0.38045931, 0.84076123, 0.54737021],\n",
       "         [0.88087134, 0.39220301, 0.02442792]],\n",
       "\n",
       "        [[0.44587056, 0.26718626, 0.40811024],\n",
       "         [0.43431054, 0.52770571, 0.8402363 ],\n",
       "         [0.793959  , 0.45506952, 0.1813199 ]],\n",
       "\n",
       "        [[0.43665474, 0.74319419, 0.52152409],\n",
       "         [0.20976816, 0.51436807, 0.06489828],\n",
       "         [0.01785718, 0.90446216, 0.30138552]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_5d = np.random.rand(1, 3, 3, 3, 8)\n",
    "#print(array_5d)\n",
    "array_5d[:,:,:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1360771 , 0.91484703, 0.68370063],\n",
       "       [0.99255511, 0.09345574, 0.90563285],\n",
       "       [0.83811493, 0.54655643, 0.33519357]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=array_5d[:,:,:,1,0]\n",
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dw2d_weights.txt', 'w') as cf:\n",
    "\n",
    "          for i in range(0,array_5d.shape[3]):\n",
    "            weights=array_5d[:,:,:,i,0]\n",
    "            weights=np.array(weights)\n",
    "            np.savetxt(cf,weights[0],delimiter=\" \",fmt=\"%d\")\n",
    "            cf.write(\"\\n...\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conv2d_weights.txt', 'w') as cf:\n",
    "        for i, layer in enumerate(mobilenetv1lite.layers):\n",
    "                if isinstance(layer,Conv2D):\n",
    "                     if layer.use_bias==False:\n",
    "                            weights=np.array(layer.get_weights())\n",
    "                            fixed_weights=ftf(weights)\n",
    "                            cf.write(f'{fixed_weights.shape}\\n')\n",
    "                            for j in range(fixed_weights.shape[4]):\n",
    "                                    kernel=fixed_weights[:,:,:,:,j]\n",
    "                                    for j in range(0,fixed_weights.shape[1]):\n",
    "                                           \n",
    "                                           np.savetxt(cf,kernel[0][j],delimiter=\" \",fmt=\"%d\")\n",
    "                                    cf.write('\\n')\n",
    "\n",
    "                     #else:\n",
    "                      #      weights=np.array(layer.get_weights()[0])\n",
    "                       #     fixed_weights=ftf(weights)\n",
    "                        #    cf.write(f'{fixed_weights.shape}\\n')\n",
    "                         #   np.savetxt(cf,fixed_weights,delimiter=\" \", fmt=\"%d\")\n",
    "                          #  cf.write('\\n')\n",
    "                           # biases=np.array(layer.get_weights()[1])\n",
    "                            #fixed_biases=ftf(biases)\n",
    "                            #cf.write(f'{fixed_biases.shape}\\n')\n",
    "                            #np.savetxt(cf,fixed_biases,delimiter=\" \", fmt=\"%d\")\n",
    "                            #cf.write('\\n---\\n')\n",
    "                            \n",
    "\n",
    "                \n",
    "                            \n",
    "                     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dw2d_weights.txt', 'w') as cf:\n",
    "        for i, layer in enumerate(mobilenetv1lite.layers):\n",
    "                if isinstance(layer,DepthwiseConv2D):\n",
    "                     if layer.use_bias==False:\n",
    "                            weights=np.array(layer.get_weights())\n",
    "                            fixed_weights=ftf(weights)\n",
    "                            cf.write(f'{fixed_weights.shape}\\n')\n",
    "                            for j in range(fixed_weights.shape[3]):\n",
    "                                    kernel=fixed_weights[:,:,:,j,0]\n",
    "                                    np.savetxt(cf,kernel[0],delimiter=\" \",fmt=\"%d\")\n",
    "                                    cf.write('\\n')\n",
    "                                                                              \n",
    "                            \n",
    "                            cf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dense_biases.txt', 'w') as cf:\n",
    "\n",
    " dense=mobilenetv1lite.layers[-1]\n",
    " dense_b=dense.get_weights()[1]\n",
    " fixed_point_densebiases=ftf(dense_b)\n",
    " np.savetxt(cf,[fixed_point_densebiases],delimiter=\" \",fmt=\"%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30017743 -0.07419148 -0.12466044 -0.16404085  0.03540794  0.24495433\n",
      "  0.09390425 -0.13774894]\n",
      "[-0.05117462 -0.20044915  0.02539817  0.36294523 -0.0873023   0.03801572\n",
      "  0.0479954  -0.2717524 ]\n",
      "[-0.58021164  0.10887035 -0.00626114  0.46409115 -0.08151932  0.18620881\n",
      " -0.05388211 -0.10900676  0.44094712  0.08115771  0.1044884   0.14494568\n",
      " -0.21114637  0.00183912 -0.45172057  0.02931757]\n",
      "[ 0.10072251 -0.14052176 -0.07808677 -0.12543939  0.01262873  0.05178702\n",
      " -0.12910813 -0.01373703  0.04184426 -0.19069828 -0.00048058 -0.09237207\n",
      " -0.06227134  0.02621358 -0.04345289  0.08637138]\n",
      "[ 0.16703653  0.37071347 -0.05185276  0.48349205  0.12315077  0.07526929\n",
      "  0.22730863  0.30420977 -0.36659884 -0.16548339 -0.00828904 -0.36348572\n",
      " -0.03768082 -0.25161058 -0.0673038  -0.04230739 -0.01397542 -0.24639243\n",
      "  0.10068566  0.15941383 -0.46944237 -0.38656363  0.13028717  0.14700721\n",
      " -0.3796412   0.34703764 -0.35440978 -0.1810673   0.449561   -0.349696\n",
      "  0.16271049 -0.0241196 ]\n",
      "[ 0.08210108  0.15252136  0.00233321 -0.04675012  0.0117612   0.06707238\n",
      " -0.03165183  0.15189488 -0.08525196  0.03875782  0.01251149  0.00502075\n",
      " -0.11176032 -0.04280929  0.01372422 -0.08366927  0.00594394 -0.11563594\n",
      "  0.07479922 -0.00754237 -0.10532056  0.12939906  0.08136427  0.00184996\n",
      "  0.11197607 -0.09237935 -0.05686245 -0.05482236  0.00669577  0.04745905\n",
      "  0.02897377 -0.00891171]\n",
      "[-0.34339693  0.16130613  0.18807447 -0.92861    -0.18858917 -0.39643088\n",
      "  0.16331132  0.44475535  0.0969381  -0.56334    -0.14630158 -0.5817085\n",
      " -0.568904    0.6300455  -0.00984974  0.15417133 -0.02171405  0.33730388\n",
      " -0.6490277   0.8428876  -0.11055563  0.13336763  0.23818125  0.39192694\n",
      "  0.13379358 -0.62703824  0.18758291 -0.04347831 -0.44501823  0.24338554\n",
      " -0.5190596   0.21498401]\n",
      "[-0.00452442 -0.09683958 -0.00907562 -0.01296066  0.09352569 -0.11254123\n",
      " -0.20541182  0.05206046  0.1479238  -0.15171419  0.02008653 -0.14534777\n",
      " -0.08188793 -0.02522107  0.06365797 -0.05342189 -0.01705026  0.07663842\n",
      "  0.16202177  0.0731473   0.17301704 -0.01415864  0.23006238  0.01966347\n",
      "  0.08228753 -0.06322277  0.10160375 -0.06306987 -0.15908493  0.10000193\n",
      " -0.0054898  -0.09027471]\n",
      "[-0.26174128 -0.02526953  0.36440024  0.02064003  0.52958447  0.20765525\n",
      " -0.6706679  -0.21367048 -0.32364592  0.11126004  0.00699001  0.42997196\n",
      " -0.07310937 -0.03403329 -0.38849738  0.05415591  0.4918583  -0.05640657\n",
      "  0.37222078 -0.4068936  -0.05851604  0.41786504 -0.2981767  -0.26826447\n",
      " -0.8725531  -0.35836875  0.20492315  0.20106453 -0.3184752   0.24827558\n",
      "  0.01175198 -0.15026522 -0.27193978 -0.00938667 -0.08026636 -0.09247857\n",
      "  0.36569566  0.07550099  0.26474932  0.14657149  0.23507792 -0.6199472\n",
      "  0.43117526 -0.34847453  0.14995126 -0.1871231  -0.17871885  0.5019733\n",
      " -0.07423155 -0.00827593  0.2882925   0.33440843  0.07426792  0.01651267\n",
      "  0.23963651  0.30348405 -0.50521547  0.14056084  0.36895666 -0.16168635\n",
      " -0.5160985   0.07062187  0.35881102  0.07563559]\n",
      "[ 0.0243655  -0.06558946  0.19158204 -0.03158131 -0.02429325 -0.14722577\n",
      "  0.02343906 -0.12354574 -0.10340873  0.04201813  0.08646958 -0.00599259\n",
      "  0.06475174 -0.1805747  -0.17493469  0.03105222  0.01701192 -0.06166711\n",
      " -0.00641801 -0.20857789  0.18776871 -0.18503575  0.05831954 -0.00800573\n",
      "  0.00037474 -0.14372355  0.02099492  0.19770198 -0.14475605 -0.10320719\n",
      "  0.08343876 -0.03115114 -0.09451536  0.02413557  0.02265813 -0.07004268\n",
      "  0.0728737   0.01151167 -0.07314925 -0.16782224  0.06422924  0.04852194\n",
      "  0.04145437 -0.12982926 -0.18483268  0.05452086  0.04327968  0.06573125\n",
      " -0.0459145  -0.0274199   0.03773735  0.01317941 -0.05106702  0.0904423\n",
      " -0.11173081  0.09882923 -0.14923777  0.02355027 -0.08673234  0.12718785\n",
      " -0.04518109  0.1279319  -0.10528403 -0.02147698]\n",
      "[-0.38873684  0.4394208  -0.6458818  -0.88347834  0.31063613 -0.26397714\n",
      "  0.3015278   0.28300744  0.03780156 -0.02191983  0.39354762  0.6028587\n",
      " -0.57936645 -0.24064066  0.14639063 -0.12107818 -0.10824255  0.28314707\n",
      " -0.2834555   0.15768947  0.9082094  -0.02373843 -0.12439798 -0.3505597\n",
      " -0.2983267   0.2275207   0.04424917 -0.5144582   0.50871366 -0.26805174\n",
      "  0.3619314  -0.20267099 -0.3480873   0.5995223  -0.44464105 -0.80658\n",
      "  0.02852754  0.7036901  -0.2745198  -0.03086984 -0.18341367 -0.5543365\n",
      " -0.11403664 -0.4918146  -0.37555712 -0.41052005  0.04135101 -0.85974455\n",
      "  0.01541131  0.00185972 -0.00518029  0.20062847 -0.85107523 -0.81512386\n",
      "  0.28631324  0.17769879  0.34965685  0.04398832 -0.39030913  0.02631313\n",
      "  0.49469793 -0.26605698  0.84889495 -0.10464476]\n",
      "[ 0.04326215 -0.12627606  0.06239926  0.11046307  0.14401753  0.04149935\n",
      "  0.18758164  0.00842235  0.18703595  0.22644183  0.00639434 -0.2519448\n",
      "  0.08194087  0.13510054  0.05945808 -0.04199941  0.02108022  0.13828182\n",
      "  0.16217066 -0.09257396  0.11903935 -0.05588331 -0.01627536 -0.00814987\n",
      "  0.05081774 -0.04507545 -0.21657777  0.00756694  0.10348456  0.01180359\n",
      "  0.11508    -0.11925776  0.02024044  0.1717846   0.05160248 -0.12603317\n",
      " -0.03764094 -0.19740903  0.03382471 -0.12245004 -0.03743177 -0.06549063\n",
      "  0.01988045 -0.1934985   0.14456649 -0.00066519 -0.0332706   0.02814678\n",
      " -0.00908608 -0.10382611  0.1263737   0.06307033  0.16052917 -0.05543484\n",
      " -0.08391696 -0.10030673  0.09909481  0.0785798   0.14135003  0.10311401\n",
      "  0.06819598 -0.16464852  0.11581253 -0.16787001]\n",
      "[ 0.1791695   0.56307703  0.12419457  0.3780538   0.24082153 -0.32229525\n",
      " -0.08349143  0.05625884  0.05025052  0.6726436   0.01117595 -0.12842079\n",
      "  0.05038267 -0.5061257   0.0772571   0.01051228 -0.13451299 -0.13436916\n",
      " -0.12265949 -0.20868865  0.31303963 -0.4758471  -0.60705984 -0.02459758\n",
      " -0.00362835 -0.1855927   0.2994921  -0.09237022  0.34277025 -0.11613929\n",
      " -0.96567667 -0.21981207 -0.14725374  0.48486415  0.38330626 -0.1910517\n",
      " -0.15894808  0.2726792  -0.04226288 -0.17570177  0.05922987 -0.15840048\n",
      "  0.20056573  0.05268034 -0.58211106 -0.3395649  -0.64884263  0.70113736\n",
      " -0.04733588  0.05894262  0.24129868 -0.16454828 -0.17684889 -0.35994735\n",
      " -0.12312289 -0.05400075 -0.07505701 -0.141424    0.28746957 -0.26974785\n",
      "  0.20738511  0.07380307  0.14349611 -0.765031    0.85487324  0.2948086\n",
      " -0.54024476  0.44901952  0.64948505  0.23903987 -0.02701015  0.45885107\n",
      "  0.23878583  0.09390131  0.0274277  -0.29753238 -0.0762137   0.56224346\n",
      " -0.28043047 -0.558713    0.08231368  0.26799026  0.75039876 -0.5574067\n",
      " -0.2764614   0.2723017   0.37796217  0.12628019  0.07767298  0.18271519\n",
      " -0.16900262 -0.56951034 -0.17503686  0.22338735 -0.3360709   0.06346149\n",
      " -0.3411336  -0.22232358 -0.03173967  0.1234773  -0.5539382  -0.2210937\n",
      "  0.20028172  0.38479275  0.09084439  0.49138966  0.05968196  0.08709799\n",
      "  0.09332892 -0.24274883  0.08419412 -0.09554121  0.3978289   0.34768787\n",
      " -0.07064848 -0.19354084  0.09936659 -0.5227965   0.10098591  0.53780556\n",
      " -0.1101594   0.21572538 -0.19575626  0.02463999 -0.26544014 -0.5030105\n",
      " -0.46794933  0.12496702]\n",
      "[-0.0217574  -0.06177149  0.01190849 -0.15368564 -0.1345233  -0.01920828\n",
      "  0.02366169 -0.09629142  0.09242834  0.10013175 -0.01177661  0.05566107\n",
      "  0.11557236  0.09642349 -0.04812698 -0.03754763 -0.02754548 -0.015994\n",
      " -0.03886288  0.11177966  0.04050105  0.02203705 -0.12244409  0.03884005\n",
      " -0.05815673 -0.11714724 -0.04126263  0.02050621 -0.1294572   0.08027182\n",
      "  0.00274177 -0.10151692 -0.13107961 -0.13682781 -0.0515158   0.01490045\n",
      "  0.03266224  0.00053816  0.16179912 -0.01590422  0.08038978  0.0925859\n",
      " -0.00238996  0.1776157   0.10211454 -0.13700512  0.09915839 -0.0158951\n",
      "  0.10220834 -0.01926705 -0.1080143   0.04932152  0.15873414 -0.05336499\n",
      " -0.01234096 -0.01973508 -0.05332268 -0.14527862  0.15275764 -0.07574422\n",
      "  0.03920333 -0.12943055 -0.01914752  0.11854126  0.11034109 -0.02899246\n",
      " -0.13509814 -0.03169928 -0.02023353 -0.12540537  0.06174858 -0.02770759\n",
      "  0.10180309 -0.09169773  0.1067242   0.01383663 -0.00222625  0.08941539\n",
      "  0.11848253  0.11734318 -0.05754781  0.10050186 -0.04333028  0.14984766\n",
      "  0.00241959 -0.03920316  0.0034046  -0.00575054  0.00256341  0.14557925\n",
      " -0.07555422  0.0493023   0.01234131 -0.0288486   0.02297287  0.0655938\n",
      "  0.12913886  0.0515673  -0.01188851 -0.20880277 -0.12568592 -0.00262374\n",
      "  0.09420748 -0.00021481  0.07265741  0.05136555  0.10577472 -0.11809359\n",
      "  0.00585782 -0.110254   -0.05542676  0.01370553 -0.03581963  0.07633844\n",
      " -0.11366858  0.09200453 -0.13734955  0.08665963 -0.09481384 -0.12207682\n",
      "  0.06594795  0.01291922 -0.02415874  0.04429091  0.01310848 -0.11970691\n",
      "  0.0126382  -0.04123973]\n",
      "[ 0.12016254  0.03660377  0.58313763  0.61746705 -0.5395796   0.27184996\n",
      " -0.48577303 -0.03345259  0.3784994  -0.7549385  -0.42524028 -0.5216678\n",
      "  1.078413   -0.46995047  1.1481899  -0.07544634  1.1034168  -0.13350816\n",
      "  0.1658389   0.54380345 -0.04112409  0.8879497   0.07642285 -0.30215105\n",
      "  0.0359855  -0.01743092 -0.35963413 -0.10907961 -0.37010103  0.09606271\n",
      " -0.34246862 -0.417087    0.18435375  0.2798914   0.07724595 -0.40320334\n",
      "  0.53373873 -0.22472636  0.45445687 -0.43695146 -0.19721298 -0.33348146\n",
      "  0.27285847  0.3198583   0.19725916  0.3557144   0.4048648   0.4335936\n",
      "  0.01103397  0.5030056   0.5984767   0.47911623  0.9779422   0.44022146\n",
      " -0.3427199   0.52459455  0.27325648  0.14543547 -0.21348803 -0.07315558\n",
      " -0.21235567  0.06386169 -0.08302705  0.15577258 -0.52590823  0.34730628\n",
      " -0.10361509  0.86522615 -0.24963549  0.45634905 -0.17259823 -0.41998327\n",
      "  0.43297598 -0.30032894 -0.38711897  1.0766456   0.17433357 -0.22141784\n",
      " -0.22587278  0.03520402  0.6344657   0.6211131  -0.01500006 -0.75003797\n",
      "  0.2598254   0.10550722  0.37631863  0.162305    0.32009515 -0.02742719\n",
      "  0.6458032   0.63283503 -0.08311553  0.12084857  0.03231932  0.16740985\n",
      " -0.15991305 -0.62500197  0.30559057 -0.62369967 -0.05152529  0.7247729\n",
      "  0.0872901  -0.34118485  0.7881053   0.12122391  0.66269404  0.42973435\n",
      "  0.20351978  0.05959838  0.16828957  0.5533529  -0.17575392  0.16505484\n",
      "  0.36813536  0.49758536  0.19131456 -0.15905462 -0.32527503 -0.33391544\n",
      "  0.07387092 -0.34019384 -0.15762554 -0.63227075 -0.3082421  -0.16204923\n",
      "  0.84313893 -0.04271345  0.53613675  0.20692626  0.7628437  -0.45225403\n",
      " -0.34499946  0.15161502  0.22620533  0.24087946  0.5037425  -0.03476657\n",
      " -0.71789867 -0.636247    0.52121484 -0.18770115  0.32491207  0.46426666\n",
      " -0.09356051  0.8372911   0.50249326  0.2085461   0.46520704 -0.04253866\n",
      " -0.3021718   0.4151011  -0.12216034 -0.15246932  0.35003677 -0.0381197\n",
      "  0.01570956  0.8585646  -0.14300457 -0.5132385   0.02893365  0.8006064\n",
      "  0.6274302   0.30505925  0.06690565 -0.5576129   0.0212016   0.42551908\n",
      "  0.4509303  -0.01538551 -0.24429722  0.41953996 -0.44458666  0.23188941\n",
      "  0.19815391  0.43876615  0.11636038 -0.20512803  0.19401984 -0.18909806\n",
      " -0.05816938  0.39715746 -0.33823845 -0.44648337  0.59281176 -0.05759626\n",
      " -0.37885457  0.3277146  -0.15339455 -0.6822567  -0.02113697  0.05476957\n",
      " -0.11024235 -0.1777822   0.14141315  0.32676506  0.08805478  0.20893459\n",
      "  0.31596917  0.12688422  0.3286251   0.37332326  0.22360897  0.49675548\n",
      "  0.77378637 -0.1596302  -0.13558349  0.09226493  0.6857207   0.60741496\n",
      "  0.5570093  -0.13121958 -0.16840959  0.2078678  -0.1677254   0.32871592\n",
      " -0.43283048 -0.22772653  0.2173157   0.38545278  0.8669443   0.42821476\n",
      " -0.19694684  0.322183   -0.04913308  0.08851999 -0.04946729 -0.52161443\n",
      " -0.11737618  0.7059701   0.12740213 -0.0430683  -0.26899967  0.09905067\n",
      "  0.4641803  -0.49916708 -0.47531077  0.26137754 -0.09697362  0.25220078\n",
      " -0.19665442 -0.48981512  0.36890608  0.78430533  0.10980105 -0.28753275\n",
      "  0.15905212 -0.9166805  -0.1972601   0.40366593 -0.6365337   0.24552739\n",
      " -0.23487492 -0.09724812  0.26550293  0.3570686 ]\n",
      "[-1.15278274e-01 -3.31712863e-03  1.33980042e-03 -1.44809792e-02\n",
      "  3.29009108e-02 -5.19311540e-02 -1.91241577e-02 -3.75651456e-02\n",
      " -1.45516032e-02 -1.81644276e-01 -3.15467245e-03  5.80593534e-02\n",
      " -1.02086850e-02  1.08030234e-02  1.11472964e-01  1.16970442e-01\n",
      " -3.02441977e-02 -4.11291514e-03 -4.71958844e-03 -1.96924550e-03\n",
      "  1.94976721e-02  1.86901027e-03 -1.14600800e-01  6.64136093e-03\n",
      " -1.90215046e-03 -1.02137022e-01  7.88676441e-02  1.36531278e-01\n",
      " -2.45414712e-02 -3.83615494e-02  1.28723845e-01  7.97887594e-02\n",
      "  1.04723191e-02 -4.40095970e-03 -2.75299754e-02 -1.18154243e-01\n",
      " -2.65908223e-02 -1.59998890e-02  8.97734314e-02 -3.40194665e-02\n",
      "  1.40041243e-02 -1.05861686e-01 -1.33551303e-02 -4.82207863e-03\n",
      " -1.64029360e-01 -4.19467725e-02 -1.50559319e-03  1.08758785e-01\n",
      " -1.25631141e-02  1.65103599e-02  8.53055865e-02 -3.74351032e-02\n",
      " -7.44265616e-02 -1.07300803e-01 -6.08502924e-02 -1.05683684e-01\n",
      " -1.12466745e-01 -1.98353957e-02  1.64238334e-01 -6.69264272e-02\n",
      "  8.07032734e-02 -3.52622867e-02  1.00036405e-01 -5.65270800e-03\n",
      " -4.01007123e-02 -1.31471106e-03 -5.77165782e-02  9.16285738e-02\n",
      "  9.93955731e-02 -3.81760597e-02 -1.02482885e-01  5.41826487e-02\n",
      "  4.22621407e-02 -4.31128452e-03 -1.29082084e-01  2.84170527e-02\n",
      " -1.46349659e-02 -1.20672518e-02  7.98301771e-02 -2.06824038e-02\n",
      "  4.68794908e-03 -1.67125594e-02 -1.43593118e-01  4.64453548e-02\n",
      " -3.57856564e-02 -3.44594866e-02 -1.47721777e-02 -7.53314123e-02\n",
      " -1.76202022e-02  2.85890196e-02 -1.68757252e-02 -5.15555218e-02\n",
      "  8.70842561e-02  5.58791636e-03  4.34193062e-04 -2.96423212e-02\n",
      " -3.24093737e-02 -8.02845042e-03  4.76281866e-02 -1.66016817e-02\n",
      " -2.71929149e-02 -5.47819119e-03  6.72349036e-02  1.21704504e-01\n",
      " -1.96628738e-02 -2.71069119e-03  8.58421847e-02  2.00467873e-02\n",
      "  9.16622952e-02 -3.23986523e-02  6.77894428e-02  1.05663724e-01\n",
      "  1.51202023e-01 -2.33009178e-02  1.25692189e-01  1.04839534e-01\n",
      " -6.91840611e-03 -3.55599984e-03  7.64966160e-02  2.02209898e-03\n",
      " -7.29219615e-02  1.29010707e-01 -6.13995967e-03  1.00384258e-01\n",
      "  4.98987781e-03  4.73020300e-02 -6.50116894e-03 -6.62679132e-03\n",
      " -1.59253478e-02  4.19355296e-02  8.80969018e-02 -2.10209880e-02\n",
      "  7.53534306e-03 -2.13455353e-02 -3.12072206e-02 -2.42688339e-02\n",
      "  1.28094642e-03  1.63570549e-02  1.26775265e-01 -5.82653098e-04\n",
      "  9.58513319e-02  2.84601040e-02 -2.09007058e-02 -1.21897899e-01\n",
      " -3.37529392e-03 -1.36895673e-02  3.15618142e-02 -2.11799070e-02\n",
      " -2.67415456e-02 -1.61447525e-02 -6.28457591e-02 -2.42713280e-02\n",
      "  4.71176952e-02 -1.13328593e-03 -5.51122800e-03 -2.69157905e-02\n",
      " -3.99689190e-03  7.06981048e-02 -2.58335052e-03 -4.26744074e-02\n",
      " -1.20970957e-01  1.34656295e-01 -1.68865523e-03  7.99543560e-02\n",
      "  2.24960932e-05 -6.03363989e-03 -3.00122052e-02 -9.32939574e-02\n",
      "  5.32973036e-02 -7.82187134e-02 -1.93283074e-02 -2.45108008e-02\n",
      "  1.85766048e-03 -7.23355170e-03 -3.75780836e-03 -1.01508610e-02\n",
      " -7.81928301e-02  1.54591963e-01 -2.77099069e-02 -1.96591076e-02\n",
      " -3.30602452e-02 -2.72666477e-02  1.11612000e-01 -2.37402320e-02\n",
      " -2.19021048e-02  7.23622069e-02  8.04860294e-02 -1.42094478e-01\n",
      " -1.46476636e-02 -1.04977302e-02 -2.06815656e-02 -4.36207280e-03\n",
      "  3.39453220e-02 -2.16782875e-02 -2.33640615e-03  9.30589885e-02\n",
      "  9.19843372e-03 -1.66287497e-02  9.36490223e-02  1.12190202e-01\n",
      " -2.12513246e-02 -2.75495388e-02  7.58884661e-03  1.20706027e-02\n",
      "  6.05385285e-03 -5.49137918e-03 -1.91942230e-02 -7.63320103e-02\n",
      " -1.04547277e-01  1.81044042e-02 -7.40188211e-02  6.59358799e-02\n",
      "  3.43563482e-02  1.21380733e-02 -6.69836327e-02 -1.08503764e-02\n",
      " -1.01671396e-02 -1.61258690e-02 -1.41031832e-01 -1.09239288e-01\n",
      "  1.49766766e-02 -3.82122844e-02 -9.69072431e-03 -1.02317750e-01\n",
      "  4.48223799e-02 -6.70139864e-03  8.11141878e-02  1.50905907e-01\n",
      " -2.42023915e-02  1.60037223e-02 -1.04173541e-01 -4.74029295e-02\n",
      " -2.24404167e-02  9.98830199e-02 -4.20161001e-02 -3.70907821e-02\n",
      " -1.45532209e-02 -2.16541649e-03 -6.54431386e-03 -7.44622201e-03\n",
      "  8.52971077e-02  3.60914059e-02 -1.76822748e-02  2.09571589e-02\n",
      " -1.28405988e-01  4.01352299e-03  1.38944956e-02 -3.76086272e-02\n",
      "  7.78606087e-02 -1.58157069e-02  1.05944186e-01 -2.95954663e-02\n",
      "  6.10196544e-03 -1.25616163e-01 -3.61322612e-02  1.18359588e-01]\n",
      "[ 5.09235978e-01  1.98176205e-01  4.27510619e-01 -3.00869137e-01\n",
      " -3.09816688e-01 -5.26503980e-01  6.26448333e-01  5.55133462e-01\n",
      "  5.96499503e-01  1.50759950e-01  6.54400945e-01 -9.20767412e-02\n",
      "  6.75974861e-02  8.44622910e-01  7.20938087e-01  6.07887246e-02\n",
      "  7.42222548e-01  9.16973233e-01  5.86905241e-01  5.43371737e-01\n",
      " -5.45422034e-03 -4.29723114e-01  1.58955425e-01  1.03043830e+00\n",
      "  5.37394956e-02  3.68557274e-01 -3.46168458e-01  1.05890691e+00\n",
      " -2.55365193e-01  8.14685047e-01  2.51904309e-01  5.32126546e-01\n",
      "  3.62028539e-01 -1.95414081e-01 -3.84175420e-01 -2.47774214e-01\n",
      " -1.14994988e-01  2.23049354e-02  2.10092351e-01  2.91615576e-01\n",
      " -5.28698266e-01  6.30088389e-01 -7.87013024e-02  1.01440918e+00\n",
      " -1.52348444e-01  8.13683122e-02 -3.52839321e-01 -6.91916347e-02\n",
      "  5.35967052e-01 -7.08452016e-02  6.08940244e-01  3.60007823e-01\n",
      "  2.74319470e-01  3.56893420e-01  1.10232317e+00  2.90480535e-02\n",
      " -2.47423515e-01 -1.26361117e-01  2.97112852e-01  2.84255832e-01\n",
      "  5.65642774e-01  2.86224604e-01 -5.92657268e-01  9.44134533e-01\n",
      "  4.98353869e-01 -5.60249239e-02 -3.93831640e-01  5.26795924e-01\n",
      "  4.53159899e-01  6.31764829e-01  1.10585856e+00 -4.72635329e-01\n",
      "  9.71309662e-01  1.19478464e+00 -5.92548735e-02  5.49081802e-01\n",
      " -3.33334655e-01  1.50392726e-01 -8.56950819e-01  4.33310181e-01\n",
      "  3.62852126e-01  4.24959689e-01  7.10890293e-01  2.17532776e-02\n",
      "  5.52195944e-02 -2.20796004e-01 -2.34004222e-02  3.06261808e-01\n",
      " -5.09362102e-01 -6.35815382e-01  2.05410659e-01  9.82752666e-02\n",
      " -5.70046842e-01 -3.65941018e-01  7.04418540e-01  6.91040754e-01\n",
      "  2.74517894e-01  4.57746685e-01 -3.78735214e-01 -2.36114208e-02\n",
      "  4.03897285e-01  6.05915606e-01 -1.79581851e-01  4.97377187e-01\n",
      " -2.81525284e-01  2.64191121e-01  2.62102522e-02  9.03057083e-02\n",
      " -6.63820624e-01  3.81827950e-01  1.99463576e-01  3.09937298e-01\n",
      " -8.53536129e-02  1.00526549e-01  3.14013362e-02  4.73730952e-01\n",
      " -1.63777977e-01  1.83490515e-01 -4.24757004e-01 -1.47008583e-01\n",
      "  2.76258767e-01 -2.20134258e-01  6.13880336e-01  5.12159586e-01\n",
      "  1.58783346e-02  5.66034436e-01  2.35388488e-01 -1.18240692e-01\n",
      "  1.09726548e+00 -5.21492362e-01 -1.23814814e-01  7.87676811e-01\n",
      "  2.15077505e-01 -5.88199675e-01  6.52873516e-02 -1.88722894e-01\n",
      "  3.34827155e-01  2.94337213e-01  2.29753897e-01 -3.49843465e-02\n",
      "  2.67069846e-01 -5.18511459e-02  3.27092439e-01 -7.93229118e-02\n",
      "  2.96839476e-01  3.15804392e-01  5.81994317e-02  1.04490353e-03\n",
      "  8.66869509e-01  1.54498959e+00  5.61083555e-01  2.00321544e-02\n",
      " -1.98655561e-01 -4.04521301e-02  2.71510154e-01  1.12648249e+00\n",
      " -6.20767586e-02  7.80353606e-01  1.05022645e+00  9.27235484e-01\n",
      "  1.02153575e+00  6.44907475e-01 -2.11221397e-01  6.83900237e-01\n",
      " -1.19321402e-02  4.24043983e-01 -3.47968280e-01  5.96545279e-01\n",
      "  3.37083310e-01  1.39419302e-01  4.37080055e-01 -4.17383671e-01\n",
      " -3.49717677e-01  2.43375346e-01 -2.56567776e-01  6.12580836e-01\n",
      " -3.67483765e-01 -1.28609091e-01  1.51925594e-01  6.70793056e-01\n",
      "  5.39556503e-01  9.83776003e-02  3.47631156e-01 -2.74145395e-01\n",
      "  5.15793681e-01  5.86710036e-01  2.09867164e-01  5.32489680e-02\n",
      "  1.27707314e+00  1.08478040e-01  4.25372958e-01  1.27704883e+00\n",
      " -2.20038503e-01  1.09770525e+00  4.44868624e-01 -2.33559772e-01\n",
      "  9.79516208e-02  8.13697934e-01 -2.76884496e-01  3.28742653e-01\n",
      "  3.03382874e-01  1.88787133e-01 -5.05580902e-01  9.82892513e-02\n",
      "  1.07200563e-01 -7.25231409e-01 -3.47161889e-01  5.52267671e-01\n",
      " -5.76163828e-01  4.49496120e-01  4.59327906e-01  9.35091376e-02\n",
      "  1.20768535e+00  7.42496908e-01  1.78225681e-01  5.52842319e-01\n",
      " -1.23584211e-01 -3.13219696e-01  4.49947000e-01  1.44876018e-01\n",
      "  4.62844580e-01  6.41066253e-01 -5.15803918e-02  5.77205002e-01\n",
      "  1.83657631e-01  4.65783328e-02 -5.02794445e-01  1.28893897e-01\n",
      " -6.23428524e-01 -4.08080369e-01 -3.01959723e-01 -5.12480021e-01\n",
      "  5.80345154e-01  2.11881161e-01  6.18264079e-01  1.38463750e-02\n",
      "  6.32112205e-01 -1.89791143e-01  5.85026324e-01 -4.30635273e-01\n",
      " -4.52147663e-01  1.59714073e-01 -2.02234499e-02  7.55715668e-02\n",
      " -5.30022740e-01  5.50216973e-01  9.19878185e-02  5.95671162e-02\n",
      "  6.34904325e-01  4.84898627e-01 -8.45117450e-01 -2.40545720e-01\n",
      " -3.64354461e-01  7.98596203e-01  4.06753421e-01  3.44186038e-01]\n"
     ]
    }
   ],
   "source": [
    "for layer in mobilenetv1lite.layers:\n",
    "    if isinstance(layer,BatchNormalization):\n",
    "        # Get the weights\n",
    "        weights = layer.get_weights()\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        print(moving_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('means.txt','w') as mf, open('gamma.txt','w') as gf:\n",
    " for layer in mobilenetv1lite.layers:\n",
    "    if isinstance(layer,BatchNormalization):\n",
    "        # Get the weights\n",
    "        weights = layer.get_weights()\n",
    "        weights=ftf(weights)\n",
    "# Unpack the weights\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        gf.write(f'{gamma.shape} \\n')\n",
    "        np.savetxt(gf,[gamma],delimiter=\" \",fmt=\"%d\")\n",
    "        gf.write('\\n')\n",
    "        mf.write(f'{moving_mean.shape} \\n')\n",
    "        np.savetxt(mf,[moving_mean],delimiter=\" \",fmt=\"%d\")\n",
    "        mf.write('\\n')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# Print the weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('variances.txt','w') as mf, open('beta.txt','w') as gf:\n",
    " for layer in mobilenetv1lite.layers:\n",
    "    if isinstance(layer,BatchNormalization):\n",
    "        # Get the weights\n",
    "        weights = layer.get_weights()\n",
    "        weights=ftf(weights)\n",
    "# Unpack the weights\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        gf.write(f'{beta.shape} \\n')\n",
    "        np.savetxt(gf,[beta],delimiter=\" \",fmt=\"%d\")\n",
    "        gf.write('\\n')\n",
    "        mf.write(f'{moving_variance.shape} \\n')\n",
    "        np.savetxt(mf,[moving_variance],delimiter=\" \",fmt=\"%d\")\n",
    "        mf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00773076  0.00751693  0.14207378  0.02845884  0.02265899  0.00320543\n",
      "  0.02708841  0.13327822]\n",
      "[ 0.03663696 -0.00315189  0.15835337 -0.00458406  0.01005088  0.01089459\n",
      "  0.0394135   0.02864885]\n",
      "[ 0.0696625   0.02370044  0.02450065  0.05359923  0.00185997  0.04267759\n",
      " -0.03996933 -0.04372416 -0.06870531  0.0070521   0.00633266  0.01678469\n",
      "  0.06596633  0.08822378  0.05008045  0.03132116]\n",
      "[ 0.01840405  0.00750033  0.07774682  0.04834275  0.00556276  0.05012243\n",
      " -0.00778291 -0.02253165  0.01866138  0.02367339 -0.03990653  0.04281659\n",
      "  0.03874187 -0.01337314  0.03218598  0.03462602]\n",
      "[-1.41216880e-02  3.88738401e-02 -1.35391718e-02 -3.15958750e-03\n",
      "  5.88724203e-02 -4.98903822e-03  5.92829026e-02 -1.11956736e-02\n",
      "  9.43732541e-03 -7.36898631e-02  2.68072449e-02  1.37576843e-02\n",
      "  5.34018241e-02  7.39045739e-02  1.17806725e-01  2.84580383e-02\n",
      "  1.99789517e-02  7.57969916e-02 -4.85256221e-03  1.29937157e-02\n",
      "  6.78119063e-02  5.01328660e-03  6.12180829e-02  5.58023490e-02\n",
      " -4.09892760e-02 -8.73052701e-03 -1.75067398e-05  3.16238031e-02\n",
      "  5.57817966e-02 -2.79304255e-02 -4.67425138e-02 -1.05148759e-02]\n",
      "[ 0.04284242 -0.02259982 -0.03397308 -0.01473895 -0.01380462  0.03991332\n",
      " -0.01510477  0.05174025  0.01507072 -0.04846514  0.0605615  -0.03776471\n",
      " -0.02817415 -0.01185988  0.01186447 -0.02138755 -0.03830786  0.06000054\n",
      "  0.01243022  0.05223059 -0.00421494 -0.01351629  0.07622027  0.07052182\n",
      " -0.00660695  0.0073823   0.0431914   0.00235754 -0.1233393  -0.06118919\n",
      " -0.01527254 -0.01748801]\n",
      "[ 0.05100303  0.00603228  0.01732673 -0.00088854 -0.08088157  0.03632648\n",
      " -0.02262454 -0.00629184 -0.00485201  0.04079603 -0.09179208 -0.01579849\n",
      "  0.01520466 -0.03877912  0.03988889  0.01371205  0.00672386 -0.04746576\n",
      "  0.04388971 -0.09331413 -0.0198768  -0.02513935 -0.02485705 -0.02643734\n",
      " -0.03326691  0.01666474 -0.02034401  0.00498691  0.00669526  0.05074261\n",
      "  0.05187019 -0.002423  ]\n",
      "[-0.08719645  0.020158   -0.03147774  0.01626736 -0.00202526 -0.01824669\n",
      "  0.03041178  0.06760918 -0.00392151 -0.00414096 -0.07620536 -0.01212185\n",
      "  0.03306523  0.01687157  0.01309624 -0.02728214 -0.07222425 -0.00144759\n",
      "  0.04550988 -0.01677033  0.02146932 -0.03571802 -0.02882432 -0.04560847\n",
      "  0.0033361   0.01401397 -0.04502076 -0.05857044 -0.02971493  0.08137607\n",
      " -0.05447218  0.0473733 ]\n",
      "[ 0.02897228 -0.00853267  0.08017401  0.06707686  0.0359809   0.02916942\n",
      " -0.01242184 -0.00364722  0.02570075 -0.01391586  0.03200789 -0.00431558\n",
      " -0.04308148  0.0018479   0.00025837 -0.01136655 -0.02737002  0.03648451\n",
      " -0.02276787  0.05498798 -0.03087014 -0.00718718  0.0031788   0.04275178\n",
      "  0.05151307  0.02425658  0.06942217  0.02458099 -0.02657253 -0.05290276\n",
      " -0.0206194   0.02826434 -0.00370192 -0.0200285  -0.01706321 -0.02789965\n",
      " -0.03162696 -0.0416268   0.01202976  0.00048422 -0.0529394   0.07972806\n",
      " -0.05715134  0.03987575  0.01550511  0.05943868 -0.05293193  0.00121204\n",
      " -0.00712744  0.05294939 -0.05484199  0.11927391 -0.04583503  0.03732971\n",
      " -0.06914212  0.01391421  0.0824094   0.02989856  0.04879554 -0.04305233\n",
      "  0.02664859  0.0068088  -0.02170449 -0.05214838]\n",
      "[ 0.04261371  0.00624675  0.0145752  -0.02427195  0.00322492  0.01961898\n",
      " -0.03430435  0.00457539 -0.00142924  0.00499167  0.01159359 -0.01858727\n",
      "  0.03005425  0.02639876 -0.01676135 -0.00305301 -0.03569201  0.01294422\n",
      " -0.02964821 -0.00118303  0.01326692 -0.00300988  0.04183673 -0.02772478\n",
      " -0.04643722  0.00574648  0.02464842  0.02600269 -0.01979086 -0.04014605\n",
      " -0.01714106 -0.02614091 -0.05390248 -0.01695322  0.02707128 -0.07692222\n",
      " -0.07370422 -0.01980736 -0.02601209 -0.00278958 -0.0139498   0.0141971\n",
      " -0.0163672  -0.00314862  0.01454082 -0.00858426 -0.01472743  0.04239597\n",
      "  0.02506202  0.01304389 -0.04588977  0.05734195 -0.04014027  0.00531991\n",
      " -0.00544993  0.0044534  -0.00934051 -0.01500591  0.02289309  0.03364852\n",
      "  0.02007877 -0.00803082  0.09271556 -0.02140071]\n",
      "[ 0.03096969  0.00728963  0.00050933  0.04037533  0.00710682 -0.01317672\n",
      " -0.02732468  0.00440792 -0.0622336   0.02269339  0.02429767  0.01036734\n",
      "  0.02369292  0.00675115 -0.0090589  -0.01736562 -0.06200378  0.04850452\n",
      " -0.04832711 -0.01032351  0.03262161 -0.04230484  0.01188637 -0.01209688\n",
      "  0.0400669  -0.00882439  0.02453848  0.00742406  0.0090316   0.04192336\n",
      "  0.03569334 -0.01913768 -0.03365548 -0.03272358 -0.02098157  0.04224171\n",
      "  0.03171514 -0.05362446 -0.00458233  0.00833702  0.02096641  0.01369623\n",
      "  0.0483553   0.04376989 -0.01472792 -0.03246934 -0.00756969 -0.0544703\n",
      "  0.01704761  0.01533549  0.04765463 -0.0309249  -0.00839018  0.05314174\n",
      " -0.03713924  0.06810737  0.04085947 -0.02102542  0.00450362 -0.00418474\n",
      "  0.00611007  0.02444897  0.00766599 -0.0074375 ]\n",
      "[ 0.0144717   0.0023455  -0.05612979 -0.00631662  0.02494088  0.07381161\n",
      "  0.03372737  0.0105155   0.03216901  0.00142999 -0.0183061   0.01467542\n",
      "  0.02063277  0.02970835 -0.03000322 -0.03202439 -0.00726641  0.06364802\n",
      " -0.02698515 -0.0294127   0.00198599 -0.0169812  -0.06166887  0.03227953\n",
      "  0.00411328 -0.03608393  0.02901254 -0.08822292  0.041163   -0.06458761\n",
      "  0.04096794  0.00514313 -0.03813482 -0.04542115 -0.00781497 -0.0422637\n",
      " -0.02562838 -0.06244779 -0.0207015   0.02628549  0.00130439  0.00145336\n",
      " -0.01258939  0.02865849  0.01240048 -0.02895629 -0.02414818 -0.04935941\n",
      " -0.039981   -0.04333632  0.03518827 -0.02355585  0.03218284  0.01767606\n",
      "  0.00498203  0.03119374  0.02308185 -0.10280168  0.02672453  0.05793998\n",
      "  0.00926556  0.0262678  -0.01019402  0.03174032]\n",
      "[-5.72850965e-02  8.37229285e-03  6.48679212e-02 -5.79410046e-02\n",
      "  2.69850791e-02  4.94295396e-02 -1.43955536e-02 -1.72490440e-02\n",
      " -2.16008313e-02 -1.48873389e-01 -1.27401273e-03  9.33479052e-03\n",
      " -3.40145752e-02  7.01327901e-03 -2.23013852e-03  8.06763172e-02\n",
      " -2.66332552e-02  3.43409553e-03  8.23616143e-03 -6.45023538e-04\n",
      " -4.67230305e-02 -1.86561625e-02  9.80717596e-03  2.32605706e-03\n",
      "  2.60219746e-03 -2.03213915e-02  1.09659424e-02 -6.35365844e-02\n",
      " -4.15730774e-02 -6.78664958e-03  1.04278862e-01  5.05550997e-03\n",
      "  1.91770196e-02 -4.99496385e-02 -7.28049427e-02  2.70064920e-02\n",
      "  3.02871671e-02 -1.64431557e-02 -3.72369625e-02  3.42591368e-02\n",
      " -2.96603702e-02 -1.33359144e-02  3.34387762e-03 -2.47357208e-02\n",
      " -1.99027155e-02  2.05901861e-02 -7.40907118e-02  3.13229784e-02\n",
      " -4.64584753e-02  1.88742317e-02  1.49878452e-03 -5.04728667e-02\n",
      "  7.77880028e-02 -4.89475206e-02 -1.30860908e-02 -3.21892761e-02\n",
      "  5.41577451e-02  5.92885017e-02  2.25646198e-02 -3.76481451e-02\n",
      " -9.13359746e-02 -1.85258202e-02 -4.16341834e-02  9.16182399e-02\n",
      "  2.90435851e-02 -4.29021083e-02  4.13023569e-02 -1.54310456e-02\n",
      "  1.12682648e-01 -1.71998776e-02 -4.16925065e-02  1.18203517e-02\n",
      " -3.06418817e-03 -3.40274349e-02  3.85860093e-02 -3.20209563e-02\n",
      " -4.87143314e-03  7.10531557e-03  2.48573869e-02  3.86597239e-03\n",
      "  3.54812071e-02 -1.71142384e-01  4.49771956e-02  4.99228202e-02\n",
      " -2.89426968e-02 -5.19413836e-02  1.92915034e-02 -3.02684586e-03\n",
      "  3.26408818e-02 -1.32157244e-02 -2.81376019e-02  8.95216875e-03\n",
      " -1.44475559e-02  1.40814751e-01 -8.79892148e-03 -1.77101512e-02\n",
      " -5.12544848e-02 -4.12757918e-02  1.87698379e-02 -1.35902762e-02\n",
      "  2.76957406e-03  1.38126372e-03  3.37730572e-02  1.05095804e-01\n",
      " -2.86773406e-02 -3.95306386e-02 -7.15352818e-02  1.07820919e-02\n",
      "  9.16880183e-03  2.66761724e-02 -4.78554294e-02 -8.82359594e-02\n",
      "  3.25216493e-03 -1.12454154e-01 -6.66180030e-02  6.86154049e-03\n",
      " -6.44038431e-03  2.62104935e-04 -2.78868806e-02  1.91250374e-03\n",
      "  8.22105259e-03 -1.94251351e-02 -7.79146925e-02 -4.51761298e-02\n",
      "  2.15950813e-02 -8.01554997e-05 -3.86578143e-02  2.29082741e-02]\n",
      "[-0.02222251 -0.04958586 -0.01042522  0.04896673  0.01985982 -0.07289666\n",
      " -0.02712878 -0.00967947 -0.01425064  0.01267565 -0.14260702 -0.04477422\n",
      "  0.00462152 -0.03302578 -0.10569642 -0.02835831 -0.07240684  0.0349719\n",
      " -0.08434428 -0.00138632 -0.09607242 -0.02899476 -0.02039914 -0.0484674\n",
      " -0.02093823  0.00703716 -0.03316382  0.01473222  0.01190774  0.00496602\n",
      " -0.04762537  0.00483693 -0.02821902  0.0433573  -0.03892879 -0.06821394\n",
      " -0.11006066 -0.07394668  0.01777438  0.01018917 -0.01953818 -0.09021614\n",
      " -0.08040881  0.0332147   0.04691426 -0.018609   -0.03280373 -0.06041716\n",
      " -0.05281302 -0.09981121  0.00276605  0.00550569  0.03934448 -0.04720408\n",
      " -0.03427849 -0.05874664  0.01314782  0.04617874  0.02431048  0.00296428\n",
      " -0.04815823  0.0439447  -0.10155131 -0.00082087 -0.00666231 -0.06425373\n",
      " -0.01154624 -0.00396259 -0.15298235  0.00290182 -0.0728695  -0.01503405\n",
      " -0.00713415 -0.08066861 -0.02120393 -0.14549965 -0.05953932 -0.00956027\n",
      " -0.0314412  -0.0280337   0.00298743 -0.0566127  -0.05534785  0.00857181\n",
      " -0.04675433 -0.06631743 -0.00220538 -0.06648729  0.0026021  -0.03350708\n",
      " -0.05806492 -0.04124912 -0.02411051 -0.0915119  -0.07644279 -0.00683307\n",
      " -0.00363883 -0.05918942 -0.12962338  0.03898475  0.00781177 -0.06138676\n",
      " -0.06474031 -0.06552254 -0.01612011 -0.04291864 -0.04238287 -0.04187907\n",
      " -0.05122707 -0.0133668   0.00763635 -0.06016796 -0.03648298 -0.02207438\n",
      "  0.03642475 -0.0002583  -0.03666145 -0.00937602 -0.03869943 -0.0022185\n",
      " -0.06642345 -0.11221597 -0.00298506  0.01720718 -0.16809203  0.01204838\n",
      " -0.06619191 -0.03235044]\n",
      "[-0.00937755  0.00860047 -0.15993597 -0.05423122 -0.05391671 -0.05745829\n",
      " -0.07033362 -0.00125601 -0.02439277  0.0534528  -0.08733817 -0.00891159\n",
      " -0.05485601 -0.01227713 -0.07115654 -0.02380857 -0.02962126 -0.08453072\n",
      " -0.21669485  0.02097712 -0.25344515 -0.19973326 -0.03948211  0.01256177\n",
      " -0.12401585 -0.04311299 -0.05145193 -0.01090095  0.05625516 -0.07452893\n",
      "  0.00201835  0.02971249 -0.13980377  0.01636241 -0.05516784 -0.01144312\n",
      " -0.06658971 -0.04653856 -0.08039245 -0.0291417  -0.34609786  0.0247933\n",
      " -0.03521115 -0.16809095  0.00574441 -0.04795071 -0.01601598 -0.13729611\n",
      " -0.03548243 -0.10208891 -0.06716295 -0.00873344 -0.0610767  -0.0064454\n",
      "  0.0581609  -0.00130832  0.03738454 -0.11005756  0.03706711 -0.00339474\n",
      " -0.06919146 -0.05481804 -0.0667551  -0.01473825 -0.01012214 -0.00771068\n",
      " -0.01896623 -0.21110567 -0.02383024 -0.05824535 -0.00271256 -0.0551488\n",
      " -0.01309252 -0.02630729  0.00767355 -0.0212295  -0.06394646 -0.0611339\n",
      " -0.07496354 -0.03006469 -0.0670971  -0.09714404 -0.00398665  0.02608288\n",
      " -0.03054083 -0.02211209 -0.05686726 -0.03199026 -0.01467978 -0.31909192\n",
      " -0.06903391 -0.00342206 -0.15298097  0.02583029  0.00882138 -0.10096254\n",
      "  0.00329655 -0.04235955 -0.14852057 -0.02992398  0.00081166 -0.14406034\n",
      " -0.0639346  -0.10330676 -0.02606411 -0.2533477  -0.03678442 -0.40933174\n",
      " -0.03710173 -0.06214793  0.02982954 -0.08400575 -0.10011917 -0.01426087\n",
      " -0.14183134  0.04688447 -0.1264327  -0.11985987 -0.07759228  0.03657379\n",
      " -0.06185223 -0.073906   -0.16166367  0.05186069 -0.02813771  0.0069001\n",
      " -0.04323304  0.07605549 -0.04072706 -0.15640397 -0.16228613  0.00478828\n",
      " -0.07173584 -0.02364875 -0.06686542 -0.12745401 -0.08407407 -0.05455603\n",
      " -0.01472946  0.02049786  0.00516568 -0.02486067 -0.01945422  0.03140989\n",
      " -0.02186045 -0.07252523 -0.37759325 -0.0257498  -0.09005778 -0.01265849\n",
      " -0.01212888 -0.08293519 -0.04569583 -0.0055705  -0.06279117 -0.02268838\n",
      " -0.08881395 -0.11274294 -0.0603423  -0.02170624  0.00896982 -0.09127622\n",
      " -0.02584747 -0.19243942 -0.05234567 -0.09461509 -0.0423017  -0.03169502\n",
      "  0.02135189 -0.01949655 -0.03901943  0.01847248 -0.0146898  -0.07227353\n",
      " -0.07770069 -0.08229944 -0.00787104 -0.12945409 -0.09498496  0.01414215\n",
      " -0.04215831 -0.06478389 -0.08828831 -0.0158813  -0.05440052 -0.17420323\n",
      "  0.03534676 -0.04301526 -0.0618025  -0.05421655 -0.00308779 -0.08728097\n",
      " -0.12635538 -0.04000853 -0.04713542 -0.02864994 -0.04130138  0.04778199\n",
      " -0.12407848 -0.17578566 -0.05171623 -0.02865855 -0.05415649 -0.28938648\n",
      " -0.18285587 -0.02094569 -0.04651594 -0.01801123  0.03257139 -0.37953022\n",
      " -0.0548542   0.01605794  0.00497926 -0.01727058 -0.02379438 -0.08383203\n",
      " -0.00792798  0.03039229  0.00879807 -0.02455326 -0.06150437  0.00597275\n",
      " -0.07318316 -0.0757673   0.01863175 -0.09557784 -0.06625023 -0.00398126\n",
      " -0.11013088 -0.1744405   0.00538129 -0.01936715 -0.03375369  0.01046248\n",
      " -0.01454325 -0.0108545   0.00101654 -0.10592998 -0.08029624 -0.04208749\n",
      " -0.02000155  0.00124936 -0.02184301 -0.07170188  0.00538309 -0.05257343\n",
      " -0.01700567 -0.01777726  0.01586024 -0.09293516  0.06987653  0.03022166\n",
      " -0.0059175   0.02073392 -0.03528067 -0.21430452]\n",
      "[-2.28438922e-03 -1.01674639e-01 -1.50878057e-01 -3.69904377e-02\n",
      " -6.73203915e-02 -6.13192916e-02 -7.71317407e-02 -4.06173058e-02\n",
      " -8.74239355e-02  1.63684972e-02 -1.24297664e-01 -2.82222293e-02\n",
      " -1.18139990e-01 -9.75537300e-03 -4.22373936e-02 -8.55825190e-03\n",
      " -2.36115921e-02 -1.43491387e-01 -1.73738435e-01 -9.33274776e-02\n",
      " -2.05107369e-02 -1.16120666e-01 -1.47574395e-02 -6.06962070e-02\n",
      " -9.02048126e-02  1.32819568e-03 -6.53735027e-02  6.66368101e-03\n",
      " -1.54213130e-01 -4.77657691e-02 -2.84120440e-02 -1.36208013e-02\n",
      " -1.75496697e-01 -5.22968657e-02 -5.90226017e-02  1.26755722e-02\n",
      " -7.64683336e-02 -1.50005504e-01 -1.87990125e-02 -4.29143831e-02\n",
      " -4.68955748e-02  8.17853678e-03 -5.94422184e-02 -9.04998630e-02\n",
      "  6.82462333e-03 -4.50623408e-02 -7.89996386e-02 -3.41534726e-02\n",
      " -8.11627209e-02 -4.86001335e-02 -2.69432534e-02 -3.05474866e-02\n",
      "  9.63769294e-03 -9.60058242e-05 -5.48838917e-03 -2.03218330e-02\n",
      " -6.06785994e-03 -1.10851012e-01  4.16700430e-02 -1.31720100e-02\n",
      " -6.12892844e-02 -7.93404579e-02 -2.31911894e-02 -1.29937917e-01\n",
      " -8.25472325e-02 -1.62741557e-01 -8.54656994e-02 -6.85174242e-02\n",
      "  1.39826490e-03 -6.69441521e-02 -6.86006173e-02 -3.21868695e-02\n",
      " -3.69554572e-02 -5.91925643e-02 -2.50035040e-02 -2.56386232e-02\n",
      " -1.10783346e-01 -1.15106978e-01  9.87831317e-03 -4.75024208e-02\n",
      " -5.54791242e-02 -1.12896986e-01  2.21820492e-02 -4.38619889e-02\n",
      " -6.50201514e-02 -6.08201465e-03 -1.16492487e-01 -5.51736131e-02\n",
      " -9.95114520e-02 -7.27609498e-03 -1.55579686e-01  4.79885796e-03\n",
      " -9.91558470e-03 -5.92046753e-02 -1.41488984e-01 -1.50761947e-01\n",
      " -4.83813249e-02 -1.23949133e-01 -1.19966663e-01 -3.72562706e-02\n",
      " -6.74994960e-02 -7.15745091e-02 -5.76705020e-03  5.13100922e-02\n",
      " -9.44490582e-02 -1.18375488e-01 -2.82378308e-02 -1.15248539e-01\n",
      " -4.19266634e-02 -1.23035654e-01 -4.78329882e-03  1.07990904e-02\n",
      "  2.70220023e-02 -4.48392332e-02  1.78034045e-02 -5.09222178e-03\n",
      " -1.50376245e-01 -1.15597315e-01  3.60964565e-04 -1.13438316e-01\n",
      " -3.29694920e-03  1.00547969e-02 -3.22358795e-02 -4.03294004e-02\n",
      " -1.24418333e-01 -1.66162010e-02 -1.08105257e-01 -1.62471622e-01\n",
      " -2.83353254e-02 -1.01988576e-01 -4.71458770e-02 -4.35491912e-02\n",
      " -1.23615973e-01 -8.62705186e-02 -5.03669344e-02 -1.11279733e-01\n",
      " -1.15125857e-01 -1.03087768e-01 -4.15687412e-02 -1.46203756e-01\n",
      "  1.12690423e-02  2.01431587e-02 -6.45427406e-02  1.22537129e-02\n",
      " -7.79393017e-02 -1.37267694e-01  3.71617661e-03 -1.11503951e-01\n",
      " -6.04313314e-02 -5.05259819e-02 -3.34109366e-02 -1.22020990e-01\n",
      " -2.85072923e-02 -1.23479031e-01 -1.38495982e-01 -3.64282206e-02\n",
      " -1.13684364e-01 -4.29244041e-02 -2.75086295e-02 -9.77303609e-02\n",
      " -4.00189124e-03 -4.06321278e-03 -9.16285366e-02 -1.26639195e-02\n",
      " -3.65956947e-02 -1.79221004e-01 -8.04724321e-02 -2.54529696e-02\n",
      " -3.41687612e-02 -4.37809527e-02 -1.17674820e-01 -1.09603398e-01\n",
      " -6.47499561e-02 -7.45407864e-02 -1.45399585e-01 -9.28855017e-02\n",
      " -2.28518732e-02  1.05219865e-02 -8.32881778e-02 -2.43510734e-02\n",
      " -5.11768684e-02 -7.88237453e-02 -1.42461518e-02 -1.26492009e-01\n",
      " -1.23393625e-01 -8.01352262e-02 -1.15816155e-02  2.41752975e-02\n",
      " -1.13877676e-01 -6.02450818e-02 -7.09646046e-02 -1.43598378e-01\n",
      " -5.19459955e-02 -2.22212682e-03 -1.43537447e-01 -3.26291807e-02\n",
      " -7.97489136e-02 -7.96193331e-02 -3.20709758e-02 -3.45428213e-02\n",
      " -5.14061153e-02 -7.72552192e-02 -9.56083015e-02 -7.18225986e-02\n",
      " -7.01594800e-02 -9.35030952e-02 -1.59284920e-01 -3.91200148e-02\n",
      "  5.16518531e-03 -1.72710955e-01 -4.10664901e-02 -5.63264489e-02\n",
      " -7.19692633e-02 -6.42428622e-02 -1.07655279e-01 -1.46026030e-01\n",
      " -6.12651110e-02 -4.95805107e-02  2.85884589e-02 -2.27902830e-02\n",
      " -7.93838501e-02 -3.25493980e-03 -1.49460793e-01  1.84350368e-02\n",
      " -3.49522792e-02 -1.81596875e-01  8.05143919e-03  2.65966952e-02\n",
      " -1.07317664e-01 -7.98875391e-02 -5.29701682e-03 -3.38701867e-02\n",
      " -7.54518509e-02 -1.80279557e-02 -2.06813812e-02 -1.74504906e-01\n",
      " -1.14857964e-01 -1.01256579e-01 -8.01925585e-02 -1.09514900e-01\n",
      "  4.32710871e-02 -6.36288002e-02 -6.94126114e-02 -5.01553863e-02\n",
      " -7.05537805e-03 -3.36029567e-02 -1.06479879e-02 -2.93924585e-02\n",
      " -2.52884347e-02 -8.00957307e-02 -3.20002288e-02  3.99122536e-02\n",
      " -1.38130886e-02 -1.23099075e-03 -1.24749452e-01 -6.72708526e-02]\n",
      "[ 6.41441159e-03 -1.42372064e-02 -5.17364970e-05  1.05458107e-02\n",
      "  1.53392619e-02  4.96339565e-03 -1.68102365e-02 -3.10957409e-03\n",
      "  5.53217828e-02  7.94956088e-03 -2.23927740e-02  1.29988501e-02\n",
      "  4.41490971e-02  2.59026680e-02  1.84146594e-02 -5.82576031e-03\n",
      " -1.93721876e-02  2.29452131e-03  4.23839279e-02 -8.11154954e-03\n",
      "  5.04941009e-02  1.78521127e-02  3.60348150e-02 -1.23968935e-02\n",
      "  6.12103147e-03  2.22728085e-02  1.33276116e-02 -4.22682054e-03\n",
      "  4.12523486e-02 -1.54358223e-02  3.65758687e-02  3.99256684e-02\n",
      " -3.56977270e-03  3.78225036e-02 -3.88082885e-03  4.07908335e-02\n",
      "  6.81610499e-03 -5.58981933e-02  4.91624558e-03 -3.56435264e-03\n",
      "  3.93610150e-02  3.08110490e-02  2.96282936e-02 -1.43549696e-03\n",
      "  3.19040492e-02  2.79626511e-02  2.61429101e-02  2.98650842e-02\n",
      "  2.64904723e-02  2.91362288e-03  7.58642238e-03  6.32353127e-04\n",
      "  3.62854637e-02 -4.22691600e-03 -1.33274123e-03 -1.11588882e-02\n",
      "  5.48019409e-02  2.38653668e-03  2.02663671e-02 -1.50127793e-02\n",
      "  1.63175650e-02  1.47365248e-02  5.52853860e-04  3.96704813e-03\n",
      "  4.69463207e-02  5.49186729e-02  3.90603393e-02 -2.29598209e-02\n",
      " -2.55519152e-02 -6.06557867e-03 -1.93016510e-02  4.43370305e-02\n",
      "  1.22620817e-03  8.52684490e-03  5.11027202e-02  4.32050638e-02\n",
      " -1.79900806e-02  2.80044843e-02  3.16233709e-02  1.76076628e-02\n",
      "  5.11076115e-02  1.25036929e-02  2.38548988e-03  1.53757576e-02\n",
      "  4.90190350e-02 -1.84563044e-02  2.30203569e-03 -4.17781342e-03\n",
      "  3.53521481e-02  1.34202447e-02  1.75340306e-02  2.89450698e-02\n",
      " -2.39395406e-02  2.15439568e-03 -1.10831168e-02  6.51398790e-04\n",
      " -4.26382711e-03 -1.12255095e-02  2.11954359e-02 -6.97774114e-03\n",
      "  2.66472027e-02 -3.05401464e-03 -7.13595515e-03  7.49049615e-03\n",
      "  5.44001907e-02 -6.76361425e-03  2.26756390e-02  1.07029406e-02\n",
      " -1.34894866e-02  2.31840834e-02 -3.27210082e-03  9.60520003e-03\n",
      " -4.90353443e-03  1.72425713e-02  8.42728623e-05  1.08955512e-02\n",
      "  6.82810694e-03  1.08165937e-02 -1.59888715e-02  3.58212390e-03\n",
      "  3.21840346e-02  6.39305413e-02 -9.69819166e-03 -1.07121095e-02\n",
      "  1.15527296e-02  1.84495279e-04  1.00596156e-03  5.39981876e-04\n",
      " -3.58611182e-03  2.74384283e-02  2.76535237e-03 -2.22955067e-02\n",
      "  2.72182506e-02  1.10191386e-02  3.11149023e-02  3.24352607e-02\n",
      " -1.52169839e-02  6.52690744e-03  2.90245730e-02  1.51618815e-03\n",
      "  6.46836264e-03  3.96436267e-02 -2.14477517e-02 -3.24578863e-03\n",
      " -9.17177298e-04  3.15252878e-02  1.91736408e-03  2.02945620e-02\n",
      "  1.46232862e-02  5.03707631e-03 -2.99165249e-02  7.94370484e-04\n",
      "  8.54931585e-03  1.07347770e-02  2.62219422e-02 -2.74536619e-03\n",
      "  1.59706809e-02 -9.69442911e-03 -1.67449331e-03 -9.87772085e-03\n",
      " -1.56056024e-02  1.12649880e-03  3.03129712e-03  3.32022528e-03\n",
      "  6.78943796e-03  5.42213256e-03  3.73794921e-02  1.20626297e-02\n",
      "  9.77117103e-03  1.07758781e-02 -3.11139086e-03 -2.15744111e-03\n",
      "  7.49376602e-03 -8.17646831e-03  1.26508605e-02 -1.75259039e-02\n",
      "  2.56803120e-03  5.12436591e-02  7.05516199e-03  4.26859893e-02\n",
      " -1.50443353e-02  4.28979993e-02 -6.21833606e-03  1.75960101e-02\n",
      " -9.43888817e-03 -2.08885386e-03  9.00114235e-03  1.30619518e-02\n",
      " -2.55603082e-02 -6.51632855e-03  9.32851515e-04 -1.23082763e-02\n",
      "  2.12299991e-02 -8.12609866e-03  2.67556985e-03  1.17538311e-02\n",
      "  8.91294703e-03  1.39536839e-02  2.47918498e-02  1.73253973e-03\n",
      " -2.05648062e-03  3.61541659e-03 -3.57420836e-03 -6.88176649e-03\n",
      " -1.57561619e-03  5.88478427e-03  2.21478427e-03  1.45545520e-04\n",
      " -5.67421131e-03 -5.10516251e-03 -2.60924958e-02  6.15228841e-04\n",
      "  2.90408228e-02  1.23769017e-02  4.50583175e-03  7.62056280e-03\n",
      " -3.25618871e-02  2.85080280e-02  5.00114693e-04  5.40179871e-02\n",
      "  3.28699267e-03 -1.64558496e-02  5.28789498e-02 -5.46505721e-03\n",
      "  2.73700263e-02  4.51422110e-02  2.69858949e-02  5.08793741e-02\n",
      " -1.44832698e-03  2.14848183e-02  1.45266680e-02  2.18713051e-03\n",
      "  2.59722825e-02 -1.58047013e-03  2.14549876e-03 -1.63876582e-02\n",
      " -8.13777186e-03  4.40222118e-03 -1.13837114e-02 -5.54422755e-03\n",
      "  1.16196321e-03  1.13962851e-02  5.00339903e-02 -1.38411382e-02\n",
      "  4.90979943e-03  4.81936662e-03  3.56952660e-02  3.51625669e-04\n",
      " -9.50163789e-03 -4.48220316e-03  2.07511671e-02  2.45252345e-02\n",
      "  8.67829425e-04 -3.04056462e-02 -2.17550015e-03  5.21851853e-02]\n"
     ]
    }
   ],
   "source": [
    "for layer in mobilenetv1lite.layers:\n",
    "    if isinstance(layer,BatchNormalization):\n",
    "        weights = layer.get_weights()\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "x=ftf(0.00750033,12)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000100101100\n",
      "1111111011010100\n",
      "0111111111111111\n",
      "1000000000000000\n"
     ]
    }
   ],
   "source": [
    "def to_signed_16bit_binary(decimal_number):\n",
    "    if decimal_number < -32768 or decimal_number > 32767:\n",
    "        raise ValueError(\"The number is out of range for a 16-bit signed integer\")\n",
    "    \n",
    "    # If the number is negative, apply two's complement\n",
    "    if decimal_number < 0:\n",
    "        decimal_number = (1 << 16) + decimal_number  # 2^16 + decimal_number\n",
    "    \n",
    "    # Convert to binary and pad to 16 bits\n",
    "    binary_representation = format(decimal_number, '016b')\n",
    "    \n",
    "    return binary_representation\n",
    "\n",
    "# Test the function\n",
    "print(to_signed_16bit_binary(300))    # Output: '0000000100101100'\n",
    "print(to_signed_16bit_binary(-300))   # Output: '1111111011010100'\n",
    "print(to_signed_16bit_binary(32767))  # Output: '0111111111111111'\n",
    "print(to_signed_16bit_binary(-32768)) # Output: '1000000000000000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000000000011111'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_signed_16bit_binary(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244 249 231 263 253 259 257 220]\n",
      "(8,)\n",
      "[-77 -19 -32 -42   9  63  24 -35]\n",
      "[53  3 13 18  5 45  7 17]\n",
      "[244 243 275 246 248 253 254 260]\n",
      "(8,)\n",
      "[-13 -51   7  93 -22  10  12 -70]\n",
      "[ 4 21  4 70  7  1  8 41]\n",
      "[241 260 263 273 253 258 245 239 236 270 244 283 253 252 253 239]\n",
      "(16,)\n",
      "[-149   28   -2  119  -21   48  -14  -28  113   21   27   37  -54    0\n",
      " -116    8]\n",
      "[33 36 19 42 32 56 17 26 48 84 72 58 50 56 91 28]\n",
      "[245 242 267 263 258 253 246 248 252 254 241 269 260 270 264 254]\n",
      "(16,)\n",
      "[ 26 -36 -20 -32   3  13 -33  -4  11 -49   0 -24 -16   7 -11  22]\n",
      "[ 6 20 14 19  3  8  6 10  4 16  9 11  3 14  3 11]\n",
      "[262 273 245 235 269 219 249 250 233 254 267 250 229 261 256 242 253 256\n",
      " 233 262 252 248 242 264 265 256 258 251 235 253 254 245]\n",
      "(32,)\n",
      "[  43   95  -13  124   32   19   58   78  -94  -42   -2  -93  -10  -64\n",
      "  -17  -11   -4  -63   26   41 -120  -99   33   38  -97   89  -91  -46\n",
      "  115  -90   42   -6]\n",
      "[59 62 47 41 26 45 46 65 72 38 35 72 50 87 57 43 55 64 57 76 52 81 38 44\n",
      " 49 52 84 67 27 92 64 53]\n",
      "[258 248 248 247 251 271 262 263 256 255 258 248 251 266 259 253 251 261\n",
      " 255 258 258 250 263 257 262 258 255 262 255 248 278 238]\n",
      "(32,)\n",
      "[ 21  39   1 -12   3  17  -8  39 -22  10   3   1 -29 -11   4 -21   2 -30\n",
      "  19  -2 -27  33  21   0  29 -24 -15 -14   2  12   7  -2]\n",
      "[ 5 11  3  3  9  9  4 20  8  8  5  3  9  2  3  5  6  3 11  4  5  4  8  9\n",
      "  5 10  3  3  4  2  9  4]\n",
      "[248 261 254 298 212 267 267 264 240 250 238 253 260 233 245 249 255 266\n",
      " 259 254 248 224 255 254 247 245 229 246 250 268 263 257]\n",
      "(32,)\n",
      "[ -88   41   48 -238  -48 -101   42  114   25 -144  -37 -149 -146  161\n",
      "   -3   39   -6   86 -166  216  -28   34   61  100   34 -161   48  -11\n",
      " -114   62 -133   55]\n",
      "[174 106  90 146  93 163  85 112  85 102  99 177 143 121  83  74 120 144\n",
      " 199  99  79  82 145 139  84 133 138  76 105  96  74 104]\n",
      "[248 258 256 298 260 262 258 271 252 251 238 247 256 241 243 244 244 252\n",
      " 258 260 255 241 260 255 254 240 239 236 245 278 261 262]\n",
      "(32,)\n",
      "[ -1 -25  -2  -3  24 -29 -53  13  38 -39   5 -37 -21  -6  16 -14  -4  20\n",
      "  41  19  44  -4  59   5  21 -16  26 -16 -41  26  -1 -23]\n",
      "[ 3  7  8  4  7  5 23 10 14  4  4  5  4  3  3  5  5 10  6  8 16  5 18  6\n",
      "  8  3 11  4  9  8  7  7]\n",
      "[264 256 252 252 256 259 259 250 254 256 261 245 266 262 252 261 262 247\n",
      " 244 258 259 267 271 257 273 255 260 268 246 248 262 245 250 267 248 236\n",
      " 266 255 246 277 245 251 245 252 265 257 259 245 240 271 254 244 242 252\n",
      " 239 268 250 251 280 266 256 254 270 259]\n",
      "(64,)\n",
      "[ -67   -6   93    5  136   53 -172  -55  -83   28    2  110  -19   -9\n",
      "  -99   14  126  -14   95 -104  -15  107  -76  -69 -223  -92   52   51\n",
      "  -82   64    3  -38  -70   -2  -21  -24   94   19   68   38   60 -159\n",
      "  110  -89   38  -48  -46  129  -19   -2   74   86   19    4   61   78\n",
      " -129   36   94  -41 -132   18   92   19]\n",
      "[ 55  60 134  86 180  66 105  69  79  72  76  77  54  64  47  47 110  84\n",
      "  72 141  46  67  62  56 252 129  88  62  81 120  79  48  51  46  49  86\n",
      "  60  66  70  72  55 127 121 113  53 132  61 109  83  62 115  86  79  38\n",
      "  67  57 167  49 125  47 138  63  79  55]\n",
      "[263 253 260 252 279 264 259 252 254 255 252 261 262 262 248 256 254 247\n",
      " 266 263 256 261 267 253 278 250 255 261 243 241 266 242 245 252 251 227\n",
      " 248 253 238 268 260 252 264 249 261 252 260 258 250 270 257 268 233 255\n",
      " 241 263 256 254 271 257 256 252 271 251]\n",
      "(64,)\n",
      "[  6 -17  49  -8  -6 -38   6 -32 -26  11  22  -2  17 -46 -45   8   4 -16\n",
      "  -2 -53  48 -47  15  -2   0 -37   5  51 -37 -26  21  -8 -24   6   6 -18\n",
      "  19   3 -19 -43  16  12  11 -33 -47  14  11  17 -12  -7  10   3 -13  23\n",
      " -29  25 -38   6 -22  33 -12  33 -27  -5]\n",
      "[ 3  3 24  5  4 11  1  9  4  3  6  4  3  9  7  4  5  2  3  7  8 12  5  2\n",
      "  1  3  4 14  4 10  4  2  3  3  3  5  5  2  4  9  6  1  5  3 11  2  3  8\n",
      "  5  6  4  5  4  3 10  9  4  4  8  7  1  4  8  4]\n",
      "[255 251 252 249 266 266 274 270 267 259 249 267 265 262 262 256 249 282\n",
      " 259 255 283 247 271 257 267 246 261 237 275 243 258 249 241 257 249 249\n",
      " 252 241 252 254 267 254 272 265 263 264 244 249 227 248 263 256 259 267\n",
      " 250 261 263 239 258 278 259 259 245 266]\n",
      "(64,)\n",
      "[-100  112 -165 -226   80  -68   77   72   10   -6  101  154 -148  -62\n",
      "   37  -31  -28   72  -73   40  233   -6  -32  -90  -76   58   11 -132\n",
      "  130  -69   93  -52  -89  153 -114 -206    7  180  -70   -8  -47 -142\n",
      "  -29 -126  -96 -105   11 -220    4    0   -1   51 -218 -209   73   45\n",
      "   90   11 -100    7  127  -68  217  -27]\n",
      "[ 82  91 119 168 106 111 111 144  98 128  76 125 107 179 173  99  87 102\n",
      " 137 177 106  94  90 128  85  86  84  88 111 101 136  85 140  93  74 222\n",
      "  67 262  76  92  94 364  84  98 116  84 161 145 103  86 129  74 116 172\n",
      "  79 107 149  95 134  92 118  86 184  94]\n",
      "[251 248 249 246 263 264 270 275 275 254 259 262 254 263 249 247 256 270\n",
      " 257 244 250 237 244 256 251 244 259 236 257 245 266 248 238 254 253 250\n",
      " 254 240 251 251 264 251 258 262 261 264 249 250 225 243 261 254 258 269\n",
      " 247 261 262 228 257 268 254 257 254 266]\n",
      "(64,)\n",
      "[ 11 -32  16  28  37  11  48   2  48  58   2 -64  21  35  15 -11   5  35\n",
      "  42 -24  30 -14  -4  -2  13 -12 -55   2  26   3  29 -31   5  44  13 -32\n",
      " -10 -51   9 -31 -10 -17   5 -50  37   0  -9   7  -2 -27  32  16  41 -14\n",
      " -21 -26  25  20  36  26  17 -42  30 -43]\n",
      "[ 2  6  3  3 16  3  8  7 10 10  3 25  6 10  6  3  4 11  8  9 10  3  4  1\n",
      "  6  3 16  1  5  2  8  7  1 11  3  3  2 28  2  5  4  1  5  8  4  3  2  1\n",
      "  1  3 10  5  6  2  3  6 10  5  4  9  5  8 11  6]\n",
      "[224 246 273 259 268 258 249 254 259 246 252 246 258 250 250 263 243 259\n",
      " 232 258 254 249 257 251 252 253 260 254 259 264 277 256 252 259 238 261\n",
      " 267 271 266 253 263 242 258 271 261 253 268 262 252 234 259 263 255 242\n",
      " 258 247 262 264 263 254 260 270 228 250 258 240 255 248 275 261 248 254\n",
      " 266 239 256 243 233 255 252 255 252 246 267 262 247 240 259 264 264 251\n",
      " 239 250 255 257 242 260 273 244 255 270 258 246 241 266 257 257 252 245\n",
      " 257 251 247 261 261 260 257 255 253 261 248 259 242 247 233 260 238 261\n",
      " 255 245]\n",
      "(128,)\n",
      "[  46  144   32   97   62  -83  -21   14   13  172    3  -33   13 -130\n",
      "   20    3  -34  -34  -31  -53   80 -122 -155   -6   -1  -48   77  -24\n",
      "   88  -30 -247  -56  -38  124   98  -49  -41   70  -11  -45   15  -41\n",
      "   51   13 -149  -87 -166  179  -12   15   62  -42  -45  -92  -32  -14\n",
      "  -19  -36   74  -69   53   19   37 -196  219   75 -138  115  166   61\n",
      "   -7  117   61   24    7  -76  -20  144  -72 -143   21   69  192 -143\n",
      "  -71   70   97   32   20   47  -43 -146  -45   57  -86   16  -87  -57\n",
      "   -8   32 -142  -57   51   99   23  126   15   22   24  -62   22  -24\n",
      "  102   89  -18  -50   25 -134   26  138  -28   55  -50    6  -68 -129\n",
      " -120   32]\n",
      "[ 85  88 151 113 118 177  74  88  85  72 109 113  68  88  93  87  85  81\n",
      "  64  94 166  81 133  57  83  72 168  92  59 127 316  67  63  84  67  93\n",
      " 139  87  85  66  77 109 124  79  72  81  78 235  70  68  84  94 132  79\n",
      "  95  59 106  93  79  76 114  90  80  89 123  72  77  84 120  79  81 168\n",
      "  82  54 152 126  90 131 108 108  46  94 103 185  77  67 156  87  65  73\n",
      "  90 140  92 124 109  71  72  90  49  87  79 100  77  85  78 152  76  56\n",
      "  88  77  63  84 105  74  62  71  93 205 102  92  71  64  56 106 127 149\n",
      " 107  73]\n",
      "[231 248 268 259 267 258 249 251 254 283 255 242 258 248 277 267 241 258\n",
      " 234 256 256 247 254 244 247 248 252 270 256 256 278 252 250 259 237 261\n",
      " 267 260 263 256 258 236 258 271 257 251 259 260 249 239 257 261 259 242\n",
      " 257 245 263 265 261 255 260 267 230 248 252 244 255 278 302 256 239 260\n",
      " 259 238 252 244 235 258 248 251 252 276 302 265 242 241 255 273 257 248\n",
      " 230 245 252 268 241 256 272 243 254 266 256 246 232 280 255 255 253 244\n",
      " 252 246 239 254 256 272 258 249 246 260 242 257 239 247 238 256 236 257\n",
      " 253 242]\n",
      "(128,)\n",
      "[ -6 -16   3 -39 -34  -5   6 -25  24  26  -3  14  30  25 -12 -10  -7  -4\n",
      " -10  29  10   6 -31  10 -15 -30 -11   5 -33  21   1 -26 -34 -35 -13   4\n",
      "   8   0  41  -4  21  24  -1  45  26 -35  25  -4  26  -5 -28  13  41 -14\n",
      "  -3  -5 -14 -37  39 -19  10 -33  -5  30  28  -7 -35  -8  -5 -32  16  -7\n",
      "  26 -23  27   4  -1  23  30  30 -15  26 -11  38   1 -10   1  -1   1  37\n",
      " -19  13   3  -7   6  17  33  13  -3 -53 -32  -1  24   0  19  13  27 -30\n",
      "   1 -28 -14   4  -9  20 -29  24 -35  22 -24 -31  17   3  -6  11   3 -31\n",
      "   3 -11]\n",
      "[ 1  3  3 11  6  1  1  7  4  5  2  1  5  1  3  4  2  3  1  3  3  1  3  2\n",
      "  3  3  3  4  5  2  1  3  3  9  2  2  2  3  7  2  3  2  2  7  4  3  4  4\n",
      "  3  2  5  3 11  3  1  2  4  4  9  3  3  8  1  2  6  3  4  4  4  7  3  3\n",
      "  6  2  9  1  1  8  3  2  3  3  6  4  2  2  2  3  2  5  4  1  1  3  1  2\n",
      "  5  1  1 13  3  1  4  4  4  4  2  4  1  5  3  2  3  4  3  3  7  2  5  7\n",
      "  1  2  1  2  1  3  2  3]\n",
      "[269 257 237 252 238 241 221 239 237 270 240 246 241 266 252 262 245 233\n",
      " 196 249 254 237 259 232 237 259 255 263 270 235 257 244 218 259 239 265\n",
      " 225 237 255 247 242 258 247 259 278 239 256 254 234 248 259 252 258 264\n",
      " 250 261 255 255 263 253 244 230 255 230 241 241 237 244 259 247 252 248\n",
      " 242 252 258 254 234 241 264 247 254 238 270 242 227 248 240 240 237 257\n",
      " 233 260 250 230 259 243 245 241 246 243 223 224 269 265 240 246 258 235\n",
      " 253 212 245 262 265 234 256 254 249 219 260 262 254 262 251 251 232 250\n",
      " 256 248 229 243 256 240 220 216 235 220 242 247 261 266 259 270 223 262\n",
      " 242 224 232 251 239 243 247 220 246 237 229 244 239 254 258 215 261 261\n",
      " 237 252 264 217 234 245 248 243 237 263 262 233 260 217 251 258 222 251\n",
      " 230 225 258 232 219 241 251 275 246 213 222 225 244 261 229 255 224 254\n",
      " 255 255 245 226 246 227 246 241 230 248 262 213 241 249 231 229 235 229\n",
      " 249 250 271 255 266 259 201 254 240 210 261 266 222 250 260 235 221 252\n",
      " 252 224 240 239 220 231 266 235 247 248 262 250 262 244 252 221 254 288\n",
      " 257 264 232 250]\n",
      "(256,)\n",
      "[  31    9  149  158 -138   70 -124   -9   97 -193 -109 -134  276 -120\n",
      "  294  -19  282  -34   42  139  -11  227   20  -77    9   -4  -92  -28\n",
      "  -95   25  -88 -107   47   72   20 -103  137  -58  116 -112  -50  -85\n",
      "   70   82   50   91  104  111    3  129  153  123  250  113  -88  134\n",
      "   70   37  -55  -19  -54   16  -21   40 -135   89  -27  221  -64  117\n",
      "  -44 -108  111  -77  -99  276   45  -57  -58    9  162  159   -4 -192\n",
      "   67   27   96   42   82   -7  165  162  -21   31    8   43  -41 -160\n",
      "   78 -160  -13  186   22  -87  202   31  170  110   52   15   43  142\n",
      "  -45   42   94  127   49  -41  -83  -85   19  -87  -40 -162  -79  -41\n",
      "  216  -11  137   53  195 -116  -88   39   58   62  129   -9 -184 -163\n",
      "  133  -48   83  119  -24  214  129   53  119  -11  -77  106  -31  -39\n",
      "   90  -10    4  220  -37 -131    7  205  161   78   17 -143    5  109\n",
      "  115   -4  -63  107 -114   59   51  112   30  -53   50  -48  -15  102\n",
      "  -87 -114  152  -15  -97   84  -39 -175   -5   14  -28  -46   36   84\n",
      "   23   53   81   32   84   96   57  127  198  -41  -35   24  176  155\n",
      "  143  -34  -43   53  -43   84 -111  -58   56   99  222  110  -50   82\n",
      "  -13   23  -13 -134  -30  181   33  -11  -69   25  119 -128 -122   67\n",
      "  -25   65  -50 -125   94  201   28  -74   41 -235  -50  103 -163   63\n",
      "  -60  -25   68   91]\n",
      "[199  84  76  88  75  67 103  82  58 106 147 123 153 133 167 120 130  67\n",
      " 144  87 120  92 110 109  83 118 159  97 149  64 107  68  82 118  44  87\n",
      " 119 134  88 169 119  94  79 107 135 144 187 134  76  93 135 127 153 144\n",
      "  72 181  75 160 123 136 103  93 101  55  65 110 110 159  80 111 147  94\n",
      "  67  65  77 101  51  99 127  71  72  87 146 165  65 100  98  92  71 123\n",
      "  72 176 102  67 133  83 124 102 128  55  91 139 125 106 107 129 151 180\n",
      "  89 114  66 121  94  68 145 218 130 160  96 102 124  93 111 173  94  89\n",
      " 160 158  58  95 109  91  82  59 124  73  82  95 202 220 134 132 139  96\n",
      " 128 120 125 119  87 148  72  76 104  58  67 118  54 143 102 100  81 156\n",
      "  75 152 138  64 136  93 121 127  83 120 116  62 200 146  90  94  65 110\n",
      "  74  62  91 100  80  99  84 163  89  71 101  65 123 103  95 162  50  86\n",
      "  96 140  83  60  90 101 151  90  52  61  87 164 196 110  83  77  73  99\n",
      " 105 121 154  92 263 154  67 124  70  87 117 118  76 129 129  54  67 104\n",
      " 213 109 116  63  77  78 141 161  80  91  96  87  69  95  81 106 170 239\n",
      "  68 130  66 133]\n",
      "[265 259 245 257 240 233 222 239 238 269 241 241 256 264 254 264 242 233\n",
      " 281 246 271 274 255 227 238 259 249 261 274 235 255 245 220 258 241 264\n",
      " 232 236 260 240 295 255 246 259 274 233 250 261 235 244 252 251 253 260\n",
      " 248 257 254 302 267 249 244 225 254 224 236 239 230 270 260 242 247 240\n",
      " 239 248 255 250 229 241 263 245 254 242 266 242 226 245 260 236 237 282\n",
      " 232 252 253 230 258 242 239 240 243 240 224 297 264 275 236 291 253 296\n",
      " 252 215 242 264 274 233 282 248 253 227 260 261 251 268 273 247 227 247\n",
      " 278 248 227 240 262 235 222 220 235 222 243 245 260 263 252 266 218 260\n",
      " 241 242 292 252 237 242 244 223 247 236 234 240 238 252 257 220 257 268\n",
      " 238 269 263 225 227 239 241 240 238 265 261 235 262 275 247 271 215 252\n",
      " 224 224 257 231 230 256 247 274 244 216 226 230 242 260 228 252 232 252\n",
      " 255 268 244 222 245 283 255 241 230 243 260 281 237 237 227 229 222 224\n",
      " 249 260 266 249 263 261 211 257 233 216 258 275 219 257 257 232 221 249\n",
      " 252 219 236 240 224 232 266 237 248 255 256 247 268 243 249 254 252 301\n",
      " 254 260 223 279]\n",
      "(256,)\n",
      "[-30  -1   0  -4   8 -13  -5 -10  -4 -47  -1  15  -3   3  29  30  -8  -1\n",
      "  -1  -1   5   0 -29   2   0 -26  20  35  -6 -10  33  20   3  -1  -7 -30\n",
      "  -7  -4  23  -9   4 -27  -3  -1 -42 -11   0  28  -3   4  22 -10 -19 -27\n",
      " -16 -27 -29  -5  42 -17  21  -9  26  -1 -10   0 -15  23  25 -10 -26  14\n",
      "  11  -1 -33   7  -4  -3  20  -5   1  -4 -37  12  -9  -9  -4 -19  -5   7\n",
      "  -4 -13  22   1   0  -8  -8  -2  12  -4  -7  -1  17  31  -5  -1  22   5\n",
      "  23  -8  17  27  39  -6  32  27  -2  -1  20   1 -19  33  -2  26   1  12\n",
      "  -2  -2  -4  11  23  -5   2  -5  -8  -6   0   4  32   0  25   7  -5 -31\n",
      "  -1  -4   8  -5  -7  -4 -16  -6  12   0  -1  -7  -1  18  -1 -11 -31  34\n",
      "   0  20   0  -2  -8 -24  14 -20  -5  -6   0  -2  -1  -3 -20  40  -7  -5\n",
      "  -8  -7  29  -6  -6  19  21 -36  -4  -3  -5  -1   9  -6  -1  24   2  -4\n",
      "  24  29  -5  -7   2   3   2  -1  -5 -20 -27   5 -19  17   9   3 -17  -3\n",
      "  -3  -4 -36 -28   4 -10  -2 -26  11  -2  21  39  -6   4 -27 -12  -6  26\n",
      " -11  -9  -4  -1  -2  -2  22   9  -5   5 -33   1   4 -10  20  -4  27  -8\n",
      "   2 -32  -9  30]\n",
      "[4 2 1 2 0 2 0 1 0 6 0 1 2 2 7 4 1 0 1 1 1 2 4 0 1 3 3 5 2 1 5 2 0 1 1 4 1\n",
      " 0 4 1 2 2 2 1 7 2 2 5 0 1 5 2 4 5 2 3 4 3 6 2 2 1 4 1 1 1 2 4 2 2 3 2 1 1\n",
      " 4 2 1 1 3 1 1 1 7 1 1 2 1 2 1 1 1 2 2 1 1 1 0 1 1 1 1 2 4 7 1 2 3 1 3 1 2\n",
      " 4 8 1 6 8 1 0 3 2 3 5 1 3 2 1 2 1 1 1 4 1 0 0 1 1 1 2 5 1 5 2 1 6 0 2 2 2\n",
      " 1 1 2 1 2 1 0 1 1 3 2 1 5 7 0 2 1 0 1 3 3 4 1 2 1 0 1 3 2 6 1 1 1 0 4 1 1\n",
      " 2 2 8 1 0 0 0 1 2 1 5 0 2 3 4 1 1 1 2 1 1 0 2 3 1 3 3 1 0 2 1 1 1 7 3 1 3\n",
      " 0 4 1 0 3 9 1 2 3 1 1 4 3 1 1 0 0 1 3 0 1 2 5 1 2 1 3 2 3 3 2 6 1 4]\n",
      "[268 257 263 267 281 258 264 285 278 258 261 261 274 269 271 257 259 270\n",
      " 278 260 276 262 268 266 261 262 261 267 277 265 268 291 277 269 257 265\n",
      " 260 245 260 257 269 270 270 263 267 266 265 270 263 260 284 266 271 268\n",
      " 269 264 278 256 259 260 265 256 266 267 271 273 268 261 260 264 263 269\n",
      " 267 267 268 280 253 266 269 264 294 260 268 258 274 263 261 265 264 261\n",
      " 266 268 248 254 272 272 261 264 268 258 274 275 256 263 277 258 267 261\n",
      " 254 266 255 293 258 264 268 266 263 280 250 257 270 280 259 275 263 297\n",
      " 256 261 266 265 259 264 265 263 271 270 258 263 275 261 297 267 286 256\n",
      " 258 272 269 269 265 273 260 273 260 261 267 269 263 266 268 264 265 262\n",
      " 260 267 260 262 272 262 269 258 289 255 261 256 267 254 260 275 260 272\n",
      " 258 273 266 267 267 262 271 262 260 253 264 262 265 262 263 264 258 265\n",
      " 260 262 258 254 256 259 258 263 262 270 254 273 265 260 272 271 258 266\n",
      " 249 271 265 281 280 266 275 259 292 271 266 275 257 263 262 258 279 282\n",
      " 278 264 259 260 255 273 255 267 278 254 261 263 271 260 257 265 264 264\n",
      " 267 265 263 278]\n",
      "(256,)\n",
      "[ 130   51  109  -77  -79 -135  160  142  153   39  168  -24   17  216\n",
      "  185   16  190  235  150  139   -1 -110   41  264   14   94  -89  271\n",
      "  -65  209   64  136   93  -50  -98  -63  -29    6   54   75 -135  161\n",
      "  -20  260  -39   21  -90  -18  137  -18  156   92   70   91  282    7\n",
      "  -63  -32   76   73  145   73 -152  242  128  -14 -101  135  116  162\n",
      "  283 -121  249  306  -15  141  -85   39 -219  111   93  109  182    6\n",
      "   14  -57   -6   78 -130 -163   53   25 -146  -94  180  177   70  117\n",
      "  -97   -6  103  155  -46  127  -72   68    7   23 -170   98   51   79\n",
      "  -22   26    8  121  -42   47 -109  -38   71  -56  157  131    4  145\n",
      "   60  -30  281 -134  -32  202   55 -151   17  -48   86   75   59   -9\n",
      "   68  -13   84  -20   76   81   15    0  222  396  144    5  -51  -10\n",
      "   70  288  -16  200  269  237  262  165  -54  175   -3  109  -89  153\n",
      "   86   36  112 -107  -90   62  -66  157  -94  -33   39  172  138   25\n",
      "   89  -70  132  150   54   14  327   28  109  327  -56  281  114  -60\n",
      "   25  208  -71   84   78   48 -129   25   27 -186  -89  141 -147  115\n",
      "  118   24  309  190   46  142  -32  -80  115   37  118  164  -13  148\n",
      "   47   12 -129   33 -160 -104  -77 -131  149   54  158    4  162  -49\n",
      "  150 -110 -116   41   -5   19 -136  141   24   15  163  124 -216  -62\n",
      "  -93  204  104   88]\n",
      "[229 218 294 156 251 173 273 229 187 268 138 171 252 206 288 194 157 306\n",
      " 194 188 208 134 219 251 169 219 171 274 252 204 239 243 202 192 159 327\n",
      " 187 123 327 195 183 181 241 185 175 273 207 224 228 214 216 301 233 227\n",
      " 297 188 246 193 223 185 246 218 189 176 244 256 388 294 181 225 241 238\n",
      " 205 283 218 202 173 241 470 195 250 169 250 221 220 178 159 190 377 290\n",
      " 166 252  75 178 219 208 150 205 226 222 228 207 142 177 224 171 219 221\n",
      " 183 263 225 256 155 259 280 220 158 243 242 168 238 243 193 292 165 282\n",
      " 183 211 272 208 229 231 206 135 253 192 258 316 337 166 283 215 211 161\n",
      " 156 232 233 169 385 440 125 252 185 174 284 275 183 231 193 222 228 247\n",
      " 160 221 160 176 194 207 267 210 219 149 176 182 167 144 136 227 199 240\n",
      " 128 251 211 135 198 184 195 205 189 235 268 298 185 428 192 174 162 381\n",
      " 266 225 162 160  96 172 149 176 184 241 182 192 193 153 249 258 174 247\n",
      " 160 220 204 241 230 250 225 296 232 275 187 222 381 181 193 164 343 231\n",
      " 220 164 278 145 111 194 165 240 178 131 150 199 308 158 172 273 339 153\n",
      " 206 208 207 229]\n"
     ]
    }
   ],
   "source": [
    "for layer in mobilenetv1lite.layers:\n",
    "    if isinstance(layer,BatchNormalization):\n",
    "        # Get the weights\n",
    "        weights = layer.get_weights()\n",
    "        weights=ftf(weights)\n",
    "# Unpack the weights\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        print(gamma)\n",
    "        print(beta.shape)\n",
    "        print(moving_mean)\n",
    "        print(moving_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv1liteQuantized=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenetv1lite.layers[:-1]:\n",
    "    mobilenetv1liteQuantized.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m32,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m65,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,744</span> (491.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m125,744\u001b[0m (491.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,832</span> (479.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,832\u001b[0m (479.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,912</span> (11.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,912\u001b[0m (11.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobilenetv1liteQuantized.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\Documents\\\\GitHub\\\\CNN-ON-FPGA-MSc.-\\\\Training Model(Python)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:65\u001b[1;36m\u001b[0m\n\u001b[1;33m    //return res\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import ml_dtypes\n",
    "\n",
    "from keras.src import activations\n",
    "from keras.src import constraints\n",
    "from keras.src import dtype_policies\n",
    "from keras.src import initializers\n",
    "from keras.src import ops\n",
    "from keras.src import quantizers\n",
    "from keras.src import regularizers\n",
    "from keras.src.api_export import keras_export\n",
    "from keras.src.layers.input_spec import InputSpec\n",
    "from keras.src.layers.layer import Layer\n",
    "import numpy \n",
    "#@tf.custom_gradient\n",
    "def bitshift(weight,shift):\n",
    "  res=0\n",
    "  if shift<0:\n",
    "       y=tf.math.abs(shift)\n",
    "       res= tf.bitwise.right_shift(weight,y)\n",
    "  else:\n",
    "       res= tf.bitwise.left_shift(weight,shift)\n",
    "def MatrixBitShift(A,B):\n",
    "    #def grd(dy):\n",
    "     #   G=ops.matmult(dy,ops.transpose(D))\n",
    "      #  return G\n",
    "\n",
    "    A=tf.cast(A,tf.int32)\n",
    "    B=tf.cast(B,tf.int32)\n",
    "    columns2=tf.shape(B)[1]\n",
    "    rows2=tf.shape(B)[0]\n",
    "    rows1=tf.shape(A)[0]\n",
    "    C=tf.zeros(shape=(rows1,columns2),dtype=tf.int32)\n",
    "    for i in range(0,rows1):\n",
    "      for j in range(0,rows2):\n",
    "            for  k in range(0,columns2):\n",
    "                original=C[i][k]\n",
    "                a=A[i][j]\n",
    "                b=B[j][k]\n",
    "                x=bitshift(a,b)\n",
    "                #print(x)\n",
    "                update=original+x\n",
    "                \n",
    "                index=tf.constant([[i,k]])\n",
    "                #u=tf.constant([update],dtype=tf.int32)\n",
    "                C=tf.tensor_scatter_nd_update(C,index,[update])\n",
    "    \n",
    "    return C\n",
    "\n",
    "def Quantizeweights(weights):\n",
    "    #weights=weights.numpy()\n",
    "    weights_absolute=tf.abs(weights)\n",
    "    maxweight=tf.reduce_max(weights_absolute)\n",
    "    #print(maxweight)\n",
    "    scaled_weights=weights/maxweight\n",
    "    #print(scaled_weights)\n",
    "    lq=LQ(scaled_weights,4)\n",
    "    #print(f'aloha {lq}')\n",
    "    return lq\n",
    "#@tf.custom_gradient\n",
    "\n",
    " # def grad(dy):\n",
    "  #     dw=2**shift*dy\n",
    "   #    ds=2**shift*weight*tf.math.log(2)*dy\n",
    "    #   return dw,ds\n",
    "#return res\n",
    "    \n",
    "    #pot_vect=numpy.vectorize(powertwo)\n",
    "    #final_weights=pot_vect(lq,maxweight)\n",
    "    #print(final_weights)\n",
    "\n",
    "\n",
    "\n",
    "def check_integer_zero_and_first_two_decimals_zero(number):\n",
    "    # Check if the integer part is zero\n",
    "    if int(number) != 0:\n",
    "        return False\n",
    "    \n",
    "    # Convert the number to a string\n",
    "    num_str = str(number)\n",
    "    \n",
    "    # Find the decimal point\n",
    "    decimal_point_index = num_str.find('.')\n",
    "    \n",
    "    # Check if there is a decimal point and if the length after the decimal point is at least 2\n",
    "    if decimal_point_index != -1 and len(num_str) > decimal_point_index + 2:\n",
    "        # Get the first two decimal places\n",
    "        first_two_decimals = num_str[decimal_point_index + 1:decimal_point_index + 3]\n",
    "        # Check if the first two decimal places are \"00\"\n",
    "        return first_two_decimals == \"00\"\n",
    "    \n",
    "    # If there are no decimal places or less than two decimal places, return False\n",
    "    return False\n",
    "def clip(weight,bitwidth):\n",
    "    \n",
    "    weight_log=numpy.round(numpy.log2(numpy.absolute(weight)))\n",
    "    bit_pot=-2**bitwidth\n",
    "    if weight_log<bit_pot:\n",
    "        return 0\n",
    "    elif weight_log>=0:\n",
    "        return -1\n",
    "    else:\n",
    "        return weight_log\n",
    "def LQ(tensor, bitwidth):\n",
    "    # Create a mask for weights equal to 0\n",
    "    #rounded_tensor=tf.where(tensor>0,tf.my u4xdcvp]\n",
    "    # [6ath.floor(tensor),tf.math.ceil(tensor))\n",
    "    rounded_weights=tensor*100\n",
    "    rounded_weights=tf.where(rounded_weights>0,tf.math.floor(rounded_weights),tf.math.ceil(rounded_weights))\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    # Compute weight_log using log2\n",
    "    weight_log = tf.math.log(tf.math.abs(tensor)+epsilon) / tf.math.log(2.0)\n",
    "    #print(weight_log)\n",
    "    weight_log=tf.where(weight_log<0,tf.math.ceil(weight_log),tf.math.floor(weight_log))\n",
    "    bit_pot = -2 ** bitwidth\n",
    "    mask_condition = weight_log >= bit_pot\n",
    "    \n",
    "    # Initialize the result tensor with zeros\n",
    "    result = tf.zeros_like(tensor, dtype=tf.float32)\n",
    "    \n",
    "    # Apply the condition where weight_log is valid\n",
    "    result = tf.where(rounded_weights!=0,tf.where(mask_condition, tf.where(tensor > 0, tf.math.abs(weight_log), weight_log), result),result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def powertwo(weight,sf):\n",
    "    pot_weight=(2**weight)*sf\n",
    "    return pot_weight\n",
    "    \n",
    "\n",
    "class QDense(Layer):\n",
    "    \"\"\"Just your regular densely-connected NN layer with Quantized weights and bit shifting.\n",
    "\n",
    "    `Dense` implements the operation:\n",
    "    `output = activation(dot(input, kernel) + bias)`\n",
    "    where `activation` is the element-wise activation function\n",
    "    passed as the `activation` argument, `kernel` is a weights matrix\n",
    "    created by the layer, and `bias` is a bias vector created by the layer\n",
    "    (only applicable if `use_bias` is `True`).\n",
    "\n",
    "    Note: If the input to the layer has a rank greater than 2, `Dense`\n",
    "    computes the dot product between the `inputs` and the `kernel` along the\n",
    "    last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\n",
    "    For example, if input has dimensions `(batch_size, d0, d1)`, then we create\n",
    "    a `kernel` with shape `(d1, units)`, and the `kernel` operates along axis 2\n",
    "    of the `input`, on every sub-tensor of shape `(1, 1, d1)` (there are\n",
    "    `batch_size * d0` such sub-tensors). The output in this case will have\n",
    "    shape `(batch_size, d0, units)`.\n",
    "\n",
    "    Args:\n",
    "        units: Positive integer, dimensionality of the output space.\n",
    "        activation: Activation function to use.\n",
    "            If you don't specify anything, no activation is applied\n",
    "            (ie. \"linear\" activation: `a(x) = x`).\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "        kernel_initializer: Initializer for the `kernel` weights matrix.\n",
    "        bias_initializer: Initializer for the bias vector.\n",
    "        kernel_regularizer: Regularizer function applied to\n",
    "            the `kernel` weights matrix.\n",
    "        bias_regularizer: Regularizer function applied to the bias vector.\n",
    "        activity_regularizer: Regularizer function applied to\n",
    "            the output of the layer (its \"activation\").\n",
    "        kernel_constraint: Constraint function applied to\n",
    "            the `kernel` weights matrix.\n",
    "        bias_constraint: Constraint function applied to the bias vector.\n",
    "        lora_rank: Optional integer. If set, the layer's forward pass\n",
    "            will implement LoRA (Low-Rank Adaptation)\n",
    "            with the provided rank. LoRA sets the layer's kernel\n",
    "            to non-trainable and replaces it with a delta over the\n",
    "            original kernel, obtained via multiplying two lower-rank\n",
    "            trainable matrices. This can be useful to reduce the\n",
    "            computation cost of fine-tuning large dense layers.\n",
    "            You can also enable LoRA on an existing\n",
    "            `Dense` layer by calling `layer.enable_lora(rank)`.\n",
    "\n",
    "    Input shape:\n",
    "        N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
    "        The most common situation would be\n",
    "        a 2D input with shape `(batch_size, input_dim)`.\n",
    "\n",
    "    Output shape:\n",
    "        N-D tensor with shape: `(batch_size, ..., units)`.\n",
    "        For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
    "        the output would have shape `(batch_size, units)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        lora_rank=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_enabled = False\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        # We use `self._dtype_policy` to check to avoid issues in torch dynamo\n",
    "        is_quantized = isinstance(\n",
    "            self._dtype_policy, dtype_policies.QuantizedDTypePolicy\n",
    "        )\n",
    "        if is_quantized:\n",
    "            self.quantized_build(\n",
    "                input_shape, mode=self.dtype_policy.quantization_mode\n",
    "            )\n",
    "        if not is_quantized or self.dtype_policy.quantization_mode != \"int8\":\n",
    "            # If the layer is quantized to int8, `self._kernel` will be added\n",
    "            # in `self._int8_build`. Therefore, we skip it here.\n",
    "            self._kernel = self.add_weight(\n",
    "                name=\"kernel\",\n",
    "                shape=(input_dim, self.units),\n",
    "                initializer=self.kernel_initializer,\n",
    "                regularizer=self.kernel_regularizer,\n",
    "                constraint=self.kernel_constraint,\n",
    "            )\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                name=\"bias\",\n",
    "                shape=(self.units,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "            )\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        self.built = True\n",
    "        if self.lora_rank:\n",
    "            self.enable_lora(self.lora_rank)\n",
    "\n",
    "    @property\n",
    "    def kernel(self):\n",
    "        if not self.built:\n",
    "            raise AttributeError(\n",
    "                \"You must build the layer before accessing `kernel`.\"\n",
    "            )\n",
    "        if self.lora_enabled:\n",
    "            return self._kernel + ops.matmul(\n",
    "                self.lora_kernel_a, self.lora_kernel_b\n",
    "            )\n",
    "        return self._kernel\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        quantized_weights=Quantizeweights(self.kernel)\n",
    "        #x = ops.matmul(inputs, self.kernel)\n",
    "        x=MatrixBitShift(inputs,quantized_weights,self.kernel)\n",
    "        if self.bias is not None:\n",
    "            x = ops.add(x, self.bias)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def enable_lora(\n",
    "        self, rank, a_initializer=\"he_uniform\", b_initializer=\"zeros\"\n",
    "    ):\n",
    "        if self.kernel_constraint:\n",
    "            raise ValueError(\n",
    "                \"Lora is incompatible with kernel constraints. \"\n",
    "                \"In order to enable lora on this layer, remove the \"\n",
    "                \"`kernel_constraint` argument.\"\n",
    "            )\n",
    "        if not self.built:\n",
    "            raise ValueError(\n",
    "                \"Cannot enable lora on a layer that isn't yet built.\"\n",
    "            )\n",
    "        if self.lora_enabled:\n",
    "            raise ValueError(\n",
    "                \"lora is already enabled. \"\n",
    "                \"This can only be done once per layer.\"\n",
    "            )\n",
    "        self._tracker.unlock()\n",
    "        self.lora_kernel_a = self.add_weight(\n",
    "            name=\"lora_kernel_a\",\n",
    "            shape=(self.kernel.shape[0], rank),\n",
    "            initializer=initializers.get(a_initializer),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "        )\n",
    "        self.lora_kernel_b = self.add_weight(\n",
    "            name=\"lora_kernel_b\",\n",
    "            shape=(rank, self.kernel.shape[1]),\n",
    "            initializer=initializers.get(b_initializer),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "        )\n",
    "        self._kernel.trainable = False\n",
    "        self._tracker.lock()\n",
    "        self.lora_enabled = True\n",
    "        self.lora_rank = rank\n",
    "\n",
    "    def save_own_variables(self, store):\n",
    "        # Do nothing if the layer isn't yet built\n",
    "        if not self.built:\n",
    "            return\n",
    "        # The keys of the `store` will be saved as determined because the\n",
    "        # default ordering will change after quantization\n",
    "        kernel_value, kernel_scale = self._get_kernel_with_merged_lora()\n",
    "        target_variables = [kernel_value]\n",
    "        if self.use_bias:\n",
    "            target_variables.append(self.bias)\n",
    "        if isinstance(self.dtype_policy, dtype_policies.QuantizedDTypePolicy):\n",
    "            mode = self.dtype_policy.quantization_mode\n",
    "            if mode == \"int8\":\n",
    "                target_variables.append(kernel_scale)\n",
    "            elif mode == \"float8\":\n",
    "                target_variables.append(self.inputs_scale)\n",
    "                target_variables.append(self.inputs_amax_history)\n",
    "                target_variables.append(self.kernel_scale)\n",
    "                target_variables.append(self.kernel_amax_history)\n",
    "                target_variables.append(self.outputs_grad_scale)\n",
    "                target_variables.append(self.outputs_grad_amax_history)\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "                )\n",
    "        for i, variable in enumerate(target_variables):\n",
    "            store[str(i)] = variable\n",
    "\n",
    "    def load_own_variables(self, store):\n",
    "        if not self.lora_enabled:\n",
    "            self._check_load_own_variables(store)\n",
    "        # Do nothing if the layer isn't yet built\n",
    "        if not self.built:\n",
    "            return\n",
    "        # The keys of the `store` will be saved as determined because the\n",
    "        # default ordering will change after quantization\n",
    "        target_variables = [self._kernel]\n",
    "        if self.use_bias:\n",
    "            target_variables.append(self.bias)\n",
    "        if isinstance(self.dtype_policy, dtype_policies.QuantizedDTypePolicy):\n",
    "            mode = self.dtype_policy.quantization_mode\n",
    "            if mode == \"int8\":\n",
    "                target_variables.append(self.kernel_scale)\n",
    "            elif mode == \"float8\":\n",
    "                target_variables.append(self.inputs_scale)\n",
    "                target_variables.append(self.inputs_amax_history)\n",
    "                target_variables.append(self.kernel_scale)\n",
    "                target_variables.append(self.kernel_amax_history)\n",
    "                target_variables.append(self.outputs_grad_scale)\n",
    "                target_variables.append(self.outputs_grad_amax_history)\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "                )\n",
    "        for i, variable in enumerate(target_variables):\n",
    "            variable.assign(store[str(i)])\n",
    "        if self.lora_enabled:\n",
    "            self.lora_kernel_a.assign(ops.zeros(self.lora_kernel_a.shape))\n",
    "            self.lora_kernel_b.assign(ops.zeros(self.lora_kernel_b.shape))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        config = {\n",
    "            \"units\": self.units,\n",
    "            \"activation\": activations.serialize(self.activation),\n",
    "            \"use_bias\": self.use_bias,\n",
    "            \"kernel_initializer\": initializers.serialize(\n",
    "                self.kernel_initializer\n",
    "            ),\n",
    "            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n",
    "            \"kernel_regularizer\": regularizers.serialize(\n",
    "                self.kernel_regularizer\n",
    "            ),\n",
    "            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n",
    "            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n",
    "            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n",
    "        }\n",
    "        if self.lora_rank:\n",
    "            config[\"lora_rank\"] = self.lora_rank\n",
    "        return {**base_config, **config}\n",
    "\n",
    "    def _check_load_own_variables(self, store):\n",
    "        all_vars = self._trainable_variables + self._non_trainable_variables\n",
    "        if len(store.keys()) != len(all_vars):\n",
    "            if len(all_vars) == 0 and not self.built:\n",
    "                raise ValueError(\n",
    "                    f\"Layer '{self.name}' was never built \"\n",
    "                    \"and thus it doesn't have any variables. \"\n",
    "                    f\"However the weights file lists {len(store.keys())} \"\n",
    "                    \"variables for this layer.\\n\"\n",
    "                    \"In most cases, this error indicates that either:\\n\\n\"\n",
    "                    \"1. The layer is owned by a parent layer that \"\n",
    "                    \"implements a `build()` method, but calling the \"\n",
    "                    \"parent's `build()` method did NOT create the state of \"\n",
    "                    f\"the child layer '{self.name}'. A `build()` method \"\n",
    "                    \"must create ALL state for the layer, including \"\n",
    "                    \"the state of any children layers.\\n\\n\"\n",
    "                    \"2. You need to implement \"\n",
    "                    \"the `def build_from_config(self, config)` method \"\n",
    "                    f\"on layer '{self.name}', to specify how to rebuild \"\n",
    "                    \"it during loading. \"\n",
    "                    \"In this case, you might also want to implement the \"\n",
    "                    \"method that generates the build config at saving time, \"\n",
    "                    \"`def get_build_config(self)`. \"\n",
    "                    \"The method `build_from_config()` is meant \"\n",
    "                    \"to create the state \"\n",
    "                    \"of the layer (i.e. its variables) upon deserialization.\",\n",
    "                )\n",
    "            raise ValueError(\n",
    "                f\"Layer '{self.name}' expected {len(all_vars)} variables, \"\n",
    "                \"but received \"\n",
    "                f\"{len(store.keys())} variables during loading. \"\n",
    "                f\"Expected: {[v.name for v in all_vars]}\"\n",
    "            )\n",
    "\n",
    "    \"\"\"Quantization-related (int8 and float8) methods\"\"\"\n",
    "\n",
    "    QUANTIZATION_MODE_ERROR_TEMPLATE = (\n",
    "        f\"Invalid quantization mode. Expected one of \"\n",
    "        f\"{dtype_policies.QUANTIZATION_MODES}. \"\n",
    "        \"Received: quantization_mode={mode}\"\n",
    "    )\n",
    "\n",
    "    def quantized_build(self, input_shape, mode):\n",
    "        if mode == \"int8\":\n",
    "            input_dim = input_shape[-1]\n",
    "            kernel_shape = (input_dim, self.units)\n",
    "            self._int8_build(kernel_shape)\n",
    "        elif mode == \"float8\":\n",
    "            self._float8_build()\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "            )\n",
    "\n",
    "    def _int8_build(\n",
    "        self,\n",
    "        kernel_shape,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        kernel_scale_initializer=\"ones\",\n",
    "    ):\n",
    "        self.inputs_quantizer = quantizers.AbsMaxQuantizer(axis=-1)\n",
    "        self._kernel = self.add_weight(\n",
    "            name=\"kernel\",\n",
    "            shape=kernel_shape,\n",
    "            initializer=kernel_initializer,\n",
    "            dtype=\"int8\",\n",
    "            trainable=False,\n",
    "        )\n",
    "        self.kernel_scale = self.add_weight(\n",
    "            name=\"kernel_scale\",\n",
    "            shape=(self.units,),\n",
    "            initializer=kernel_scale_initializer,\n",
    "            trainable=False,\n",
    "        )\n",
    "        self._is_quantized = True\n",
    "\n",
    "    def _float8_build(self):\n",
    "        if not isinstance(\n",
    "            self.dtype_policy, dtype_policies.QuantizedFloat8DTypePolicy\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"`self.dtype_policy` must be the type of \"\n",
    "                f\"QuantizedFloat8DTypePolicy. Received {self.dtype_policy}\"\n",
    "            )\n",
    "        amax_history_length = self.dtype_policy.amax_history_length\n",
    "        # We set `trainable=True` because we will use the gradients to overwrite\n",
    "        # these variables\n",
    "        scale_kwargs = {\n",
    "            \"shape\": (),\n",
    "            \"initializer\": \"ones\",\n",
    "            \"dtype\": \"float32\",  # Always be float32\n",
    "            \"trainable\": True,\n",
    "            \"autocast\": False,\n",
    "        }\n",
    "        amax_history_kwargs = {\n",
    "            \"shape\": (amax_history_length,),\n",
    "            \"initializer\": \"zeros\",\n",
    "            \"dtype\": \"float32\",  # Always be float32\n",
    "            \"trainable\": True,\n",
    "            \"autocast\": False,\n",
    "        }\n",
    "        self.inputs_scale = self.add_weight(name=\"inputs_scale\", **scale_kwargs)\n",
    "        self.inputs_amax_history = self.add_weight(\n",
    "            name=\"inputs_amax_history\", **amax_history_kwargs\n",
    "        )\n",
    "        self.kernel_scale = self.add_weight(name=\"kernel_scale\", **scale_kwargs)\n",
    "        self.kernel_amax_history = self.add_weight(\n",
    "            name=\"kernel_amax_history\", **amax_history_kwargs\n",
    "        )\n",
    "        self.outputs_grad_scale = self.add_weight(\n",
    "            name=\"outputs_grad_scale\", **scale_kwargs\n",
    "        )\n",
    "        self.outputs_grad_amax_history = self.add_weight(\n",
    "            name=\"outputs_grad_amax_history\", **amax_history_kwargs\n",
    "        )\n",
    "        # We need to set `overwrite_with_gradient=True` to instruct the\n",
    "        # optimizer to directly overwrite these variables with their computed\n",
    "        # gradients during training\n",
    "        self.inputs_scale.overwrite_with_gradient = True\n",
    "        self.inputs_amax_history.overwrite_with_gradient = True\n",
    "        self.kernel_scale.overwrite_with_gradient = True\n",
    "        self.kernel_amax_history.overwrite_with_gradient = True\n",
    "        self.outputs_grad_scale.overwrite_with_gradient = True\n",
    "        self.outputs_grad_amax_history.overwrite_with_gradient = True\n",
    "        self._is_quantized = True\n",
    "\n",
    "    def quantized_call(self, inputs):\n",
    "        if self.dtype_policy.quantization_mode == \"int8\":\n",
    "            return self._int8_call(inputs)\n",
    "        elif self.dtype_policy.quantization_mode == \"float8\":\n",
    "            return self._float8_call(inputs)\n",
    "        else:\n",
    "            mode = self.dtype_policy.quantization_mode\n",
    "            raise NotImplementedError(\n",
    "                self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "            )\n",
    "\n",
    "    def _int8_call(self, inputs):\n",
    "        @ops.custom_gradient\n",
    "        def matmul_with_inputs_gradient(inputs, kernel, kernel_scale):\n",
    "            def grad_fn(*args, upstream=None):\n",
    "                if upstream is None:\n",
    "                    (upstream,) = args\n",
    "                float_kernel = ops.divide(\n",
    "                    ops.cast(kernel, dtype=self.compute_dtype),\n",
    "                    kernel_scale,\n",
    "                )\n",
    "                inputs_grad = ops.matmul(upstream, ops.transpose(float_kernel))\n",
    "                return (inputs_grad, None, None)\n",
    "\n",
    "            inputs, inputs_scale = self.inputs_quantizer(inputs)\n",
    "            x = ops.matmul(inputs, kernel)\n",
    "            # De-scale outputs\n",
    "            x = ops.cast(x, self.compute_dtype)\n",
    "            x = ops.divide(x, ops.multiply(inputs_scale, kernel_scale))\n",
    "            return x, grad_fn\n",
    "\n",
    "        x = matmul_with_inputs_gradient(\n",
    "            inputs,\n",
    "            ops.convert_to_tensor(self._kernel),\n",
    "            ops.convert_to_tensor(self.kernel_scale),\n",
    "        )\n",
    "        if self.lora_enabled:\n",
    "            lora_x = ops.matmul(inputs, self.lora_kernel_a)\n",
    "            lora_x = ops.matmul(lora_x, self.lora_kernel_b)\n",
    "            x = ops.add(x, lora_x)\n",
    "        if self.bias is not None:\n",
    "            x = ops.add(x, self.bias)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def _float8_call(self, inputs):\n",
    "        if self.lora_enabled:\n",
    "            raise NotImplementedError(\n",
    "                \"Currently, `_float8_call` doesn't support LoRA\"\n",
    "            )\n",
    "\n",
    "        @ops.custom_gradient\n",
    "        def quantized_dequantize_inputs(inputs, scale, amax_history):\n",
    "            new_scale = quantizers.compute_float8_scale(\n",
    "                ops.max(amax_history, axis=0),\n",
    "                scale,\n",
    "                ops.cast(\n",
    "                    float(ml_dtypes.finfo(\"float8_e4m3fn\").max), \"float32\"\n",
    "                ),\n",
    "            )\n",
    "            qdq_inputs = quantizers.quantize_and_dequantize(\n",
    "                inputs, scale, \"float8_e4m3fn\", self.compute_dtype\n",
    "            )\n",
    "            new_amax_history = quantizers.compute_float8_amax_history(\n",
    "                inputs, amax_history\n",
    "            )\n",
    "\n",
    "            def grad(*args, upstream=None, variables=None):\n",
    "                if upstream is None:\n",
    "                    (upstream,) = args\n",
    "                return upstream, new_scale, new_amax_history\n",
    "\n",
    "            return qdq_inputs, grad\n",
    "\n",
    "        @ops.custom_gradient\n",
    "        def quantized_dequantize_outputs(outputs, scale, amax_history):\n",
    "            \"\"\"Quantize-dequantize the output gradient but not the output.\"\"\"\n",
    "\n",
    "            def grad(*args, upstream=None, variables=None):\n",
    "                if upstream is None:\n",
    "                    (upstream,) = args\n",
    "                new_scale = quantizers.compute_float8_scale(\n",
    "                    ops.max(amax_history, axis=0),\n",
    "                    scale,\n",
    "                    ops.cast(\n",
    "                        float(ml_dtypes.finfo(\"float8_e5m2\").max), \"float32\"\n",
    "                    ),\n",
    "                )\n",
    "                qdq_upstream = quantizers.quantize_and_dequantize(\n",
    "                    upstream, scale, \"float8_e5m2\", self.compute_dtype\n",
    "                )\n",
    "                new_amax_history = quantizers.compute_float8_amax_history(\n",
    "                    upstream, amax_history\n",
    "                )\n",
    "                return qdq_upstream, new_scale, new_amax_history\n",
    "\n",
    "            return outputs, grad\n",
    "\n",
    "        x = ops.matmul(\n",
    "            quantized_dequantize_inputs(\n",
    "                inputs,\n",
    "                ops.convert_to_tensor(self.inputs_scale),\n",
    "                ops.convert_to_tensor(self.inputs_amax_history),\n",
    "            ),\n",
    "            quantized_dequantize_inputs(\n",
    "                ops.convert_to_tensor(self._kernel),\n",
    "                ops.convert_to_tensor(self.kernel_scale),\n",
    "                ops.convert_to_tensor(self.kernel_amax_history),\n",
    "            ),\n",
    "        )\n",
    "        # `quantized_dequantize_outputs` is placed immediately after\n",
    "        # `ops.matmul` for the sake of pattern matching in gemm_rewrite. That\n",
    "        # way, the qdq will be adjacent to the corresponding matmul_bprop in the\n",
    "        # bprop.\n",
    "        x = quantized_dequantize_outputs(\n",
    "            x,\n",
    "            ops.convert_to_tensor(self.outputs_grad_scale),\n",
    "            ops.convert_to_tensor(self.outputs_grad_amax_history),\n",
    "        )\n",
    "        if self.bias is not None:\n",
    "            # Under non-mixed precision cases, F32 bias has to be converted to\n",
    "            # BF16 first to get the biasAdd fusion support. ref. PR\n",
    "            # https://github.com/tensorflow/tensorflow/pull/60306\n",
    "            bias = self.bias\n",
    "            if self.dtype_policy.compute_dtype == \"float32\":\n",
    "                bias_bf16 = ops.cast(bias, \"bfloat16\")\n",
    "                bias = ops.cast(bias_bf16, bias.dtype)\n",
    "            x = ops.add(x, bias)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def quantize(self, mode):\n",
    "        import gc\n",
    "\n",
    "        # Prevent quantization of the subclasses\n",
    "        if type(self) is not Dense:\n",
    "            raise NotImplementedError(\n",
    "                f\"Layer {self.__class__.__name__} does not have a `quantize()` \"\n",
    "                \"method implemented.\"\n",
    "            )\n",
    "        self._check_quantize_args(mode, self.compute_dtype)\n",
    "\n",
    "        # Set new dtype policy\n",
    "        if not isinstance(\n",
    "            self.dtype_policy, dtype_policies.QuantizedDTypePolicy\n",
    "        ):\n",
    "            quantized_dtype = f\"{mode}_from_{self.dtype_policy.name}\"\n",
    "            # We set the internal `self._dtype_policy` instead of using the\n",
    "            # setter to avoid double `quantize` call\n",
    "            self._dtype_policy = dtype_policies.get(quantized_dtype)\n",
    "\n",
    "        self._tracker.unlock()\n",
    "        if mode == \"int8\":\n",
    "            # Quantize `self._kernel` to int8 and compute corresponding scale\n",
    "            kernel_value, kernel_scale = quantizers.abs_max_quantize(\n",
    "                self._kernel, axis=0\n",
    "            )\n",
    "            kernel_scale = ops.squeeze(kernel_scale, axis=0)\n",
    "            self._untrack_variable(self._kernel)\n",
    "            kernel_shape = self._kernel.shape\n",
    "            del self._kernel\n",
    "            # Utilize a lambda expression as an initializer to prevent adding a\n",
    "            # large constant to the computation graph.\n",
    "            self._int8_build(\n",
    "                kernel_shape,\n",
    "                lambda shape, dtype: kernel_value,\n",
    "                lambda shape, dtype: kernel_scale,\n",
    "            )\n",
    "        elif mode == \"float8\":\n",
    "            self._float8_build()\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "            )\n",
    "        self._tracker.lock()\n",
    "\n",
    "        # Release memory manually because sometimes the backend doesn't\n",
    "        gc.collect()\n",
    "\n",
    "    def _get_kernel_with_merged_lora(self):\n",
    "        if isinstance(self.dtype_policy, dtype_policies.QuantizedDTypePolicy):\n",
    "            kernel_value = self._kernel\n",
    "            kernel_scale = self.kernel_scale\n",
    "            if self.lora_enabled:\n",
    "                # Dequantize & quantize to merge lora weights into int8 kernel\n",
    "                # Note that this is a lossy compression\n",
    "                kernel_value = ops.divide(kernel_value, kernel_scale)\n",
    "                kernel_value = ops.add(\n",
    "                    kernel_value,\n",
    "                    ops.matmul(self.lora_kernel_a, self.lora_kernel_b),\n",
    "                )\n",
    "                kernel_value, kernel_scale = quantizers.abs_max_quantize(\n",
    "                    kernel_value, axis=0\n",
    "                )\n",
    "                kernel_scale = ops.squeeze(kernel_scale, axis=0)\n",
    "            return kernel_value, kernel_scale\n",
    "        return self.kernel, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv1liteQuantized.add(QDense(units=4,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ q_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QDense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m32,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m65,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ q_dense (\u001b[38;5;33mQDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,744</span> (491.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m125,744\u001b[0m (491.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,832</span> (479.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,832\u001b[0m (479.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,912</span> (11.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,912\u001b[0m (11.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobilenetv1liteQuantized.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenetv1liteQuantized.layers[:-1]:\n",
    "   layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ q_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QDense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m32,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m65,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ q_dense (\u001b[38;5;33mQDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,744</span> (491.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m125,744\u001b[0m (491.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,832</span> (479.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,832\u001b[0m (479.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,912</span> (11.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,912\u001b[0m (11.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobilenetv1liteQuantized.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv1liteQuantized.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"Air Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Enable eager execution\n",
    "tf.config.run_functions_eagerly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitshift2(weight,shift):\n",
    "    if shift<0:\n",
    "       y=tf.math.abs(shift)\n",
    "       return tf.bitwise.right_shift(weight,shift)\n",
    "    else:\n",
    "       return tf.bitwise.left_shift(weight,shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixBitShift(A,B):\n",
    "    A=tf.cast(A,tf.int32)\n",
    "    B=tf.cast(B,tf.int32)\n",
    "    columns2=tf.shape(B)[1]\n",
    "    rows2=tf.shape(B)[0]\n",
    "    rows1=tf.shape(A)[0]\n",
    "    print(rows1)\n",
    "    C=tf.zeros(shape=(rows1,columns2),dtype=tf.int32)\n",
    "    for i in range(0,rows1):\n",
    "      for j in range(0,rows2):\n",
    "            for  k in range(0,columns2):\n",
    "                original=C[i][k]\n",
    "                a=A[i][j]\n",
    "                b=B[j][k]\n",
    "                x=bitshift2(a,b)\n",
    "                #print(x)\n",
    "                update=original+x\n",
    "                \n",
    "                index=tf.constant([[i,k]])\n",
    "                #u=tf.constant([update],dtype=tf.int32)\n",
    "                C=tf.tensor_scatter_nd_update(C,index,[update])\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[14 14 14]\n",
      " [14 14 14]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[1, 1, 2, 3],[1,1,2,3]])\n",
    "tens2=tf.constant([[1,1,1],[1,1,1],[1,1,1],[1,1,1]])\n",
    "C=MatrixBitShift(tensor,tens2)\n",
    "print(C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

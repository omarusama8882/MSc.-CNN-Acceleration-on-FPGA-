{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense,Conv2D,MaxPool2D,Flatten,BatchNormalization,Reshape,InputLayer,GlobalAveragePooling2D,DepthwiseConv2D,Dropout,MaxPooling2D,ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='train'\n",
    "test_path='test'\n",
    "valid_path='valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"Air Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2244 images belonging to 4 classes.\n",
      "Found 120 images belonging to 4 classes.\n",
      "Found 120 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=train_path,target_size=(512,512),batch_size=32)\n",
    "valid_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=valid_path,target_size=(512,512),batch_size=4)\n",
    "test_batches=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=test_path,target_size=(512,512),batch_size=4,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile=tf.keras.applications.mobilenet.MobileNet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet v1Lite without Bitshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(InputLayer(shape=(512, 512, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv2d is a Conv2D layer with 8 filters and (2, 2) strides and (3, 3) kernel_size\n",
      "Layer conv_dw_1 is a DepthConv2D layer with  (1, 1) strides and (3, 3) kernel size\n",
      "Layer conv2d_1 is a Conv2D layer with 16 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "1\n",
      "Layer conv_dw_2 is a DepthConv2D layer with  (2, 2) strides and (3, 3) kernel size\n",
      "Layer conv2d_2 is a Conv2D layer with 32 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "Layer conv_dw_3 is a DepthConv2D layer with  (1, 1) strides and (3, 3) kernel size\n",
      "Layer conv2d_3 is a Conv2D layer with 32 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "1\n",
      "Layer conv_dw_4 is a DepthConv2D layer with  (2, 2) strides and (3, 3) kernel size\n",
      "Layer conv2d_4 is a Conv2D layer with 64 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "Layer conv_dw_5 is a DepthConv2D layer with  (1, 1) strides and (3, 3) kernel size\n",
      "Layer conv2d_5 is a Conv2D layer with 64 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "1\n",
      "Layer conv_dw_6 is a DepthConv2D layer with  (2, 2) strides and (3, 3) kernel size\n",
      "Layer conv2d_6 is a Conv2D layer with 128 filters and (1, 1) strides and (1, 1) kernel_size\n"
     ]
    }
   ],
   "source": [
    "for layer in mobile.layers[1:43]:\n",
    "     if isinstance(layer, Conv2D):\n",
    "        \n",
    "        #print(f'Layer {layer.name} is a Conv2D layer with {layer.filters} filters')\n",
    "        newfilters=(int)(layer.filters/4)\n",
    "        newlayer=Conv2D(newfilters, layer.kernel_size, strides=layer.strides,\n",
    "                      padding=layer.padding, activation=layer.activation,\n",
    "                      use_bias=layer.use_bias, kernel_initializer=layer.kernel_initializer,\n",
    "                      bias_initializer=layer.bias_initializer)\n",
    "        model.add(newlayer)\n",
    "        print(f'Layer {newlayer.name} is a Conv2D layer with {newlayer.filters} filters and {newlayer.strides} strides and {newlayer.kernel_size} kernel_size')\n",
    "     elif isinstance(layer, BatchNormalization) :\n",
    "        model.add(BatchNormalization(axis=getattr(layer, 'axis', -1),\n",
    "    momentum=getattr(layer, 'momentum', 0.99),\n",
    "    epsilon=getattr(layer, 'epsilon', 1e-3),\n",
    "    center=getattr(layer, 'center', True),\n",
    "    scale=getattr(layer, 'scale', True),\n",
    "    beta_initializer=getattr(layer, 'beta_initializer', 'zeros'),\n",
    "    gamma_initializer=getattr(layer, 'gamma_initializer', 'ones'),\n",
    "    moving_mean_initializer=getattr(layer, 'moving_mean_initializer', 'zeros'),\n",
    "    moving_variance_initializer=getattr(layer, 'moving_variance_initializer', 'ones'),\n",
    "    beta_regularizer=getattr(layer, 'beta_regularizer', None),\n",
    "    gamma_regularizer=getattr(layer, 'gamma_regularizer', None),\n",
    "    beta_constraint=getattr(layer, 'beta_constraint', None),\n",
    "    gamma_constraint=getattr(layer, 'gamma_constraint', None)))\n",
    "     elif isinstance(layer,DepthwiseConv2D):\n",
    "         print(f'Layer {layer.name} is a DepthConv2D layer with  {layer.strides} strides and {layer.kernel_size} kernel size')\n",
    "         model.add(DepthwiseConv2D(kernel_size=getattr(layer, 'kernel_size', (3, 3)),\n",
    "    strides=getattr(layer, 'strides', (1, 1)),\n",
    "    padding=getattr(layer, 'padding', 'valid'),\n",
    "    depth_multiplier=getattr(layer, 'depth_multiplier', 1),\n",
    "    activation=getattr(layer, 'activation', None),\n",
    "    use_bias=getattr(layer, 'use_bias', True),\n",
    "    bias_initializer=getattr(layer, 'bias_initializer', 'zeros'),\n",
    "    depthwise_initializer=getattr(layer, 'depthwise_initializer', 'glorot_uniform')\n",
    "))\n",
    "     #elif(isinstance(layer,DepthwiseConv2D)):\n",
    "        #     print('hellooooooooooo')\n",
    "       #      print(f'Layer {layer.name} is a DepthConv2D layer with  {layer.strides} strides')\n",
    "             #model.add(layer)\n",
    "     elif (isinstance(layer,ZeroPadding2D)):\n",
    "         print(1)\n",
    "\n",
    "     else:\n",
    "          #print(layer.name)\n",
    "          model.add(layer)\n",
    "     \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,400</span> (79.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,400\u001b[0m (79.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,280</span> (75.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,280\u001b[0m (75.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120</span> (4.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,120\u001b[0m (4.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Layer conv_dw_12 is a DepthConv2D layer with  (2, 2) strides and (3, 3) kernel size\n",
      "Layer conv2d_7 is a Conv2D layer with 256 filters and (1, 1) strides and (1, 1) kernel_size\n",
      "Layer conv_dw_13 is a DepthConv2D layer with  (1, 1) strides and (3, 3) kernel size\n",
      "Layer conv2d_8 is a Conv2D layer with 256 filters and (1, 1) strides and (1, 1) kernel_size\n"
     ]
    }
   ],
   "source": [
    "for layer in mobile.layers[73:86]:\n",
    "     if isinstance(layer, Conv2D):\n",
    "        \n",
    "        #print(f'Layer {layer.name} is a Conv2D layer with {layer.filters} filters')\n",
    "        newfilters=(int)(layer.filters/4)\n",
    "        newlayer=Conv2D(newfilters, layer.kernel_size, strides=layer.strides,\n",
    "                      padding=layer.padding, activation=layer.activation,\n",
    "                      use_bias=layer.use_bias, kernel_initializer=layer.kernel_initializer,\n",
    "                      bias_initializer=layer.bias_initializer)\n",
    "        model.add(newlayer)\n",
    "        print(f'Layer {newlayer.name} is a Conv2D layer with {newlayer.filters} filters and {newlayer.strides} strides and {newlayer.kernel_size} kernel_size')\n",
    "     elif isinstance(layer, BatchNormalization) :\n",
    "        model.add(BatchNormalization(axis=getattr(layer, 'axis', -1),\n",
    "    momentum=getattr(layer, 'momentum', 0.99),\n",
    "    epsilon=getattr(layer, 'epsilon', 1e-3),\n",
    "    center=getattr(layer, 'center', True),\n",
    "    scale=getattr(layer, 'scale', True),\n",
    "    beta_initializer=getattr(layer, 'beta_initializer', 'zeros'),\n",
    "    gamma_initializer=getattr(layer, 'gamma_initializer', 'ones'),\n",
    "    moving_mean_initializer=getattr(layer, 'moving_mean_initializer', 'zeros'),\n",
    "    moving_variance_initializer=getattr(layer, 'moving_variance_initializer', 'ones'),\n",
    "    beta_regularizer=getattr(layer, 'beta_regularizer', None),\n",
    "    gamma_regularizer=getattr(layer, 'gamma_regularizer', None),\n",
    "    beta_constraint=getattr(layer, 'beta_constraint', None),\n",
    "    gamma_constraint=getattr(layer, 'gamma_constraint', None)))\n",
    "     elif isinstance(layer,DepthwiseConv2D):\n",
    "         print(f'Layer {layer.name} is a DepthConv2D layer with  {layer.strides} strides and {layer.kernel_size} kernel size')\n",
    "\n",
    "         model.add(DepthwiseConv2D(kernel_size=getattr(layer, 'kernel_size', (3, 3)),\n",
    "    strides=getattr(layer, 'strides', (1, 1)),\n",
    "    padding=getattr(layer, 'padding', 'valid'),\n",
    "    depth_multiplier=getattr(layer, 'depth_multiplier', 1),\n",
    "    activation=getattr(layer, 'activation', None),\n",
    "    use_bias=getattr(layer, 'use_bias', True),\n",
    "    bias_initializer=getattr(layer, 'bias_initializer', 'zeros'),\n",
    "    depthwise_initializer=getattr(layer, 'depthwise_initializer', 'glorot_uniform')\n",
    "))\n",
    "     elif (isinstance(layer,ZeroPadding2D)):\n",
    "         print(1) \n",
    "     else:\n",
    "         model.add(layer)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GlobalAveragePooling2D(name='global_average_pooling2d'))\n",
    "model.add(Dense(units=4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m32,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m65,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,028\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,772</span> (495.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m126,772\u001b[0m (495.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,860</span> (483.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,860\u001b[0m (483.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,912</span> (11.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,912\u001b[0m (11.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=train_batches,validation_data=valid_batches,epochs=20,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Documents\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 - 253s - 4s/step - accuracy: 0.6872 - loss: 0.7596 - val_accuracy: 0.2500 - val_loss: 1.5832\n",
      "Epoch 2/20\n",
      "71/71 - 221s - 3s/step - accuracy: 0.7736 - loss: 0.5615 - val_accuracy: 0.2500 - val_loss: 2.1149\n",
      "Epoch 3/20\n",
      "71/71 - 223s - 3s/step - accuracy: 0.7981 - loss: 0.4750 - val_accuracy: 0.2500 - val_loss: 2.7135\n",
      "Epoch 4/20\n",
      "71/71 - 225s - 3s/step - accuracy: 0.8191 - loss: 0.4346 - val_accuracy: 0.2500 - val_loss: 3.4659\n",
      "Epoch 5/20\n",
      "71/71 - 219s - 3s/step - accuracy: 0.8258 - loss: 0.4037 - val_accuracy: 0.2500 - val_loss: 3.5441\n",
      "Epoch 6/20\n",
      "71/71 - 224s - 3s/step - accuracy: 0.8373 - loss: 0.3888 - val_accuracy: 0.2500 - val_loss: 3.6216\n",
      "Epoch 7/20\n",
      "71/71 - 220s - 3s/step - accuracy: 0.8454 - loss: 0.3495 - val_accuracy: 0.2917 - val_loss: 3.0772\n",
      "Epoch 8/20\n",
      "71/71 - 229s - 3s/step - accuracy: 0.8614 - loss: 0.3237 - val_accuracy: 0.6083 - val_loss: 0.9164\n",
      "Epoch 9/20\n",
      "71/71 - 207s - 3s/step - accuracy: 0.8739 - loss: 0.2971 - val_accuracy: 0.7417 - val_loss: 0.6955\n",
      "Epoch 10/20\n",
      "71/71 - 207s - 3s/step - accuracy: 0.8694 - loss: 0.3021 - val_accuracy: 0.8250 - val_loss: 0.5788\n",
      "Epoch 11/20\n",
      "71/71 - 204s - 3s/step - accuracy: 0.8926 - loss: 0.2610 - val_accuracy: 0.8750 - val_loss: 0.4609\n",
      "Epoch 12/20\n",
      "71/71 - 204s - 3s/step - accuracy: 0.8980 - loss: 0.2601 - val_accuracy: 0.8417 - val_loss: 0.4376\n",
      "Epoch 13/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9086 - loss: 0.2405 - val_accuracy: 0.8750 - val_loss: 0.3529\n",
      "Epoch 14/20\n",
      "71/71 - 204s - 3s/step - accuracy: 0.9193 - loss: 0.2231 - val_accuracy: 0.8583 - val_loss: 0.4643\n",
      "Epoch 15/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9135 - loss: 0.2303 - val_accuracy: 0.8667 - val_loss: 0.3355\n",
      "Epoch 16/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9140 - loss: 0.2391 - val_accuracy: 0.8667 - val_loss: 0.4559\n",
      "Epoch 17/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9251 - loss: 0.1934 - val_accuracy: 0.8833 - val_loss: 0.3400\n",
      "Epoch 18/20\n",
      "71/71 - 198s - 3s/step - accuracy: 0.9434 - loss: 0.1612 - val_accuracy: 0.9083 - val_loss: 0.4399\n",
      "Epoch 19/20\n",
      "71/71 - 204s - 3s/step - accuracy: 0.9452 - loss: 0.1510 - val_accuracy: 0.7333 - val_loss: 1.5938\n",
      "Epoch 20/20\n",
      "71/71 - 203s - 3s/step - accuracy: 0.9510 - loss: 0.1330 - val_accuracy: 0.8917 - val_loss: 0.4912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25f8f1172f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,validation_data=valid_batches,epochs=20,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(x=test_batches,verbose=0)\n",
    "rounded_pred=np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=np.argmax(rounded_pred,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.66666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "test_labels=test_batches.classes\n",
    "\n",
    "f1_micro = f1_score(test_labels, predict,average='micro')\n",
    "f1_micro*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mobilenetv1lite\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mobilenetv1lite\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'mobilenetv1lite'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name='keras_tensor_91')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2609415171024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415172368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415171216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415172176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415172560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415174288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415174096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415175056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415174864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415173712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415176016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445913040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445912848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415175248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445912656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445914384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445913616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445915536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445915344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445913424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445914960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445917072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445915728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445916880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445916688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445918416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445919952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445918800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445920144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445919760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445923408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445925136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445924368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445925328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609445924176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446781392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446783120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446782736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446783312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446782928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446785616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446787152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446785808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446788112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446788880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609415171408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446788496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446789840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446783696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446789072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446790800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446790032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446792912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446786960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446791952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446790608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446792336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446793104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446787344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446794448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446793872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446785424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446796752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446796176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446794256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446794832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454481872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454481488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454482832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609446795792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454481680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454483408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454482448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454484560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454482256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454483024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454483984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454486288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454484752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454486096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454485520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454486672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2609454487824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export('mobilenetv1lite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mobilenetv1lite.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet v1 Lite with bitshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "mobilenetv1lite=load_model('mobilenetv1lite.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16436005, -0.15154105, -0.18714835,  0.06735396],\n",
       "       [ 0.02512901, -0.07903466,  0.08077965, -0.1139873 ],\n",
       "       [ 0.15105017,  0.03615137,  0.06673397, -0.05782771],\n",
       "       ...,\n",
       "       [ 0.09227933,  0.06480524,  0.16097234, -0.02970978],\n",
       "       [ 0.07203227, -0.0595542 , -0.03374214, -0.13438588],\n",
       "       [ 0.1369904 ,  0.12464586, -0.1388945 , -0.16122779]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_weights=mobilenetv1lite.layers[-1].get_weights()[0]\n",
    "dense_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantizeweights(weights):\n",
    "    #weights=weights.numpy()\n",
    "    weights_absolute=tf.abs(weights)\n",
    "    maxweight=tf.reduce_max(weights_absolute)\n",
    "    #print(maxweight)\n",
    "    scaled_weights=weights/maxweight\n",
    "    #print(scaled_weights)\n",
    "    lq=LQ(scaled_weights,16)\n",
    "    #print(f'aloha {lq}')\n",
    "    return lq\n",
    "def LQ(tensor, bitwidth):\n",
    "    # Create a mask for weights equal to 0\n",
    "    #rounded_tensor=tf.where(tensor>0,tf.my u4xdcvp]\n",
    "    # [6ath.floor(tensor),tf.math.ceil(tensor))\n",
    "    rounded_weights=tensor*100\n",
    "    rounded_weights=tf.where(rounded_weights>0,tf.math.floor(rounded_weights),tf.math.ceil(rounded_weights))\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    # Compute weight_log using log2\n",
    "    weight_log = tf.math.log(tf.math.abs(tensor)+epsilon) / tf.math.log(2.0)\n",
    "    #print(weight_log)\n",
    "    weight_log=tf.where(weight_log<0,tf.math.ceil(weight_log),tf.math.floor(weight_log))\n",
    "    bit_pot = -2 ** bitwidth\n",
    "    mask_condition = weight_log >= bit_pot\n",
    "    \n",
    "    # Initialize the result tensor with zeros\n",
    "    result = tf.zeros_like(tensor, dtype=tf.float32)\n",
    "    \n",
    "    # Apply the condition where weight_log is valid\n",
    "    result = tf.where(rounded_weights!=0,tf.where(mask_condition, tf.where(tensor > 0, tf.math.abs(weight_log), weight_log), result),result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_dense_weights=Quantizeweights(dense_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -0., -0.,  2.],\n",
       "       [ 3., -1.,  1., -1.],\n",
       "       [ 0.,  3.,  2., -2.],\n",
       "       ...,\n",
       "       [ 1.,  2.,  0., -3.],\n",
       "       [ 2., -2., -3., -1.],\n",
       "       [ 1.,  1., -1., -0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_dense_weights=quantized_dense_weights.numpy()\n",
    "quantized_dense_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  2],\n",
       "       [ 3, -1,  1, -1],\n",
       "       [ 0,  3,  2, -2],\n",
       "       ...,\n",
       "       [ 1,  2,  0, -3],\n",
       "       [ 2, -2, -3, -1],\n",
       "       [ 1,  1, -1,  0]], dtype=int16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qds_int=quantized_dense_weights.astype(np.int16)\n",
    "qds_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3,  0, ...,  1,  2,  1],\n",
       "       [ 0, -1,  3, ...,  2, -2,  1],\n",
       "       [ 0,  1,  2, ...,  0, -3, -1],\n",
       "       [ 2, -1, -2, ..., -3, -1,  0]], dtype=int16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_dense_weights_transp=np.transpose(qds_int)\n",
    "quantized_dense_weights_transp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  0, ..., -3, -1,  0], dtype=int16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_dense=quantized_dense_weights_transp.flatten()\n",
    "flattened_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0x3'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(flattened_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_twos_complement_hex(x, bit_width=4):\n",
    "    if x >= 0:\n",
    "        return format(x, 'x')  # Hexadecimal without '0x' prefix\n",
    "    else:\n",
    "        return format((1 << bit_width) + x, 'x')  # Two's complement hex without '0x' prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00ff\n",
      "ff01\n"
     ]
    }
   ],
   "source": [
    "def int16_to_hex(value):\n",
    "    # Check if the input is within the range of a signed 16-bit integer\n",
    "    if not -32768 <= value <= 32767:\n",
    "        raise ValueError(\"Value must be a 16-bit signed integer.\")\n",
    "    \n",
    "    # Handle negative numbers using two's complement\n",
    "    if value < 0:\n",
    "        value = (1 << 16) + value\n",
    "    \n",
    "    # Convert to hexadecimal without '0x' and return\n",
    "    return format(value, '04x')\n",
    "\n",
    "# Example usage\n",
    "print(int16_to_hex(255))   # Output: '00ff'\n",
    "print(int16_to_hex(-255))  # Output: '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0010'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int16_to_hex(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_twos_complement_hex(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '3', '0', ..., 'd', 'f', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_hex=np.vectorize(int_to_twos_complement_hex)\n",
    "hex_dense=v_hex(flattened_dense)\n",
    "hex_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dense_weights.txt', 'w') as cf:\n",
    "\n",
    " \n",
    " np.savetxt(cf,hex_dense,delimiter=\" \",fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"weights.txt\", qds_int, delimiter=\" \", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00117536,  0.00042983,  0.00199678,  0.00135183], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_bias=mobilenetv1lite.layers[-1].get_weights()[1]\n",
    "dense_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float32_to_fixed16(value, fractional_bits=8):\n",
    "    # Scale by 2^fractional_bits\n",
    "    scaled_value = value * (2 ** fractional_bits)\n",
    "    \n",
    "    # Round to the nearest integer\n",
    "    fixed_value = np.round(scaled_value).astype(np.int16)\n",
    "    \n",
    "    # Handle overflow (for 16-bit signed integers)\n",
    "    #max_val = 2**15 - 1\n",
    "    #min_val = -2**15\n",
    "    #fixed_value = np.clip(fixed_value, min_val, max_val)\n",
    "    \n",
    "    return fixed_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftf=np.vectorize(float32_to_fixed16)\n",
    "\n",
    "#np.savetxt(\"weights.txt\", d_bias, delimiter=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0], dtype=int16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_dense_bias=ftf(dense_bias)\n",
    "fixed_dense_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '1', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_bias=v_hex(fixed_dense_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,layer in enumerate(mobilenetv1lite.layers):\n",
    "    if isinstance(layer,Conv2D):\n",
    "        if layer.use_bias==True:\n",
    "            print(i)\n",
    "            x=np.array(layer.get_weights())\n",
    "            y=ftf(x)\n",
    "            print(x.shape)\n",
    "            print(f'weights {y}')\n",
    "        \n",
    "            #print(f'biases {layer.get_weights()[1]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hayhay\n",
      "(1, 3, 3, 8, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 16, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 32, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 32, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 64, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 64, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 128, 1)\n",
      "hayhay\n",
      "(1, 3, 3, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(mobilenetv1lite.layers):\n",
    "    if isinstance(layer,DepthwiseConv2D):\n",
    "        if layer.use_bias==False:\n",
    "            print('hayhay')\n",
    "            x=np.array(layer.get_weights())\n",
    "            #y=ftf(x)\n",
    "            print(x.shape)\n",
    "        else:\n",
    "           print('hoyhoy')\n",
    "           x=np.array(layer.get_weights()[0])\n",
    "           y=np.array(layer.get_weights()[1])\n",
    "           print(x.shape)\n",
    "           print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            #print(f'weights {y}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.39815469, 0.99627766, 0.41200907],\n",
       "         [0.38045931, 0.84076123, 0.54737021],\n",
       "         [0.88087134, 0.39220301, 0.02442792]],\n",
       "\n",
       "        [[0.44587056, 0.26718626, 0.40811024],\n",
       "         [0.43431054, 0.52770571, 0.8402363 ],\n",
       "         [0.793959  , 0.45506952, 0.1813199 ]],\n",
       "\n",
       "        [[0.43665474, 0.74319419, 0.52152409],\n",
       "         [0.20976816, 0.51436807, 0.06489828],\n",
       "         [0.01785718, 0.90446216, 0.30138552]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_5d = np.random.rand(1, 3, 3, 3, 8)\n",
    "#print(array_5d)\n",
    "array_5d[:,:,:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1360771 , 0.91484703, 0.68370063],\n",
       "       [0.99255511, 0.09345574, 0.90563285],\n",
       "       [0.83811493, 0.54655643, 0.33519357]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=array_5d[:,:,:,1,0]\n",
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dw2d_weights.txt', 'w') as cf:\n",
    "\n",
    "          for i in range(0,array_5d.shape[3]):\n",
    "            weights=array_5d[:,:,:,i,0]\n",
    "            weights=np.array(weights)\n",
    "            np.savetxt(cf,weights[0],delimiter=\" \",fmt=\"%d\")\n",
    "            cf.write(\"\\n...\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conv2d_weights.txt', 'w') as cf:\n",
    "        for i, layer in enumerate(mobilenetv1lite.layers):\n",
    "                if isinstance(layer,Conv2D):\n",
    "                     if layer.use_bias==False:\n",
    "                            weights=np.array(layer.get_weights())\n",
    "                            fixed_weights=ftf(weights)\n",
    "                            cf.write(f'{fixed_weights.shape}\\n')\n",
    "                            for j in range(fixed_weights.shape[4]):\n",
    "                                    kernel=fixed_weights[:,:,:,:,j]\n",
    "                                    for j in range(0,fixed_weights.shape[1]):\n",
    "                                           \n",
    "                                           np.savetxt(cf,kernel[0][j],delimiter=\" \",fmt=\"%d\")\n",
    "                                    cf.write('\\n')\n",
    "\n",
    "                     #else:\n",
    "                      #      weights=np.array(layer.get_weights()[0])\n",
    "                       #     fixed_weights=ftf(weights)\n",
    "                        #    cf.write(f'{fixed_weights.shape}\\n')\n",
    "                         #   np.savetxt(cf,fixed_weights,delimiter=\" \", fmt=\"%d\")\n",
    "                          #  cf.write('\\n')\n",
    "                           # biases=np.array(layer.get_weights()[1])\n",
    "                            #fixed_biases=ftf(biases)\n",
    "                            #cf.write(f'{fixed_biases.shape}\\n')\n",
    "                            #np.savetxt(cf,fixed_biases,delimiter=\" \", fmt=\"%d\")\n",
    "                            #cf.write('\\n---\\n')\n",
    "                            \n",
    "\n",
    "                \n",
    "                            \n",
    "                     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dw2d_weights.txt', 'w') as cf:\n",
    "        for i, layer in enumerate(mobilenetv1lite.layers):\n",
    "                if isinstance(layer,DepthwiseConv2D):\n",
    "                     if layer.use_bias==False:\n",
    "                            weights=np.array(layer.get_weights())\n",
    "                            fixed_weights=ftf(weights)\n",
    "                            cf.write(f'{fixed_weights.shape}\\n')\n",
    "                            for j in range(fixed_weights.shape[3]):\n",
    "                                    kernel=fixed_weights[:,:,:,j,0]\n",
    "                                    np.savetxt(cf,kernel[0],delimiter=\" \",fmt=\"%d\")\n",
    "                                    cf.write('\\n')\n",
    "                                                                              \n",
    "                            \n",
    "                            cf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dense_biases.txt', 'w') as cf:\n",
    "\n",
    " dense=mobilenetv1lite.layers[-1]\n",
    " dense_b=dense.get_weights()[1]\n",
    " fixed_point_densebiases=ftf(dense_b)\n",
    " np.savetxt(cf,[fixed_point_densebiases],delimiter=\" \",fmt=\"%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_vec=np.vectorize(int16_to_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean= 0.24495433\n",
      "gamma= 1.0273736\n",
      "maxgvc= 9.535793\n",
      "mingvc= 2.0916414\n",
      "maxgmbvc= 0.7149915\n",
      "mingmbvc= -0.5885011\n",
      "['10bc' '4c49' '202c' '1eb3' '37f4' '1353' '306c' '1aaf']\n",
      "mean= 0.36294523\n",
      "gamma= 1.0741372\n",
      "maxgvc= 15.418801\n",
      "mingvc= 1.83548\n",
      "maxgmbvc= 0.72245985\n",
      "mingmbvc= -0.6707628\n",
      "['40be' '1aac' '41cf' '0eaf' '2ec4' '7b5a' '2c45' '146d']\n",
      "mean= 0.46409115\n",
      "gamma= 1.1039228\n",
      "maxgvc= 3.7414162\n",
      "mingvc= 1.6543442\n",
      "maxgmbvc= 1.599596\n",
      "mingmbvc= -1.1633953\n",
      "['1518' '15b9' '1dee' '14fb' '1646' '1133' '1da2' '1761' '1115' '0ec5'\n",
      " '0e5b' '127a' '11d4' '10c2' '0d3c' '16b5']\n",
      "mean= 0.10072251\n",
      "gamma= 1.0549612\n",
      "maxgvc= 9.469972\n",
      "mingvc= 3.342732\n",
      "maxgmbvc= 0.78563905\n",
      "mingmbvc= -0.5959974\n",
      "['30cd' '1abe' '2389' '1e81' '4bc3' '2bde' '312a' '26c5' '424d' '1f5d'\n",
      " '27ac' '293d' '4701' '247b' '46fc' '271b']\n",
      "mean= 0.48349205\n",
      "gamma= 1.0655665\n",
      "maxgvc= 3.306471\n",
      "mingvc= 1.650026\n",
      "maxgmbvc= 1.0924006\n",
      "mingmbvc= -1.2249463\n",
      "['1115' '114c' '11c8' '1258' '1a74' '1062' '1269' '0f82' '0dab' '1489'\n",
      " '16ae' '0ebf' '102e' '0dfa' '10e2' '1258' '1120' '0ffd' '0f6f' '0f0d'\n",
      " '1176' '0dc4' '13a0' '13f4' '12dc' '11ae' '0e17' '0f50' '16ca' '0d33'\n",
      " '0fea' '10d1']\n",
      "mean= 0.15252136\n",
      "gamma= 1.086758\n",
      "maxgvc= 12.201404\n",
      "mingvc= 3.7071393\n",
      "maxgmbvc= 1.2387226\n",
      "mingmbvc= -1.0312823\n",
      "['386e' '25de' '483f' '432f' '28ef' '2dad' '40bb' '1da8' '2cff' '2cab'\n",
      " '3c85' '4c6d' '29ac' '57a7' '5111' '387c' '34b7' '518c' '2702' '4181'\n",
      " '38b0' '3eec' '2d9f' '29b6' '3989' '2811' '4ab5' '5117' '4406' '619c'\n",
      " '2f1d' '3da9']\n",
      "mean= 0.8428876\n",
      "gamma= 1.1650566\n",
      "maxgvc= 1.9136187\n",
      "mingvc= 1.1474444\n",
      "maxgmbvc= 1.4310113\n",
      "mingmbvc= -1.4402114\n",
      "['096c' '0cb6' '0d60' '0c56' '0aff' '0a7b' '0e6b' '0c84' '0cfe' '0c63'\n",
      " '0bf5' '097e' '0ade' '0a94' '0d6f' '0e72' '0ba8' '0b18' '092e' '0cc9'\n",
      " '0df5' '0c5b' '0a93' '0ac8' '0d85' '0a98' '09c4' '0e18' '0c2e' '0dad'\n",
      " '0f4f' '0c97']\n",
      "mean= 0.23006238\n",
      "gamma= 1.164093\n",
      "maxgvc= 9.5729685\n",
      "mingvc= 3.3803244\n",
      "maxgmbvc= 1.2396561\n",
      "mingmbvc= -1.0296634\n",
      "['4c95' '2f33' '2e2f' '4b98' '2fea' '3acc' '1b0b' '2a81' '2192' '4196'\n",
      " '3beb' '349f' '416e' '4237' '464d' '36b0' '3553' '2731' '3516' '2daa'\n",
      " '2017' '3690' '1e9b' '326a' '2cdc' '45ff' '23bd' '3c3f' '2923' '3083'\n",
      " '30fb' '3036']\n",
      "mean= 0.52958447\n",
      "gamma= 1.0947859\n",
      "maxgvc= 2.5655248\n",
      "mingvc= 1.0748637\n",
      "maxgmbvc= 1.0476748\n",
      "mingmbvc= -0.85796463\n",
      "['11ce' '108e' '0ae0' '0d8f' '0992' '0ff9' '0ca5' '0efa' '0e4e' '0f23'\n",
      " '0ee9' '0de7' '1211' '105a' '1259' '1303' '0c7f' '0d80' '0e67' '0ae2'\n",
      " '1313' '104a' '1141' '111a' '0899' '0b36' '0de2' '10fd' '0da7' '0b4e'\n",
      " '0eb5' '11b9' '1194' '13ad' '11bc' '0cb5' '1139' '0fb4' '0eab' '1056'\n",
      " '108d' '0b21' '0b20' '0bdc' '122b' '0b2e' '109a' '0bbf' '0d2d' '1141'\n",
      " '0bd5' '0d27' '0d95' '1486' '0ea1' '11ad' '09a8' '11e2' '0c83' '136b'\n",
      " '0ae4' '1007' '0f24' '1177']\n",
      "mean= 0.19770198\n",
      "gamma= 1.0883875\n",
      "maxgvc= 17.260092\n",
      "mingvc= 3.314729\n",
      "maxgmbvc= 1.2659299\n",
      "mingmbvc= -1.0685539\n",
      "['50ea' '4f31' '1a85' '3792' '4964' '28ad' '8946' '290c' '4014' '497a'\n",
      " '3330' '3e54' '46e6' '2a94' '2dbd' '3daf' '3b5a' '553a' '4791' '300e'\n",
      " '2e17' '2527' '3b23' '59e5' '8a15' '4625' '3df8' '2286' '3bfd' '26c5'\n",
      " '45f3' '5530' '45cc' '4359' '46ae' '34f5' '3762' '5898' '3d74' '2b97'\n",
      " '36ad' '6944' '3b00' '4a84' '26de' '5a46' '4b99' '2d3d' '377d' '36ef'\n",
      " '3e39' '39d4' '3e4b' '4a2f' '25db' '2c88' '43a5' '3f39' '2e8b' '30c4'\n",
      " '6a59' '4001' '308f' '3dc8']\n",
      "mean= 0.9082094\n",
      "gamma= 1.1050941\n",
      "maxgvc= 1.9230559\n",
      "mingvc= 0.83168226\n",
      "maxgmbvc= 1.2684754\n",
      "mingmbvc= -1.526742\n",
      "['0e1d' '0d27' '0b8a' '0996' '0cee' '0ca4' '0d07' '0b41' '0d73' '0b75'\n",
      " '0e48' '0bf5' '0cd3' '09cc' '09fa' '0cda' '0d66' '0df2' '0b0c' '0995'\n",
      " '0dbc' '0cba' '0e50' '0b57' '0e86' '0d46' '0e43' '0ca2' '0d10' '0c1a'\n",
      " '0b10' '0d8b' '0a30' '0d5a' '0e6f' '085c' '0f62' '0772' '0e72' '0d42'\n",
      " '0db9' '06a7' '0eca' '0d65' '0c39' '0e61' '09a2' '0a5b' '0b26' '0d64'\n",
      " '0b8b' '0eec' '0c01' '0a28' '0e0b' '0ca1' '0ac6' '0c46' '0b26' '0e85'\n",
      " '0be3' '0def' '0907' '0db0']\n",
      "mean= 0.22644183\n",
      "gamma= 1.0747932\n",
      "maxgvc= 14.765086\n",
      "mingvc= 2.854015\n",
      "maxgmbvc= 1.1802348\n",
      "mingmbvc= -1.1731693\n",
      "['51c3' '31df' '4c0f' '42b2' '206c' '4d30' '2f2f' '3567' '2bb2' '2849'\n",
      " '45d2' '1a5c' '32ba' '29ba' '32d7' '43ab' '40bb' '2886' '2ef4' '28e7'\n",
      " '26e1' '40b7' '3f69' '7528' '31b7' '489b' '20d2' '6161' '36f8' '5935'\n",
      " '2dc1' '2fe8' '69df' '25b6' '490a' '48c2' '529e' '16d5' '6583' '3900'\n",
      " '417a' '761f' '3a52' '2d2a' '419b' '4e7d' '5c2d' '6751' '5cc3' '461e'\n",
      " '28f1' '3916' '3610' '593b' '4b5e' '3757' '2893' '354e' '3f6f' '2c73'\n",
      " '372f' '2cb6' '25d2' '36bc']\n",
      "mean= 0.85487324\n",
      "gamma= 1.0807867\n",
      "maxgvc= 2.3194304\n",
      "mingvc= 0.9722335\n",
      "maxgmbvc= 1.3618338\n",
      "mingmbvc= -1.3659542\n",
      "['0c2f' '0d19' '0b19' '0c36' '0c5a' '09b8' '0e70' '0d8c' '0e0b' '0e7a'\n",
      " '0c14' '0b88' '0faf' '0d4f' '0cfe' '0e16' '0d2b' '0e58' '0e79' '0d4c'\n",
      " '09dc' '0dd2' '0b20' '1091' '0ddd' '0eed' '0a07' '0d36' '10de' '0bbb'\n",
      " '07c7' '0f9f' '0fea' '0e20' '0e92' '0d87' '0b4f' '0e84' '0e65' '0fa0'\n",
      " '0f05' '0b91' '0b92' '0f34' '0f60' '0e0e' '0f1f' '0889' '0f02' '0e39'\n",
      " '0e1d' '0d87' '0b1d' '0d9c' '0d44' '1006' '0cbe' '0dae' '0eba' '0e81'\n",
      " '0c2e' '0e36' '0cb1' '0d48' '0ba7' '0e2c' '0e77' '0d87' '0c90' '0ea3'\n",
      " '0dc4' '09c8' '0ec1' '103c' '0a5e' '0ad3' '0c3a' '0b1f' '0c1e' '0c49'\n",
      " '128e' '0cb6' '0d24' '099c' '0e0c' '0ea6' '0a5c' '0e2c' '1069' '0ea9'\n",
      " '0c95' '0a8e' '0d51' '0b88' '0b95' '0f6b' '1027' '0ce0' '122e' '0e85'\n",
      " '0e91' '0c52' '0daf' '0e5e' '0e91' '0a6b' '0e6c' '104f' '0dba' '0e47'\n",
      " '0f9a' '0e40' '0cbc' '0f1e' '105d' '0f2b' '0d20' '0919' '0c45' '0d8d'\n",
      " '0e5b' '0f85' '0f99' '0c9e' '0a93' '0ab5' '0c5c' '0e5b']\n",
      "mean= 0.1776157\n",
      "gamma= 1.1804168\n",
      "maxgvc= 19.917433\n",
      "mingvc= 4.6086836\n",
      "maxgmbvc= 1.2495242\n",
      "mingmbvc= -1.2980008\n",
      "['73ee' '4380' '5216' '270a' '3624' '7761' '6c72' '2f73' '406c' '4153'\n",
      " '524f' '79b3' '395b' '65c5' '509e' '43be' '5c51' '50f5' '5fd3' '4be4'\n",
      " '4ab1' '9f57' '5052' '4d8d' '4225' '4552' '499a' '44da' '36c4' '6046'\n",
      " '90ed' '4e23' '45ef' '2a0d' '5220' '60b8' '6919' '4d52' '31ad' '558b'\n",
      " '4526' '5a09' '57e0' '3290' '439d' '4a0c' '3e3c' '43de' '4cf8' '4e55'\n",
      " '38f4' '5217' '2737' '48a3' '7580' '60d5' '427a' '4216' '2aa8' '4926'\n",
      " '5227' '2fff' '630c' '5644' '3468' '4617' '4380' '49ed' '48d2' '3212'\n",
      " '42d8' '4fed' '3389' '5bb1' '297f' '8e9a' '973c' '2ec5' '43a8' '50cb'\n",
      " '4c0e' '4e73' '3e3a' '45c1' '4f2b' '4e0a' '6099' '5129' '561b' '35bd'\n",
      " '3b17' '700e' '6f7f' '4a92' '7860' '5c04' '3cfb' '6a09' '7191' '24df'\n",
      " '4ea5' '6793' '3a69' '4984' '3f43' '3f21' '52df' '3fb3' '7558' '393a'\n",
      " '41d5' '542d' '48be' '45b3' '46e2' '44b8' '2eb9' '6647' '3754' '30e3'\n",
      " '64a5' '6281' '6e1e' '5f68' '9ef9' '4734' '5764' '472f']\n",
      "mean= 1.1481899\n",
      "gamma= 1.1252828\n",
      "maxgvc= 2.25987\n",
      "mingvc= 1.021547\n",
      "maxgmbvc= 1.4148391\n",
      "mingmbvc= -1.7190884\n",
      "['098f' '0e13' '0d9e' '0d6a' '0dcd' '0ec1' '0ae3' '0d29' '0f8e' '0d1f'\n",
      " '09e5' '0b18' '09c3' '0b88' '09be' '0bf6' '0ac0' '0e3b' '082c' '0d58'\n",
      " '0b9a' '0c5a' '0c51' '0b1e' '0d0d' '0bea' '0a1e' '0d60' '0b14' '0eb5'\n",
      " '0c69' '0eca' '0c0b' '0bea' '1214' '0e31' '0a4b' '0a40' '0d94' '097e'\n",
      " '0b19' '0d4e' '0deb' '0c84' '0bfd' '09f7' '095c' '0afc' '0d68' '0cd3'\n",
      " '0b1f' '0b36' '0a69' '0b01' '0eab' '09b1' '0ebb' '0a16' '0bd5' '0ad4'\n",
      " '0c02' '0bf8' '0cbc' '0f87' '0ef6' '0b81' '0b50' '09b3' '0e7a' '0bb0'\n",
      " '0a64' '0cd2' '0ec6' '0f99' '0ec4' '0c9e' '106e' '0c1e' '0bb2' '0eab'\n",
      " '0ef3' '0cc1' '0b33' '0969' '0e1e' '0c69' '0c23' '0c80' '0e16' '0b9d'\n",
      " '0dc0' '09d0' '0c5f' '0e12' '0b34' '0d5e' '0b01' '0bf7' '0ad7' '106f'\n",
      " '0ba5' '0986' '0c0e' '0cd9' '0b99' '0acf' '0a7d' '08c4' '0d6b' '09ec'\n",
      " '0f12' '0be7' '0da8' '0e2e' '0aa2' '089e' '0aee' '08a3' '0d3a' '0d01'\n",
      " '0b71' '0d8f' '0be8' '0988' '0bf7' '0d49' '0a21' '09de' '0f1e' '0c77'\n",
      " '0c3e' '0c8e' '0c1e' '0e25' '0a8c' '0cd7' '0d57' '0cb1' '0930' '08fa'\n",
      " '0b32' '0bbc' '096d' '0d5c' '0aab' '0a35' '0a61' '0b81' '0cca' '0a00'\n",
      " '0e86' '0c9a' '0c0b' '0f98' '0e0e' '0b38' '1030' '0aa1' '0cc7' '0ac6'\n",
      " '0e83' '0a6e' '0db0' '0a3c' '0b40' '0d98' '0a0a' '0cb2' '0b43' '0ac9'\n",
      " '0cfb' '0c07' '0c29' '0eb7' '0933' '08fa' '0d45' '0d51' '0dd0' '0bf7'\n",
      " '0d62' '0e4b' '0d8b' '0b91' '0c3d' '0c24' '0db0' '0acc' '0d0a' '0cac'\n",
      " '0b14' '0dee' '0b03' '0cd7' '0bc7' '0a04' '0fda' '0da4' '0d11' '0ac4'\n",
      " '0d7a' '0e9c' '0cf5' '0b4b' '0a02' '0cbe' '0ff1' '0fcb' '0e14' '0853'\n",
      " '089e' '0be6' '0ca1' '0d0a' '0dc5' '0b81' '0c27' '0b5e' '0af2' '0d43'\n",
      " '0832' '0a6d' '0c52' '0b66' '0e66' '0b43' '0c08' '0c3d' '0cbd' '0b00'\n",
      " '0b6e' '0ff7' '0d86' '0c60' '08a7' '0ab8' '0b23' '0f14' '0c89' '0d12'\n",
      " '0b35' '093c' '0dd5' '0d02' '0d5a' '0d5b' '0fc6' '0c81' '0e01' '0ab8'\n",
      " '09c2' '0952' '0f8f' '0b8c' '0e46' '0ae0']\n",
      "mean= 0.16423833\n",
      "gamma= 1.1802981\n",
      "maxgvc= 80.17452\n",
      "mingvc= 5.4943495\n",
      "maxgmbvc= 1.2349807\n",
      "mingmbvc= -1.0799087\n",
      "['43d2' '5a84' '99fc' '678e' 'b61c' '5b26' '04b0' '9c50' 'c175' '35ac'\n",
      " '29bc' '6942' '6855' '5d57' '2ede' '4666' '64a3' 'b3eb' '72d0' '69ec'\n",
      " '8430' '6cb8' '408c' 'ca9a' 'a35b' '4ec4' '4aee' '394e' '63b5' '89a2'\n",
      " '3af8' '5dd7' 'e274' '6a8f' '8cfa' '4517' '5f6a' 'ac4e' '42eb' 'a292'\n",
      " '77d7' '5096' '61b0' '6daf' '32cb' '560d' '60ad' '3abf' 'c61c' '6c8b'\n",
      " '38d5' '6602' '4007' '3b3d' '512c' '4522' '42bf' '562f' '3571' '5e73'\n",
      " '5a37' '663a' '4315' '6417' '8dbe' '8a3c' '5a52' '410f' '53ff' '5d70'\n",
      " '4a94' '5bda' '8884' '79b7' '414d' '541e' '7624' '9368' '4d39' '836c'\n",
      " '6b36' '8aa4' '322a' 'a581' '9d66' '5d05' '7970' '4c9c' '8357' '789d'\n",
      " '75d6' '5c89' '53b4' '8ac4' '7b7b' '6d56' 'c205' '7db3' '7cdf' '8222'\n",
      " '8414' '646c' '44fd' '34b9' '7212' '663e' '4bb0' '8abe' '4793' '64fb'\n",
      " '5e11' '3ecc' '311c' '7862' '3986' '2bf4' '7ddc' '7f5e' '47e2' '6864'\n",
      " '4391' '3bfd' '75b1' '4347' '5850' '91a8' '5c7f' '81cd' '912c' '6a49'\n",
      " '4142' '7018' 'b6d1' 'b031' '66eb' '7d7b' '8ae3' '5aed' '3881' '84de'\n",
      " '3b05' '583c' '8437' '36dc' 'd497' '56ad' '6828' '60d5' '7418' '9e92'\n",
      " '6159' '8601' '61f9' '88d4' 'cd72' '694e' '9fab' '4c5f' '66e0' '8aae'\n",
      " '3a54' '3381' 'aaed' '5860' '72ad' '6a2b' '61aa' '404f' '41ee' '3ebc'\n",
      " 'a488' '64ce' '7148' '2120' '800d' '565b' '523a' '3575' '8abe' '7bc5'\n",
      " '7204' 'ae1d' '3d62' '6c2a' '6f6e' '5be3' '602a' '3127' '699a' 'bee5'\n",
      " 'cb4b' '8165' '6b49' '5e95' '921b' '38a2' 'f79e' '5f50' '45db' '40dd'\n",
      " '8eff' '9117' '6970' '6abe' '69c0' '8d57' 'b6b1' '568a' '4a39' '8383'\n",
      " '46b2' '4721' '84c1' 'b636' '4a00' '795b' 'a16e' '6f84' '3100' '4387'\n",
      " '6d1c' '4a47' 'cdfa' '43a7' '6d56' 'd699' '4502' '2e1a' '8ca5' '618c'\n",
      " '4820' '77c6' '8e1b' '3b6d' '4766' '9035' '9149' 'ab91' 'cd0f' 'a1d6'\n",
      " '51e9' 'd9a6' '7440' '640e' '385c' '76a5' '66ee' '9857' '4e9b' '63f3'\n",
      " '4ac6' '5c2d' '6408' '35a2' '66ae' '4472']\n",
      "mean= 1.5449896\n",
      "gamma= 1.1620655\n",
      "maxgvc= 1.7954129\n",
      "mingvc= 0.7757887\n",
      "maxgmbvc= 0.9995299\n",
      "mingmbvc= -1.5341096\n",
      "['08d7' '08b5' '07ac' '0ab3' '08dd' '09ce' '07fa' '096d' '0a2a' '07e4'\n",
      " '0b1b' '09f9' '08a4' '0960' '07fd' '0936' '0a51' '07b7' '09fb' '097e'\n",
      " '0992' '0b56' '090a' '0865' '0a08' '08d7' '09fe' '0816' '08be' '0944'\n",
      " '08a7' '0951' '09bf' '09b2' '0a31' '0755' '097e' '0b04' '072f' '0935'\n",
      " '09f2' '0a0b' '08b2' '09aa' '0a15' '080b' '0938' '090b' '08b8' '08e3'\n",
      " '09a8' '07ae' '08e2' '08e7' '07cc' '099c' '08e0' '093b' '08aa' '098e'\n",
      " '0871' '08b0' '09b1' '0a11' '08b1' '0887' '06ce' '079f' '09ad' '08ce'\n",
      " '0879' '08b5' '0952' '07f3' '0910' '09d9' '09a3' '0890' '0635' '0974'\n",
      " '0948' '0a05' '087e' '08ad' '0940' '09db' '0a58' '099f' '06ce' '07a8'\n",
      " '0a5a' '0870' '0e5d' '0984' '0933' '096a' '0aad' '0939' '08ec' '08a8'\n",
      " '0911' '0990' '0abd' '09e0' '093b' '09dc' '0904' '08ca' '0962' '0837'\n",
      " '0884' '0928' '0a61' '0836' '07ff' '08f4' '0a75' '08fa' '0807' '09ec'\n",
      " '08bf' '08f8' '094f' '080c' '0a3b' '08d7' '097a' '08fe' '080e' '092b'\n",
      " '088f' '08b0' '0938' '0b53' '0887' '09bc' '080c' '0762' '077a' '0a1d'\n",
      " '08d8' '091f' '09d4' '0a17' '0a56' '08ef' '08d0' '0a5a' '06c0' '0680'\n",
      " '0b9a' '0895' '0993' '09de' '07ec' '081e' '09b7' '08bd' '09a5' '08da'\n",
      " '08ca' '0855' '0a4d' '08fb' '0a3e' '09de' '09c4' '091d' '0839' '08e9'\n",
      " '09c0' '0a71' '09d0' '0982' '0a55' '0a97' '0b2d' '0921' '093d' '08c6'\n",
      " '0b61' '089c' '0928' '0b7b' '097d' '09aa' '09b4' '0929' '0973' '083d'\n",
      " '0812' '0799' '09be' '0654' '0982' '0a06' '0a1f' '06c9' '07f9' '08c0'\n",
      " '0a1d' '0a0d' '0d12' '09db' '0a93' '09e3' '09ab' '08b1' '0965' '09df'\n",
      " '0989' '0a7b' '089f' '086f' '09c9' '087b' '09d5' '0925' '0944' '090a'\n",
      " '0941' '0866' '092e' '0786' '0994' '082e' '09bd' '093a' '0694' '09c8'\n",
      " '096f' '0a18' '078b' '0948' '0960' '0a4d' '07c6' '0ac6' '0c14' '09d3'\n",
      " '09ed' '089e' '0a6a' '0b16' '0aa6' '0951' '07b8' '0a5f' '09cb' '0806'\n",
      " '072d' '0aa5' '094d' '0930' '0925' '0934']\n"
     ]
    }
   ],
   "source": [
    "with open('gvc.txt','w') as mf, open('gmbvc.txt','w') as gf:\n",
    "   for layer in mobilenetv1lite.layers:\n",
    "      if isinstance(layer,BatchNormalization):\n",
    "        # Get the weights\n",
    "        weights = layer.get_weights()\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        sqrtvar=np.sqrt(moving_variance)\n",
    "        varc=1/sqrtvar\n",
    "        gvc=gamma*varc\n",
    "        gmbvc=(gamma*moving_mean*varc)-beta\n",
    "        gmbvc=-gmbvc\n",
    "       # print(\"varc =\",varc)\n",
    "        print(\"mean=\",np.max(moving_mean))\n",
    "        print(\"gamma=\",np.max(gamma))\n",
    "        print(\"maxgvc=\",np.max(gvc))\n",
    "        print(\"mingvc=\",np.min(gvc))\n",
    "        print(\"maxgmbvc=\",np.max(gmbvc))\n",
    "        print(\"mingmbvc=\",np.min(gmbvc))\n",
    "        #print(\"gmbvc= \",gmbvc)\n",
    "        gvc=ftf(gvc,11)\n",
    "        gmbvc=ftf(gmbvc,11)\n",
    "        gvc=hex_vec(gvc)\n",
    "        print(gvc)\n",
    "        gmbvc=hex_vec(gmbvc)\n",
    "       \n",
    "        \n",
    "       \n",
    "        gf.write(f'{hex_vec(gamma.shape[0])} \\n')\n",
    "        np.savetxt(gf,[gmbvc],delimiter=\" \",fmt=\"%s\")\n",
    "        gf.write('\\n')\n",
    "        mf.write(f'{hex_vec(moving_variance.shape[0])} \\n')\n",
    "        np.savetxt(mf,[gvc],delimiter=\" \",fmt=\"%s\")\n",
    "        mf.write('\\n')\n",
    "        \n",
    "\n",
    "                     \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('means.txt','w') as mf, open('gamma.txt','w') as gf:\n",
    " for layer in mobilenetv1lite.layers:\n",
    "    if isinstance(layer,BatchNormalization):\n",
    "        # Get the weights\n",
    "        weights = layer.get_weights()\n",
    "        weights=ftf(weights)\n",
    "# Unpack the weights\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        gf.write(f'{gamma.shape} \\n')\n",
    "        np.savetxt(gf,[gamma],delimiter=\" \",fmt=\"%d\")\n",
    "        gf.write('\\n')\n",
    "        mf.write(f'{moving_mean.shape} \\n')\n",
    "        np.savetxt(mf,[moving_mean],delimiter=\" \",fmt=\"%d\")\n",
    "        mf.write('\\n')\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# Print the weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('variances.txt','w') as mf, open('beta.txt','w') as gf:\n",
    " for layer in mobilenetv1lite.layers:\n",
    "    if isinstance(layer,BatchNormalization):\n",
    "        # Get the weights\n",
    "        weights = layer.get_weights()\n",
    "        weights=ftf(weights)\n",
    "# Unpack the weights\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        gf.write(f'{beta.shape} \\n')\n",
    "        np.savetxt(gf,[beta],delimiter=\" \",fmt=\"%d\")\n",
    "        gf.write('\\n')\n",
    "        mf.write(f'{moving_variance.shape} \\n')\n",
    "        np.savetxt(mf,[moving_variance],delimiter=\" \",fmt=\"%d\")\n",
    "        mf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00773076  0.00751693  0.14207378  0.02845884  0.02265899  0.00320543\n",
      "  0.02708841  0.13327822]\n",
      "[ 0.03663696 -0.00315189  0.15835337 -0.00458406  0.01005088  0.01089459\n",
      "  0.0394135   0.02864885]\n",
      "[ 0.0696625   0.02370044  0.02450065  0.05359923  0.00185997  0.04267759\n",
      " -0.03996933 -0.04372416 -0.06870531  0.0070521   0.00633266  0.01678469\n",
      "  0.06596633  0.08822378  0.05008045  0.03132116]\n",
      "[ 0.01840405  0.00750033  0.07774682  0.04834275  0.00556276  0.05012243\n",
      " -0.00778291 -0.02253165  0.01866138  0.02367339 -0.03990653  0.04281659\n",
      "  0.03874187 -0.01337314  0.03218598  0.03462602]\n",
      "[-1.41216880e-02  3.88738401e-02 -1.35391718e-02 -3.15958750e-03\n",
      "  5.88724203e-02 -4.98903822e-03  5.92829026e-02 -1.11956736e-02\n",
      "  9.43732541e-03 -7.36898631e-02  2.68072449e-02  1.37576843e-02\n",
      "  5.34018241e-02  7.39045739e-02  1.17806725e-01  2.84580383e-02\n",
      "  1.99789517e-02  7.57969916e-02 -4.85256221e-03  1.29937157e-02\n",
      "  6.78119063e-02  5.01328660e-03  6.12180829e-02  5.58023490e-02\n",
      " -4.09892760e-02 -8.73052701e-03 -1.75067398e-05  3.16238031e-02\n",
      "  5.57817966e-02 -2.79304255e-02 -4.67425138e-02 -1.05148759e-02]\n",
      "[ 0.04284242 -0.02259982 -0.03397308 -0.01473895 -0.01380462  0.03991332\n",
      " -0.01510477  0.05174025  0.01507072 -0.04846514  0.0605615  -0.03776471\n",
      " -0.02817415 -0.01185988  0.01186447 -0.02138755 -0.03830786  0.06000054\n",
      "  0.01243022  0.05223059 -0.00421494 -0.01351629  0.07622027  0.07052182\n",
      " -0.00660695  0.0073823   0.0431914   0.00235754 -0.1233393  -0.06118919\n",
      " -0.01527254 -0.01748801]\n",
      "[ 0.05100303  0.00603228  0.01732673 -0.00088854 -0.08088157  0.03632648\n",
      " -0.02262454 -0.00629184 -0.00485201  0.04079603 -0.09179208 -0.01579849\n",
      "  0.01520466 -0.03877912  0.03988889  0.01371205  0.00672386 -0.04746576\n",
      "  0.04388971 -0.09331413 -0.0198768  -0.02513935 -0.02485705 -0.02643734\n",
      " -0.03326691  0.01666474 -0.02034401  0.00498691  0.00669526  0.05074261\n",
      "  0.05187019 -0.002423  ]\n",
      "[-0.08719645  0.020158   -0.03147774  0.01626736 -0.00202526 -0.01824669\n",
      "  0.03041178  0.06760918 -0.00392151 -0.00414096 -0.07620536 -0.01212185\n",
      "  0.03306523  0.01687157  0.01309624 -0.02728214 -0.07222425 -0.00144759\n",
      "  0.04550988 -0.01677033  0.02146932 -0.03571802 -0.02882432 -0.04560847\n",
      "  0.0033361   0.01401397 -0.04502076 -0.05857044 -0.02971493  0.08137607\n",
      " -0.05447218  0.0473733 ]\n",
      "[ 0.02897228 -0.00853267  0.08017401  0.06707686  0.0359809   0.02916942\n",
      " -0.01242184 -0.00364722  0.02570075 -0.01391586  0.03200789 -0.00431558\n",
      " -0.04308148  0.0018479   0.00025837 -0.01136655 -0.02737002  0.03648451\n",
      " -0.02276787  0.05498798 -0.03087014 -0.00718718  0.0031788   0.04275178\n",
      "  0.05151307  0.02425658  0.06942217  0.02458099 -0.02657253 -0.05290276\n",
      " -0.0206194   0.02826434 -0.00370192 -0.0200285  -0.01706321 -0.02789965\n",
      " -0.03162696 -0.0416268   0.01202976  0.00048422 -0.0529394   0.07972806\n",
      " -0.05715134  0.03987575  0.01550511  0.05943868 -0.05293193  0.00121204\n",
      " -0.00712744  0.05294939 -0.05484199  0.11927391 -0.04583503  0.03732971\n",
      " -0.06914212  0.01391421  0.0824094   0.02989856  0.04879554 -0.04305233\n",
      "  0.02664859  0.0068088  -0.02170449 -0.05214838]\n",
      "[ 0.04261371  0.00624675  0.0145752  -0.02427195  0.00322492  0.01961898\n",
      " -0.03430435  0.00457539 -0.00142924  0.00499167  0.01159359 -0.01858727\n",
      "  0.03005425  0.02639876 -0.01676135 -0.00305301 -0.03569201  0.01294422\n",
      " -0.02964821 -0.00118303  0.01326692 -0.00300988  0.04183673 -0.02772478\n",
      " -0.04643722  0.00574648  0.02464842  0.02600269 -0.01979086 -0.04014605\n",
      " -0.01714106 -0.02614091 -0.05390248 -0.01695322  0.02707128 -0.07692222\n",
      " -0.07370422 -0.01980736 -0.02601209 -0.00278958 -0.0139498   0.0141971\n",
      " -0.0163672  -0.00314862  0.01454082 -0.00858426 -0.01472743  0.04239597\n",
      "  0.02506202  0.01304389 -0.04588977  0.05734195 -0.04014027  0.00531991\n",
      " -0.00544993  0.0044534  -0.00934051 -0.01500591  0.02289309  0.03364852\n",
      "  0.02007877 -0.00803082  0.09271556 -0.02140071]\n",
      "[ 0.03096969  0.00728963  0.00050933  0.04037533  0.00710682 -0.01317672\n",
      " -0.02732468  0.00440792 -0.0622336   0.02269339  0.02429767  0.01036734\n",
      "  0.02369292  0.00675115 -0.0090589  -0.01736562 -0.06200378  0.04850452\n",
      " -0.04832711 -0.01032351  0.03262161 -0.04230484  0.01188637 -0.01209688\n",
      "  0.0400669  -0.00882439  0.02453848  0.00742406  0.0090316   0.04192336\n",
      "  0.03569334 -0.01913768 -0.03365548 -0.03272358 -0.02098157  0.04224171\n",
      "  0.03171514 -0.05362446 -0.00458233  0.00833702  0.02096641  0.01369623\n",
      "  0.0483553   0.04376989 -0.01472792 -0.03246934 -0.00756969 -0.0544703\n",
      "  0.01704761  0.01533549  0.04765463 -0.0309249  -0.00839018  0.05314174\n",
      " -0.03713924  0.06810737  0.04085947 -0.02102542  0.00450362 -0.00418474\n",
      "  0.00611007  0.02444897  0.00766599 -0.0074375 ]\n",
      "[ 0.0144717   0.0023455  -0.05612979 -0.00631662  0.02494088  0.07381161\n",
      "  0.03372737  0.0105155   0.03216901  0.00142999 -0.0183061   0.01467542\n",
      "  0.02063277  0.02970835 -0.03000322 -0.03202439 -0.00726641  0.06364802\n",
      " -0.02698515 -0.0294127   0.00198599 -0.0169812  -0.06166887  0.03227953\n",
      "  0.00411328 -0.03608393  0.02901254 -0.08822292  0.041163   -0.06458761\n",
      "  0.04096794  0.00514313 -0.03813482 -0.04542115 -0.00781497 -0.0422637\n",
      " -0.02562838 -0.06244779 -0.0207015   0.02628549  0.00130439  0.00145336\n",
      " -0.01258939  0.02865849  0.01240048 -0.02895629 -0.02414818 -0.04935941\n",
      " -0.039981   -0.04333632  0.03518827 -0.02355585  0.03218284  0.01767606\n",
      "  0.00498203  0.03119374  0.02308185 -0.10280168  0.02672453  0.05793998\n",
      "  0.00926556  0.0262678  -0.01019402  0.03174032]\n",
      "[-5.72850965e-02  8.37229285e-03  6.48679212e-02 -5.79410046e-02\n",
      "  2.69850791e-02  4.94295396e-02 -1.43955536e-02 -1.72490440e-02\n",
      " -2.16008313e-02 -1.48873389e-01 -1.27401273e-03  9.33479052e-03\n",
      " -3.40145752e-02  7.01327901e-03 -2.23013852e-03  8.06763172e-02\n",
      " -2.66332552e-02  3.43409553e-03  8.23616143e-03 -6.45023538e-04\n",
      " -4.67230305e-02 -1.86561625e-02  9.80717596e-03  2.32605706e-03\n",
      "  2.60219746e-03 -2.03213915e-02  1.09659424e-02 -6.35365844e-02\n",
      " -4.15730774e-02 -6.78664958e-03  1.04278862e-01  5.05550997e-03\n",
      "  1.91770196e-02 -4.99496385e-02 -7.28049427e-02  2.70064920e-02\n",
      "  3.02871671e-02 -1.64431557e-02 -3.72369625e-02  3.42591368e-02\n",
      " -2.96603702e-02 -1.33359144e-02  3.34387762e-03 -2.47357208e-02\n",
      " -1.99027155e-02  2.05901861e-02 -7.40907118e-02  3.13229784e-02\n",
      " -4.64584753e-02  1.88742317e-02  1.49878452e-03 -5.04728667e-02\n",
      "  7.77880028e-02 -4.89475206e-02 -1.30860908e-02 -3.21892761e-02\n",
      "  5.41577451e-02  5.92885017e-02  2.25646198e-02 -3.76481451e-02\n",
      " -9.13359746e-02 -1.85258202e-02 -4.16341834e-02  9.16182399e-02\n",
      "  2.90435851e-02 -4.29021083e-02  4.13023569e-02 -1.54310456e-02\n",
      "  1.12682648e-01 -1.71998776e-02 -4.16925065e-02  1.18203517e-02\n",
      " -3.06418817e-03 -3.40274349e-02  3.85860093e-02 -3.20209563e-02\n",
      " -4.87143314e-03  7.10531557e-03  2.48573869e-02  3.86597239e-03\n",
      "  3.54812071e-02 -1.71142384e-01  4.49771956e-02  4.99228202e-02\n",
      " -2.89426968e-02 -5.19413836e-02  1.92915034e-02 -3.02684586e-03\n",
      "  3.26408818e-02 -1.32157244e-02 -2.81376019e-02  8.95216875e-03\n",
      " -1.44475559e-02  1.40814751e-01 -8.79892148e-03 -1.77101512e-02\n",
      " -5.12544848e-02 -4.12757918e-02  1.87698379e-02 -1.35902762e-02\n",
      "  2.76957406e-03  1.38126372e-03  3.37730572e-02  1.05095804e-01\n",
      " -2.86773406e-02 -3.95306386e-02 -7.15352818e-02  1.07820919e-02\n",
      "  9.16880183e-03  2.66761724e-02 -4.78554294e-02 -8.82359594e-02\n",
      "  3.25216493e-03 -1.12454154e-01 -6.66180030e-02  6.86154049e-03\n",
      " -6.44038431e-03  2.62104935e-04 -2.78868806e-02  1.91250374e-03\n",
      "  8.22105259e-03 -1.94251351e-02 -7.79146925e-02 -4.51761298e-02\n",
      "  2.15950813e-02 -8.01554997e-05 -3.86578143e-02  2.29082741e-02]\n",
      "[-0.02222251 -0.04958586 -0.01042522  0.04896673  0.01985982 -0.07289666\n",
      " -0.02712878 -0.00967947 -0.01425064  0.01267565 -0.14260702 -0.04477422\n",
      "  0.00462152 -0.03302578 -0.10569642 -0.02835831 -0.07240684  0.0349719\n",
      " -0.08434428 -0.00138632 -0.09607242 -0.02899476 -0.02039914 -0.0484674\n",
      " -0.02093823  0.00703716 -0.03316382  0.01473222  0.01190774  0.00496602\n",
      " -0.04762537  0.00483693 -0.02821902  0.0433573  -0.03892879 -0.06821394\n",
      " -0.11006066 -0.07394668  0.01777438  0.01018917 -0.01953818 -0.09021614\n",
      " -0.08040881  0.0332147   0.04691426 -0.018609   -0.03280373 -0.06041716\n",
      " -0.05281302 -0.09981121  0.00276605  0.00550569  0.03934448 -0.04720408\n",
      " -0.03427849 -0.05874664  0.01314782  0.04617874  0.02431048  0.00296428\n",
      " -0.04815823  0.0439447  -0.10155131 -0.00082087 -0.00666231 -0.06425373\n",
      " -0.01154624 -0.00396259 -0.15298235  0.00290182 -0.0728695  -0.01503405\n",
      " -0.00713415 -0.08066861 -0.02120393 -0.14549965 -0.05953932 -0.00956027\n",
      " -0.0314412  -0.0280337   0.00298743 -0.0566127  -0.05534785  0.00857181\n",
      " -0.04675433 -0.06631743 -0.00220538 -0.06648729  0.0026021  -0.03350708\n",
      " -0.05806492 -0.04124912 -0.02411051 -0.0915119  -0.07644279 -0.00683307\n",
      " -0.00363883 -0.05918942 -0.12962338  0.03898475  0.00781177 -0.06138676\n",
      " -0.06474031 -0.06552254 -0.01612011 -0.04291864 -0.04238287 -0.04187907\n",
      " -0.05122707 -0.0133668   0.00763635 -0.06016796 -0.03648298 -0.02207438\n",
      "  0.03642475 -0.0002583  -0.03666145 -0.00937602 -0.03869943 -0.0022185\n",
      " -0.06642345 -0.11221597 -0.00298506  0.01720718 -0.16809203  0.01204838\n",
      " -0.06619191 -0.03235044]\n",
      "[-0.00937755  0.00860047 -0.15993597 -0.05423122 -0.05391671 -0.05745829\n",
      " -0.07033362 -0.00125601 -0.02439277  0.0534528  -0.08733817 -0.00891159\n",
      " -0.05485601 -0.01227713 -0.07115654 -0.02380857 -0.02962126 -0.08453072\n",
      " -0.21669485  0.02097712 -0.25344515 -0.19973326 -0.03948211  0.01256177\n",
      " -0.12401585 -0.04311299 -0.05145193 -0.01090095  0.05625516 -0.07452893\n",
      "  0.00201835  0.02971249 -0.13980377  0.01636241 -0.05516784 -0.01144312\n",
      " -0.06658971 -0.04653856 -0.08039245 -0.0291417  -0.34609786  0.0247933\n",
      " -0.03521115 -0.16809095  0.00574441 -0.04795071 -0.01601598 -0.13729611\n",
      " -0.03548243 -0.10208891 -0.06716295 -0.00873344 -0.0610767  -0.0064454\n",
      "  0.0581609  -0.00130832  0.03738454 -0.11005756  0.03706711 -0.00339474\n",
      " -0.06919146 -0.05481804 -0.0667551  -0.01473825 -0.01012214 -0.00771068\n",
      " -0.01896623 -0.21110567 -0.02383024 -0.05824535 -0.00271256 -0.0551488\n",
      " -0.01309252 -0.02630729  0.00767355 -0.0212295  -0.06394646 -0.0611339\n",
      " -0.07496354 -0.03006469 -0.0670971  -0.09714404 -0.00398665  0.02608288\n",
      " -0.03054083 -0.02211209 -0.05686726 -0.03199026 -0.01467978 -0.31909192\n",
      " -0.06903391 -0.00342206 -0.15298097  0.02583029  0.00882138 -0.10096254\n",
      "  0.00329655 -0.04235955 -0.14852057 -0.02992398  0.00081166 -0.14406034\n",
      " -0.0639346  -0.10330676 -0.02606411 -0.2533477  -0.03678442 -0.40933174\n",
      " -0.03710173 -0.06214793  0.02982954 -0.08400575 -0.10011917 -0.01426087\n",
      " -0.14183134  0.04688447 -0.1264327  -0.11985987 -0.07759228  0.03657379\n",
      " -0.06185223 -0.073906   -0.16166367  0.05186069 -0.02813771  0.0069001\n",
      " -0.04323304  0.07605549 -0.04072706 -0.15640397 -0.16228613  0.00478828\n",
      " -0.07173584 -0.02364875 -0.06686542 -0.12745401 -0.08407407 -0.05455603\n",
      " -0.01472946  0.02049786  0.00516568 -0.02486067 -0.01945422  0.03140989\n",
      " -0.02186045 -0.07252523 -0.37759325 -0.0257498  -0.09005778 -0.01265849\n",
      " -0.01212888 -0.08293519 -0.04569583 -0.0055705  -0.06279117 -0.02268838\n",
      " -0.08881395 -0.11274294 -0.0603423  -0.02170624  0.00896982 -0.09127622\n",
      " -0.02584747 -0.19243942 -0.05234567 -0.09461509 -0.0423017  -0.03169502\n",
      "  0.02135189 -0.01949655 -0.03901943  0.01847248 -0.0146898  -0.07227353\n",
      " -0.07770069 -0.08229944 -0.00787104 -0.12945409 -0.09498496  0.01414215\n",
      " -0.04215831 -0.06478389 -0.08828831 -0.0158813  -0.05440052 -0.17420323\n",
      "  0.03534676 -0.04301526 -0.0618025  -0.05421655 -0.00308779 -0.08728097\n",
      " -0.12635538 -0.04000853 -0.04713542 -0.02864994 -0.04130138  0.04778199\n",
      " -0.12407848 -0.17578566 -0.05171623 -0.02865855 -0.05415649 -0.28938648\n",
      " -0.18285587 -0.02094569 -0.04651594 -0.01801123  0.03257139 -0.37953022\n",
      " -0.0548542   0.01605794  0.00497926 -0.01727058 -0.02379438 -0.08383203\n",
      " -0.00792798  0.03039229  0.00879807 -0.02455326 -0.06150437  0.00597275\n",
      " -0.07318316 -0.0757673   0.01863175 -0.09557784 -0.06625023 -0.00398126\n",
      " -0.11013088 -0.1744405   0.00538129 -0.01936715 -0.03375369  0.01046248\n",
      " -0.01454325 -0.0108545   0.00101654 -0.10592998 -0.08029624 -0.04208749\n",
      " -0.02000155  0.00124936 -0.02184301 -0.07170188  0.00538309 -0.05257343\n",
      " -0.01700567 -0.01777726  0.01586024 -0.09293516  0.06987653  0.03022166\n",
      " -0.0059175   0.02073392 -0.03528067 -0.21430452]\n",
      "[-2.28438922e-03 -1.01674639e-01 -1.50878057e-01 -3.69904377e-02\n",
      " -6.73203915e-02 -6.13192916e-02 -7.71317407e-02 -4.06173058e-02\n",
      " -8.74239355e-02  1.63684972e-02 -1.24297664e-01 -2.82222293e-02\n",
      " -1.18139990e-01 -9.75537300e-03 -4.22373936e-02 -8.55825190e-03\n",
      " -2.36115921e-02 -1.43491387e-01 -1.73738435e-01 -9.33274776e-02\n",
      " -2.05107369e-02 -1.16120666e-01 -1.47574395e-02 -6.06962070e-02\n",
      " -9.02048126e-02  1.32819568e-03 -6.53735027e-02  6.66368101e-03\n",
      " -1.54213130e-01 -4.77657691e-02 -2.84120440e-02 -1.36208013e-02\n",
      " -1.75496697e-01 -5.22968657e-02 -5.90226017e-02  1.26755722e-02\n",
      " -7.64683336e-02 -1.50005504e-01 -1.87990125e-02 -4.29143831e-02\n",
      " -4.68955748e-02  8.17853678e-03 -5.94422184e-02 -9.04998630e-02\n",
      "  6.82462333e-03 -4.50623408e-02 -7.89996386e-02 -3.41534726e-02\n",
      " -8.11627209e-02 -4.86001335e-02 -2.69432534e-02 -3.05474866e-02\n",
      "  9.63769294e-03 -9.60058242e-05 -5.48838917e-03 -2.03218330e-02\n",
      " -6.06785994e-03 -1.10851012e-01  4.16700430e-02 -1.31720100e-02\n",
      " -6.12892844e-02 -7.93404579e-02 -2.31911894e-02 -1.29937917e-01\n",
      " -8.25472325e-02 -1.62741557e-01 -8.54656994e-02 -6.85174242e-02\n",
      "  1.39826490e-03 -6.69441521e-02 -6.86006173e-02 -3.21868695e-02\n",
      " -3.69554572e-02 -5.91925643e-02 -2.50035040e-02 -2.56386232e-02\n",
      " -1.10783346e-01 -1.15106978e-01  9.87831317e-03 -4.75024208e-02\n",
      " -5.54791242e-02 -1.12896986e-01  2.21820492e-02 -4.38619889e-02\n",
      " -6.50201514e-02 -6.08201465e-03 -1.16492487e-01 -5.51736131e-02\n",
      " -9.95114520e-02 -7.27609498e-03 -1.55579686e-01  4.79885796e-03\n",
      " -9.91558470e-03 -5.92046753e-02 -1.41488984e-01 -1.50761947e-01\n",
      " -4.83813249e-02 -1.23949133e-01 -1.19966663e-01 -3.72562706e-02\n",
      " -6.74994960e-02 -7.15745091e-02 -5.76705020e-03  5.13100922e-02\n",
      " -9.44490582e-02 -1.18375488e-01 -2.82378308e-02 -1.15248539e-01\n",
      " -4.19266634e-02 -1.23035654e-01 -4.78329882e-03  1.07990904e-02\n",
      "  2.70220023e-02 -4.48392332e-02  1.78034045e-02 -5.09222178e-03\n",
      " -1.50376245e-01 -1.15597315e-01  3.60964565e-04 -1.13438316e-01\n",
      " -3.29694920e-03  1.00547969e-02 -3.22358795e-02 -4.03294004e-02\n",
      " -1.24418333e-01 -1.66162010e-02 -1.08105257e-01 -1.62471622e-01\n",
      " -2.83353254e-02 -1.01988576e-01 -4.71458770e-02 -4.35491912e-02\n",
      " -1.23615973e-01 -8.62705186e-02 -5.03669344e-02 -1.11279733e-01\n",
      " -1.15125857e-01 -1.03087768e-01 -4.15687412e-02 -1.46203756e-01\n",
      "  1.12690423e-02  2.01431587e-02 -6.45427406e-02  1.22537129e-02\n",
      " -7.79393017e-02 -1.37267694e-01  3.71617661e-03 -1.11503951e-01\n",
      " -6.04313314e-02 -5.05259819e-02 -3.34109366e-02 -1.22020990e-01\n",
      " -2.85072923e-02 -1.23479031e-01 -1.38495982e-01 -3.64282206e-02\n",
      " -1.13684364e-01 -4.29244041e-02 -2.75086295e-02 -9.77303609e-02\n",
      " -4.00189124e-03 -4.06321278e-03 -9.16285366e-02 -1.26639195e-02\n",
      " -3.65956947e-02 -1.79221004e-01 -8.04724321e-02 -2.54529696e-02\n",
      " -3.41687612e-02 -4.37809527e-02 -1.17674820e-01 -1.09603398e-01\n",
      " -6.47499561e-02 -7.45407864e-02 -1.45399585e-01 -9.28855017e-02\n",
      " -2.28518732e-02  1.05219865e-02 -8.32881778e-02 -2.43510734e-02\n",
      " -5.11768684e-02 -7.88237453e-02 -1.42461518e-02 -1.26492009e-01\n",
      " -1.23393625e-01 -8.01352262e-02 -1.15816155e-02  2.41752975e-02\n",
      " -1.13877676e-01 -6.02450818e-02 -7.09646046e-02 -1.43598378e-01\n",
      " -5.19459955e-02 -2.22212682e-03 -1.43537447e-01 -3.26291807e-02\n",
      " -7.97489136e-02 -7.96193331e-02 -3.20709758e-02 -3.45428213e-02\n",
      " -5.14061153e-02 -7.72552192e-02 -9.56083015e-02 -7.18225986e-02\n",
      " -7.01594800e-02 -9.35030952e-02 -1.59284920e-01 -3.91200148e-02\n",
      "  5.16518531e-03 -1.72710955e-01 -4.10664901e-02 -5.63264489e-02\n",
      " -7.19692633e-02 -6.42428622e-02 -1.07655279e-01 -1.46026030e-01\n",
      " -6.12651110e-02 -4.95805107e-02  2.85884589e-02 -2.27902830e-02\n",
      " -7.93838501e-02 -3.25493980e-03 -1.49460793e-01  1.84350368e-02\n",
      " -3.49522792e-02 -1.81596875e-01  8.05143919e-03  2.65966952e-02\n",
      " -1.07317664e-01 -7.98875391e-02 -5.29701682e-03 -3.38701867e-02\n",
      " -7.54518509e-02 -1.80279557e-02 -2.06813812e-02 -1.74504906e-01\n",
      " -1.14857964e-01 -1.01256579e-01 -8.01925585e-02 -1.09514900e-01\n",
      "  4.32710871e-02 -6.36288002e-02 -6.94126114e-02 -5.01553863e-02\n",
      " -7.05537805e-03 -3.36029567e-02 -1.06479879e-02 -2.93924585e-02\n",
      " -2.52884347e-02 -8.00957307e-02 -3.20002288e-02  3.99122536e-02\n",
      " -1.38130886e-02 -1.23099075e-03 -1.24749452e-01 -6.72708526e-02]\n",
      "[ 6.41441159e-03 -1.42372064e-02 -5.17364970e-05  1.05458107e-02\n",
      "  1.53392619e-02  4.96339565e-03 -1.68102365e-02 -3.10957409e-03\n",
      "  5.53217828e-02  7.94956088e-03 -2.23927740e-02  1.29988501e-02\n",
      "  4.41490971e-02  2.59026680e-02  1.84146594e-02 -5.82576031e-03\n",
      " -1.93721876e-02  2.29452131e-03  4.23839279e-02 -8.11154954e-03\n",
      "  5.04941009e-02  1.78521127e-02  3.60348150e-02 -1.23968935e-02\n",
      "  6.12103147e-03  2.22728085e-02  1.33276116e-02 -4.22682054e-03\n",
      "  4.12523486e-02 -1.54358223e-02  3.65758687e-02  3.99256684e-02\n",
      " -3.56977270e-03  3.78225036e-02 -3.88082885e-03  4.07908335e-02\n",
      "  6.81610499e-03 -5.58981933e-02  4.91624558e-03 -3.56435264e-03\n",
      "  3.93610150e-02  3.08110490e-02  2.96282936e-02 -1.43549696e-03\n",
      "  3.19040492e-02  2.79626511e-02  2.61429101e-02  2.98650842e-02\n",
      "  2.64904723e-02  2.91362288e-03  7.58642238e-03  6.32353127e-04\n",
      "  3.62854637e-02 -4.22691600e-03 -1.33274123e-03 -1.11588882e-02\n",
      "  5.48019409e-02  2.38653668e-03  2.02663671e-02 -1.50127793e-02\n",
      "  1.63175650e-02  1.47365248e-02  5.52853860e-04  3.96704813e-03\n",
      "  4.69463207e-02  5.49186729e-02  3.90603393e-02 -2.29598209e-02\n",
      " -2.55519152e-02 -6.06557867e-03 -1.93016510e-02  4.43370305e-02\n",
      "  1.22620817e-03  8.52684490e-03  5.11027202e-02  4.32050638e-02\n",
      " -1.79900806e-02  2.80044843e-02  3.16233709e-02  1.76076628e-02\n",
      "  5.11076115e-02  1.25036929e-02  2.38548988e-03  1.53757576e-02\n",
      "  4.90190350e-02 -1.84563044e-02  2.30203569e-03 -4.17781342e-03\n",
      "  3.53521481e-02  1.34202447e-02  1.75340306e-02  2.89450698e-02\n",
      " -2.39395406e-02  2.15439568e-03 -1.10831168e-02  6.51398790e-04\n",
      " -4.26382711e-03 -1.12255095e-02  2.11954359e-02 -6.97774114e-03\n",
      "  2.66472027e-02 -3.05401464e-03 -7.13595515e-03  7.49049615e-03\n",
      "  5.44001907e-02 -6.76361425e-03  2.26756390e-02  1.07029406e-02\n",
      " -1.34894866e-02  2.31840834e-02 -3.27210082e-03  9.60520003e-03\n",
      " -4.90353443e-03  1.72425713e-02  8.42728623e-05  1.08955512e-02\n",
      "  6.82810694e-03  1.08165937e-02 -1.59888715e-02  3.58212390e-03\n",
      "  3.21840346e-02  6.39305413e-02 -9.69819166e-03 -1.07121095e-02\n",
      "  1.15527296e-02  1.84495279e-04  1.00596156e-03  5.39981876e-04\n",
      " -3.58611182e-03  2.74384283e-02  2.76535237e-03 -2.22955067e-02\n",
      "  2.72182506e-02  1.10191386e-02  3.11149023e-02  3.24352607e-02\n",
      " -1.52169839e-02  6.52690744e-03  2.90245730e-02  1.51618815e-03\n",
      "  6.46836264e-03  3.96436267e-02 -2.14477517e-02 -3.24578863e-03\n",
      " -9.17177298e-04  3.15252878e-02  1.91736408e-03  2.02945620e-02\n",
      "  1.46232862e-02  5.03707631e-03 -2.99165249e-02  7.94370484e-04\n",
      "  8.54931585e-03  1.07347770e-02  2.62219422e-02 -2.74536619e-03\n",
      "  1.59706809e-02 -9.69442911e-03 -1.67449331e-03 -9.87772085e-03\n",
      " -1.56056024e-02  1.12649880e-03  3.03129712e-03  3.32022528e-03\n",
      "  6.78943796e-03  5.42213256e-03  3.73794921e-02  1.20626297e-02\n",
      "  9.77117103e-03  1.07758781e-02 -3.11139086e-03 -2.15744111e-03\n",
      "  7.49376602e-03 -8.17646831e-03  1.26508605e-02 -1.75259039e-02\n",
      "  2.56803120e-03  5.12436591e-02  7.05516199e-03  4.26859893e-02\n",
      " -1.50443353e-02  4.28979993e-02 -6.21833606e-03  1.75960101e-02\n",
      " -9.43888817e-03 -2.08885386e-03  9.00114235e-03  1.30619518e-02\n",
      " -2.55603082e-02 -6.51632855e-03  9.32851515e-04 -1.23082763e-02\n",
      "  2.12299991e-02 -8.12609866e-03  2.67556985e-03  1.17538311e-02\n",
      "  8.91294703e-03  1.39536839e-02  2.47918498e-02  1.73253973e-03\n",
      " -2.05648062e-03  3.61541659e-03 -3.57420836e-03 -6.88176649e-03\n",
      " -1.57561619e-03  5.88478427e-03  2.21478427e-03  1.45545520e-04\n",
      " -5.67421131e-03 -5.10516251e-03 -2.60924958e-02  6.15228841e-04\n",
      "  2.90408228e-02  1.23769017e-02  4.50583175e-03  7.62056280e-03\n",
      " -3.25618871e-02  2.85080280e-02  5.00114693e-04  5.40179871e-02\n",
      "  3.28699267e-03 -1.64558496e-02  5.28789498e-02 -5.46505721e-03\n",
      "  2.73700263e-02  4.51422110e-02  2.69858949e-02  5.08793741e-02\n",
      " -1.44832698e-03  2.14848183e-02  1.45266680e-02  2.18713051e-03\n",
      "  2.59722825e-02 -1.58047013e-03  2.14549876e-03 -1.63876582e-02\n",
      " -8.13777186e-03  4.40222118e-03 -1.13837114e-02 -5.54422755e-03\n",
      "  1.16196321e-03  1.13962851e-02  5.00339903e-02 -1.38411382e-02\n",
      "  4.90979943e-03  4.81936662e-03  3.56952660e-02  3.51625669e-04\n",
      " -9.50163789e-03 -4.48220316e-03  2.07511671e-02  2.45252345e-02\n",
      "  8.67829425e-04 -3.04056462e-02 -2.17550015e-03  5.21851853e-02]\n"
     ]
    }
   ],
   "source": [
    "for layer in mobilenetv1lite.layers:\n",
    "    if isinstance(layer,BatchNormalization):\n",
    "        weights = layer.get_weights()\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "x=ftf(0.00750033,12)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000100101100\n",
      "1111111011010100\n",
      "0111111111111111\n",
      "1000000000000000\n"
     ]
    }
   ],
   "source": [
    "def to_signed_16bit_binary(decimal_number):\n",
    "    if decimal_number < -32768 or decimal_number > 32767:\n",
    "        raise ValueError(\"The number is out of range for a 16-bit signed integer\")\n",
    "    \n",
    "    # If the number is negative, apply two's complement\n",
    "    if decimal_number < 0:\n",
    "        decimal_number = (1 << 16) + decimal_number  # 2^16 + decimal_number\n",
    "    \n",
    "    # Convert to binary and pad to 16 bits\n",
    "    binary_representation = format(decimal_number, '016b')\n",
    "    \n",
    "    return binary_representation\n",
    "\n",
    "# Test the function\n",
    "print(to_signed_16bit_binary(300))    # Output: '0000000100101100'\n",
    "print(to_signed_16bit_binary(-300))   # Output: '1111111011010100'\n",
    "print(to_signed_16bit_binary(32767))  # Output: '0111111111111111'\n",
    "print(to_signed_16bit_binary(-32768)) # Output: '1000000000000000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000000000000010'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_signed_16bit_binary(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244 249 231 263 253 259 257 220]\n",
      "(8,)\n",
      "[-77 -19 -32 -42   9  63  24 -35]\n",
      "[53  3 13 18  5 45  7 17]\n",
      "[244 243 275 246 248 253 254 260]\n",
      "(8,)\n",
      "[-13 -51   7  93 -22  10  12 -70]\n",
      "[ 4 21  4 70  7  1  8 41]\n",
      "[241 260 263 273 253 258 245 239 236 270 244 283 253 252 253 239]\n",
      "(16,)\n",
      "[-149   28   -2  119  -21   48  -14  -28  113   21   27   37  -54    0\n",
      " -116    8]\n",
      "[33 36 19 42 32 56 17 26 48 84 72 58 50 56 91 28]\n",
      "[245 242 267 263 258 253 246 248 252 254 241 269 260 270 264 254]\n",
      "(16,)\n",
      "[ 26 -36 -20 -32   3  13 -33  -4  11 -49   0 -24 -16   7 -11  22]\n",
      "[ 6 20 14 19  3  8  6 10  4 16  9 11  3 14  3 11]\n",
      "[262 273 245 235 269 219 249 250 233 254 267 250 229 261 256 242 253 256\n",
      " 233 262 252 248 242 264 265 256 258 251 235 253 254 245]\n",
      "(32,)\n",
      "[  43   95  -13  124   32   19   58   78  -94  -42   -2  -93  -10  -64\n",
      "  -17  -11   -4  -63   26   41 -120  -99   33   38  -97   89  -91  -46\n",
      "  115  -90   42   -6]\n",
      "[59 62 47 41 26 45 46 65 72 38 35 72 50 87 57 43 55 64 57 76 52 81 38 44\n",
      " 49 52 84 67 27 92 64 53]\n",
      "[258 248 248 247 251 271 262 263 256 255 258 248 251 266 259 253 251 261\n",
      " 255 258 258 250 263 257 262 258 255 262 255 248 278 238]\n",
      "(32,)\n",
      "[ 21  39   1 -12   3  17  -8  39 -22  10   3   1 -29 -11   4 -21   2 -30\n",
      "  19  -2 -27  33  21   0  29 -24 -15 -14   2  12   7  -2]\n",
      "[ 5 11  3  3  9  9  4 20  8  8  5  3  9  2  3  5  6  3 11  4  5  4  8  9\n",
      "  5 10  3  3  4  2  9  4]\n",
      "[248 261 254 298 212 267 267 264 240 250 238 253 260 233 245 249 255 266\n",
      " 259 254 248 224 255 254 247 245 229 246 250 268 263 257]\n",
      "(32,)\n",
      "[ -88   41   48 -238  -48 -101   42  114   25 -144  -37 -149 -146  161\n",
      "   -3   39   -6   86 -166  216  -28   34   61  100   34 -161   48  -11\n",
      " -114   62 -133   55]\n",
      "[174 106  90 146  93 163  85 112  85 102  99 177 143 121  83  74 120 144\n",
      " 199  99  79  82 145 139  84 133 138  76 105  96  74 104]\n",
      "[248 258 256 298 260 262 258 271 252 251 238 247 256 241 243 244 244 252\n",
      " 258 260 255 241 260 255 254 240 239 236 245 278 261 262]\n",
      "(32,)\n",
      "[ -1 -25  -2  -3  24 -29 -53  13  38 -39   5 -37 -21  -6  16 -14  -4  20\n",
      "  41  19  44  -4  59   5  21 -16  26 -16 -41  26  -1 -23]\n",
      "[ 3  7  8  4  7  5 23 10 14  4  4  5  4  3  3  5  5 10  6  8 16  5 18  6\n",
      "  8  3 11  4  9  8  7  7]\n",
      "[264 256 252 252 256 259 259 250 254 256 261 245 266 262 252 261 262 247\n",
      " 244 258 259 267 271 257 273 255 260 268 246 248 262 245 250 267 248 236\n",
      " 266 255 246 277 245 251 245 252 265 257 259 245 240 271 254 244 242 252\n",
      " 239 268 250 251 280 266 256 254 270 259]\n",
      "(64,)\n",
      "[ -67   -6   93    5  136   53 -172  -55  -83   28    2  110  -19   -9\n",
      "  -99   14  126  -14   95 -104  -15  107  -76  -69 -223  -92   52   51\n",
      "  -82   64    3  -38  -70   -2  -21  -24   94   19   68   38   60 -159\n",
      "  110  -89   38  -48  -46  129  -19   -2   74   86   19    4   61   78\n",
      " -129   36   94  -41 -132   18   92   19]\n",
      "[ 55  60 134  86 180  66 105  69  79  72  76  77  54  64  47  47 110  84\n",
      "  72 141  46  67  62  56 252 129  88  62  81 120  79  48  51  46  49  86\n",
      "  60  66  70  72  55 127 121 113  53 132  61 109  83  62 115  86  79  38\n",
      "  67  57 167  49 125  47 138  63  79  55]\n",
      "[263 253 260 252 279 264 259 252 254 255 252 261 262 262 248 256 254 247\n",
      " 266 263 256 261 267 253 278 250 255 261 243 241 266 242 245 252 251 227\n",
      " 248 253 238 268 260 252 264 249 261 252 260 258 250 270 257 268 233 255\n",
      " 241 263 256 254 271 257 256 252 271 251]\n",
      "(64,)\n",
      "[  6 -17  49  -8  -6 -38   6 -32 -26  11  22  -2  17 -46 -45   8   4 -16\n",
      "  -2 -53  48 -47  15  -2   0 -37   5  51 -37 -26  21  -8 -24   6   6 -18\n",
      "  19   3 -19 -43  16  12  11 -33 -47  14  11  17 -12  -7  10   3 -13  23\n",
      " -29  25 -38   6 -22  33 -12  33 -27  -5]\n",
      "[ 3  3 24  5  4 11  1  9  4  3  6  4  3  9  7  4  5  2  3  7  8 12  5  2\n",
      "  1  3  4 14  4 10  4  2  3  3  3  5  5  2  4  9  6  1  5  3 11  2  3  8\n",
      "  5  6  4  5  4  3 10  9  4  4  8  7  1  4  8  4]\n",
      "[255 251 252 249 266 266 274 270 267 259 249 267 265 262 262 256 249 282\n",
      " 259 255 283 247 271 257 267 246 261 237 275 243 258 249 241 257 249 249\n",
      " 252 241 252 254 267 254 272 265 263 264 244 249 227 248 263 256 259 267\n",
      " 250 261 263 239 258 278 259 259 245 266]\n",
      "(64,)\n",
      "[-100  112 -165 -226   80  -68   77   72   10   -6  101  154 -148  -62\n",
      "   37  -31  -28   72  -73   40  233   -6  -32  -90  -76   58   11 -132\n",
      "  130  -69   93  -52  -89  153 -114 -206    7  180  -70   -8  -47 -142\n",
      "  -29 -126  -96 -105   11 -220    4    0   -1   51 -218 -209   73   45\n",
      "   90   11 -100    7  127  -68  217  -27]\n",
      "[ 82  91 119 168 106 111 111 144  98 128  76 125 107 179 173  99  87 102\n",
      " 137 177 106  94  90 128  85  86  84  88 111 101 136  85 140  93  74 222\n",
      "  67 262  76  92  94 364  84  98 116  84 161 145 103  86 129  74 116 172\n",
      "  79 107 149  95 134  92 118  86 184  94]\n",
      "[251 248 249 246 263 264 270 275 275 254 259 262 254 263 249 247 256 270\n",
      " 257 244 250 237 244 256 251 244 259 236 257 245 266 248 238 254 253 250\n",
      " 254 240 251 251 264 251 258 262 261 264 249 250 225 243 261 254 258 269\n",
      " 247 261 262 228 257 268 254 257 254 266]\n",
      "(64,)\n",
      "[ 11 -32  16  28  37  11  48   2  48  58   2 -64  21  35  15 -11   5  35\n",
      "  42 -24  30 -14  -4  -2  13 -12 -55   2  26   3  29 -31   5  44  13 -32\n",
      " -10 -51   9 -31 -10 -17   5 -50  37   0  -9   7  -2 -27  32  16  41 -14\n",
      " -21 -26  25  20  36  26  17 -42  30 -43]\n",
      "[ 2  6  3  3 16  3  8  7 10 10  3 25  6 10  6  3  4 11  8  9 10  3  4  1\n",
      "  6  3 16  1  5  2  8  7  1 11  3  3  2 28  2  5  4  1  5  8  4  3  2  1\n",
      "  1  3 10  5  6  2  3  6 10  5  4  9  5  8 11  6]\n",
      "[224 246 273 259 268 258 249 254 259 246 252 246 258 250 250 263 243 259\n",
      " 232 258 254 249 257 251 252 253 260 254 259 264 277 256 252 259 238 261\n",
      " 267 271 266 253 263 242 258 271 261 253 268 262 252 234 259 263 255 242\n",
      " 258 247 262 264 263 254 260 270 228 250 258 240 255 248 275 261 248 254\n",
      " 266 239 256 243 233 255 252 255 252 246 267 262 247 240 259 264 264 251\n",
      " 239 250 255 257 242 260 273 244 255 270 258 246 241 266 257 257 252 245\n",
      " 257 251 247 261 261 260 257 255 253 261 248 259 242 247 233 260 238 261\n",
      " 255 245]\n",
      "(128,)\n",
      "[  46  144   32   97   62  -83  -21   14   13  172    3  -33   13 -130\n",
      "   20    3  -34  -34  -31  -53   80 -122 -155   -6   -1  -48   77  -24\n",
      "   88  -30 -247  -56  -38  124   98  -49  -41   70  -11  -45   15  -41\n",
      "   51   13 -149  -87 -166  179  -12   15   62  -42  -45  -92  -32  -14\n",
      "  -19  -36   74  -69   53   19   37 -196  219   75 -138  115  166   61\n",
      "   -7  117   61   24    7  -76  -20  144  -72 -143   21   69  192 -143\n",
      "  -71   70   97   32   20   47  -43 -146  -45   57  -86   16  -87  -57\n",
      "   -8   32 -142  -57   51   99   23  126   15   22   24  -62   22  -24\n",
      "  102   89  -18  -50   25 -134   26  138  -28   55  -50    6  -68 -129\n",
      " -120   32]\n",
      "[ 85  88 151 113 118 177  74  88  85  72 109 113  68  88  93  87  85  81\n",
      "  64  94 166  81 133  57  83  72 168  92  59 127 316  67  63  84  67  93\n",
      " 139  87  85  66  77 109 124  79  72  81  78 235  70  68  84  94 132  79\n",
      "  95  59 106  93  79  76 114  90  80  89 123  72  77  84 120  79  81 168\n",
      "  82  54 152 126  90 131 108 108  46  94 103 185  77  67 156  87  65  73\n",
      "  90 140  92 124 109  71  72  90  49  87  79 100  77  85  78 152  76  56\n",
      "  88  77  63  84 105  74  62  71  93 205 102  92  71  64  56 106 127 149\n",
      " 107  73]\n",
      "[231 248 268 259 267 258 249 251 254 283 255 242 258 248 277 267 241 258\n",
      " 234 256 256 247 254 244 247 248 252 270 256 256 278 252 250 259 237 261\n",
      " 267 260 263 256 258 236 258 271 257 251 259 260 249 239 257 261 259 242\n",
      " 257 245 263 265 261 255 260 267 230 248 252 244 255 278 302 256 239 260\n",
      " 259 238 252 244 235 258 248 251 252 276 302 265 242 241 255 273 257 248\n",
      " 230 245 252 268 241 256 272 243 254 266 256 246 232 280 255 255 253 244\n",
      " 252 246 239 254 256 272 258 249 246 260 242 257 239 247 238 256 236 257\n",
      " 253 242]\n",
      "(128,)\n",
      "[ -6 -16   3 -39 -34  -5   6 -25  24  26  -3  14  30  25 -12 -10  -7  -4\n",
      " -10  29  10   6 -31  10 -15 -30 -11   5 -33  21   1 -26 -34 -35 -13   4\n",
      "   8   0  41  -4  21  24  -1  45  26 -35  25  -4  26  -5 -28  13  41 -14\n",
      "  -3  -5 -14 -37  39 -19  10 -33  -5  30  28  -7 -35  -8  -5 -32  16  -7\n",
      "  26 -23  27   4  -1  23  30  30 -15  26 -11  38   1 -10   1  -1   1  37\n",
      " -19  13   3  -7   6  17  33  13  -3 -53 -32  -1  24   0  19  13  27 -30\n",
      "   1 -28 -14   4  -9  20 -29  24 -35  22 -24 -31  17   3  -6  11   3 -31\n",
      "   3 -11]\n",
      "[ 1  3  3 11  6  1  1  7  4  5  2  1  5  1  3  4  2  3  1  3  3  1  3  2\n",
      "  3  3  3  4  5  2  1  3  3  9  2  2  2  3  7  2  3  2  2  7  4  3  4  4\n",
      "  3  2  5  3 11  3  1  2  4  4  9  3  3  8  1  2  6  3  4  4  4  7  3  3\n",
      "  6  2  9  1  1  8  3  2  3  3  6  4  2  2  2  3  2  5  4  1  1  3  1  2\n",
      "  5  1  1 13  3  1  4  4  4  4  2  4  1  5  3  2  3  4  3  3  7  2  5  7\n",
      "  1  2  1  2  1  3  2  3]\n",
      "[269 257 237 252 238 241 221 239 237 270 240 246 241 266 252 262 245 233\n",
      " 196 249 254 237 259 232 237 259 255 263 270 235 257 244 218 259 239 265\n",
      " 225 237 255 247 242 258 247 259 278 239 256 254 234 248 259 252 258 264\n",
      " 250 261 255 255 263 253 244 230 255 230 241 241 237 244 259 247 252 248\n",
      " 242 252 258 254 234 241 264 247 254 238 270 242 227 248 240 240 237 257\n",
      " 233 260 250 230 259 243 245 241 246 243 223 224 269 265 240 246 258 235\n",
      " 253 212 245 262 265 234 256 254 249 219 260 262 254 262 251 251 232 250\n",
      " 256 248 229 243 256 240 220 216 235 220 242 247 261 266 259 270 223 262\n",
      " 242 224 232 251 239 243 247 220 246 237 229 244 239 254 258 215 261 261\n",
      " 237 252 264 217 234 245 248 243 237 263 262 233 260 217 251 258 222 251\n",
      " 230 225 258 232 219 241 251 275 246 213 222 225 244 261 229 255 224 254\n",
      " 255 255 245 226 246 227 246 241 230 248 262 213 241 249 231 229 235 229\n",
      " 249 250 271 255 266 259 201 254 240 210 261 266 222 250 260 235 221 252\n",
      " 252 224 240 239 220 231 266 235 247 248 262 250 262 244 252 221 254 288\n",
      " 257 264 232 250]\n",
      "(256,)\n",
      "[  31    9  149  158 -138   70 -124   -9   97 -193 -109 -134  276 -120\n",
      "  294  -19  282  -34   42  139  -11  227   20  -77    9   -4  -92  -28\n",
      "  -95   25  -88 -107   47   72   20 -103  137  -58  116 -112  -50  -85\n",
      "   70   82   50   91  104  111    3  129  153  123  250  113  -88  134\n",
      "   70   37  -55  -19  -54   16  -21   40 -135   89  -27  221  -64  117\n",
      "  -44 -108  111  -77  -99  276   45  -57  -58    9  162  159   -4 -192\n",
      "   67   27   96   42   82   -7  165  162  -21   31    8   43  -41 -160\n",
      "   78 -160  -13  186   22  -87  202   31  170  110   52   15   43  142\n",
      "  -45   42   94  127   49  -41  -83  -85   19  -87  -40 -162  -79  -41\n",
      "  216  -11  137   53  195 -116  -88   39   58   62  129   -9 -184 -163\n",
      "  133  -48   83  119  -24  214  129   53  119  -11  -77  106  -31  -39\n",
      "   90  -10    4  220  -37 -131    7  205  161   78   17 -143    5  109\n",
      "  115   -4  -63  107 -114   59   51  112   30  -53   50  -48  -15  102\n",
      "  -87 -114  152  -15  -97   84  -39 -175   -5   14  -28  -46   36   84\n",
      "   23   53   81   32   84   96   57  127  198  -41  -35   24  176  155\n",
      "  143  -34  -43   53  -43   84 -111  -58   56   99  222  110  -50   82\n",
      "  -13   23  -13 -134  -30  181   33  -11  -69   25  119 -128 -122   67\n",
      "  -25   65  -50 -125   94  201   28  -74   41 -235  -50  103 -163   63\n",
      "  -60  -25   68   91]\n",
      "[199  84  76  88  75  67 103  82  58 106 147 123 153 133 167 120 130  67\n",
      " 144  87 120  92 110 109  83 118 159  97 149  64 107  68  82 118  44  87\n",
      " 119 134  88 169 119  94  79 107 135 144 187 134  76  93 135 127 153 144\n",
      "  72 181  75 160 123 136 103  93 101  55  65 110 110 159  80 111 147  94\n",
      "  67  65  77 101  51  99 127  71  72  87 146 165  65 100  98  92  71 123\n",
      "  72 176 102  67 133  83 124 102 128  55  91 139 125 106 107 129 151 180\n",
      "  89 114  66 121  94  68 145 218 130 160  96 102 124  93 111 173  94  89\n",
      " 160 158  58  95 109  91  82  59 124  73  82  95 202 220 134 132 139  96\n",
      " 128 120 125 119  87 148  72  76 104  58  67 118  54 143 102 100  81 156\n",
      "  75 152 138  64 136  93 121 127  83 120 116  62 200 146  90  94  65 110\n",
      "  74  62  91 100  80  99  84 163  89  71 101  65 123 103  95 162  50  86\n",
      "  96 140  83  60  90 101 151  90  52  61  87 164 196 110  83  77  73  99\n",
      " 105 121 154  92 263 154  67 124  70  87 117 118  76 129 129  54  67 104\n",
      " 213 109 116  63  77  78 141 161  80  91  96  87  69  95  81 106 170 239\n",
      "  68 130  66 133]\n",
      "[265 259 245 257 240 233 222 239 238 269 241 241 256 264 254 264 242 233\n",
      " 281 246 271 274 255 227 238 259 249 261 274 235 255 245 220 258 241 264\n",
      " 232 236 260 240 295 255 246 259 274 233 250 261 235 244 252 251 253 260\n",
      " 248 257 254 302 267 249 244 225 254 224 236 239 230 270 260 242 247 240\n",
      " 239 248 255 250 229 241 263 245 254 242 266 242 226 245 260 236 237 282\n",
      " 232 252 253 230 258 242 239 240 243 240 224 297 264 275 236 291 253 296\n",
      " 252 215 242 264 274 233 282 248 253 227 260 261 251 268 273 247 227 247\n",
      " 278 248 227 240 262 235 222 220 235 222 243 245 260 263 252 266 218 260\n",
      " 241 242 292 252 237 242 244 223 247 236 234 240 238 252 257 220 257 268\n",
      " 238 269 263 225 227 239 241 240 238 265 261 235 262 275 247 271 215 252\n",
      " 224 224 257 231 230 256 247 274 244 216 226 230 242 260 228 252 232 252\n",
      " 255 268 244 222 245 283 255 241 230 243 260 281 237 237 227 229 222 224\n",
      " 249 260 266 249 263 261 211 257 233 216 258 275 219 257 257 232 221 249\n",
      " 252 219 236 240 224 232 266 237 248 255 256 247 268 243 249 254 252 301\n",
      " 254 260 223 279]\n",
      "(256,)\n",
      "[-30  -1   0  -4   8 -13  -5 -10  -4 -47  -1  15  -3   3  29  30  -8  -1\n",
      "  -1  -1   5   0 -29   2   0 -26  20  35  -6 -10  33  20   3  -1  -7 -30\n",
      "  -7  -4  23  -9   4 -27  -3  -1 -42 -11   0  28  -3   4  22 -10 -19 -27\n",
      " -16 -27 -29  -5  42 -17  21  -9  26  -1 -10   0 -15  23  25 -10 -26  14\n",
      "  11  -1 -33   7  -4  -3  20  -5   1  -4 -37  12  -9  -9  -4 -19  -5   7\n",
      "  -4 -13  22   1   0  -8  -8  -2  12  -4  -7  -1  17  31  -5  -1  22   5\n",
      "  23  -8  17  27  39  -6  32  27  -2  -1  20   1 -19  33  -2  26   1  12\n",
      "  -2  -2  -4  11  23  -5   2  -5  -8  -6   0   4  32   0  25   7  -5 -31\n",
      "  -1  -4   8  -5  -7  -4 -16  -6  12   0  -1  -7  -1  18  -1 -11 -31  34\n",
      "   0  20   0  -2  -8 -24  14 -20  -5  -6   0  -2  -1  -3 -20  40  -7  -5\n",
      "  -8  -7  29  -6  -6  19  21 -36  -4  -3  -5  -1   9  -6  -1  24   2  -4\n",
      "  24  29  -5  -7   2   3   2  -1  -5 -20 -27   5 -19  17   9   3 -17  -3\n",
      "  -3  -4 -36 -28   4 -10  -2 -26  11  -2  21  39  -6   4 -27 -12  -6  26\n",
      " -11  -9  -4  -1  -2  -2  22   9  -5   5 -33   1   4 -10  20  -4  27  -8\n",
      "   2 -32  -9  30]\n",
      "[4 2 1 2 0 2 0 1 0 6 0 1 2 2 7 4 1 0 1 1 1 2 4 0 1 3 3 5 2 1 5 2 0 1 1 4 1\n",
      " 0 4 1 2 2 2 1 7 2 2 5 0 1 5 2 4 5 2 3 4 3 6 2 2 1 4 1 1 1 2 4 2 2 3 2 1 1\n",
      " 4 2 1 1 3 1 1 1 7 1 1 2 1 2 1 1 1 2 2 1 1 1 0 1 1 1 1 2 4 7 1 2 3 1 3 1 2\n",
      " 4 8 1 6 8 1 0 3 2 3 5 1 3 2 1 2 1 1 1 4 1 0 0 1 1 1 2 5 1 5 2 1 6 0 2 2 2\n",
      " 1 1 2 1 2 1 0 1 1 3 2 1 5 7 0 2 1 0 1 3 3 4 1 2 1 0 1 3 2 6 1 1 1 0 4 1 1\n",
      " 2 2 8 1 0 0 0 1 2 1 5 0 2 3 4 1 1 1 2 1 1 0 2 3 1 3 3 1 0 2 1 1 1 7 3 1 3\n",
      " 0 4 1 0 3 9 1 2 3 1 1 4 3 1 1 0 0 1 3 0 1 2 5 1 2 1 3 2 3 3 2 6 1 4]\n",
      "[268 257 263 267 281 258 264 285 278 258 261 261 274 269 271 257 259 270\n",
      " 278 260 276 262 268 266 261 262 261 267 277 265 268 291 277 269 257 265\n",
      " 260 245 260 257 269 270 270 263 267 266 265 270 263 260 284 266 271 268\n",
      " 269 264 278 256 259 260 265 256 266 267 271 273 268 261 260 264 263 269\n",
      " 267 267 268 280 253 266 269 264 294 260 268 258 274 263 261 265 264 261\n",
      " 266 268 248 254 272 272 261 264 268 258 274 275 256 263 277 258 267 261\n",
      " 254 266 255 293 258 264 268 266 263 280 250 257 270 280 259 275 263 297\n",
      " 256 261 266 265 259 264 265 263 271 270 258 263 275 261 297 267 286 256\n",
      " 258 272 269 269 265 273 260 273 260 261 267 269 263 266 268 264 265 262\n",
      " 260 267 260 262 272 262 269 258 289 255 261 256 267 254 260 275 260 272\n",
      " 258 273 266 267 267 262 271 262 260 253 264 262 265 262 263 264 258 265\n",
      " 260 262 258 254 256 259 258 263 262 270 254 273 265 260 272 271 258 266\n",
      " 249 271 265 281 280 266 275 259 292 271 266 275 257 263 262 258 279 282\n",
      " 278 264 259 260 255 273 255 267 278 254 261 263 271 260 257 265 264 264\n",
      " 267 265 263 278]\n",
      "(256,)\n",
      "[ 130   51  109  -77  -79 -135  160  142  153   39  168  -24   17  216\n",
      "  185   16  190  235  150  139   -1 -110   41  264   14   94  -89  271\n",
      "  -65  209   64  136   93  -50  -98  -63  -29    6   54   75 -135  161\n",
      "  -20  260  -39   21  -90  -18  137  -18  156   92   70   91  282    7\n",
      "  -63  -32   76   73  145   73 -152  242  128  -14 -101  135  116  162\n",
      "  283 -121  249  306  -15  141  -85   39 -219  111   93  109  182    6\n",
      "   14  -57   -6   78 -130 -163   53   25 -146  -94  180  177   70  117\n",
      "  -97   -6  103  155  -46  127  -72   68    7   23 -170   98   51   79\n",
      "  -22   26    8  121  -42   47 -109  -38   71  -56  157  131    4  145\n",
      "   60  -30  281 -134  -32  202   55 -151   17  -48   86   75   59   -9\n",
      "   68  -13   84  -20   76   81   15    0  222  396  144    5  -51  -10\n",
      "   70  288  -16  200  269  237  262  165  -54  175   -3  109  -89  153\n",
      "   86   36  112 -107  -90   62  -66  157  -94  -33   39  172  138   25\n",
      "   89  -70  132  150   54   14  327   28  109  327  -56  281  114  -60\n",
      "   25  208  -71   84   78   48 -129   25   27 -186  -89  141 -147  115\n",
      "  118   24  309  190   46  142  -32  -80  115   37  118  164  -13  148\n",
      "   47   12 -129   33 -160 -104  -77 -131  149   54  158    4  162  -49\n",
      "  150 -110 -116   41   -5   19 -136  141   24   15  163  124 -216  -62\n",
      "  -93  204  104   88]\n",
      "[229 218 294 156 251 173 273 229 187 268 138 171 252 206 288 194 157 306\n",
      " 194 188 208 134 219 251 169 219 171 274 252 204 239 243 202 192 159 327\n",
      " 187 123 327 195 183 181 241 185 175 273 207 224 228 214 216 301 233 227\n",
      " 297 188 246 193 223 185 246 218 189 176 244 256 388 294 181 225 241 238\n",
      " 205 283 218 202 173 241 470 195 250 169 250 221 220 178 159 190 377 290\n",
      " 166 252  75 178 219 208 150 205 226 222 228 207 142 177 224 171 219 221\n",
      " 183 263 225 256 155 259 280 220 158 243 242 168 238 243 193 292 165 282\n",
      " 183 211 272 208 229 231 206 135 253 192 258 316 337 166 283 215 211 161\n",
      " 156 232 233 169 385 440 125 252 185 174 284 275 183 231 193 222 228 247\n",
      " 160 221 160 176 194 207 267 210 219 149 176 182 167 144 136 227 199 240\n",
      " 128 251 211 135 198 184 195 205 189 235 268 298 185 428 192 174 162 381\n",
      " 266 225 162 160  96 172 149 176 184 241 182 192 193 153 249 258 174 247\n",
      " 160 220 204 241 230 250 225 296 232 275 187 222 381 181 193 164 343 231\n",
      " 220 164 278 145 111 194 165 240 178 131 150 199 308 158 172 273 339 153\n",
      " 206 208 207 229]\n"
     ]
    }
   ],
   "source": [
    "for layer in mobilenetv1lite.layers:\n",
    "    if isinstance(layer,BatchNormalization):\n",
    "        # Get the weights\n",
    "        weights = layer.get_weights()\n",
    "        weights=ftf(weights)\n",
    "# Unpack the weights\n",
    "        gamma, beta, moving_mean, moving_variance = weights\n",
    "        print(gamma)\n",
    "        print(beta.shape)\n",
    "        print(moving_mean)\n",
    "        print(moving_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv1liteQuantized=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenetv1lite.layers[:-1]:\n",
    "    mobilenetv1liteQuantized.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m32,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m65,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,744</span> (491.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m125,744\u001b[0m (491.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,832</span> (479.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,832\u001b[0m (479.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,912</span> (11.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,912\u001b[0m (11.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobilenetv1liteQuantized.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\Documents\\\\GitHub\\\\CNN-ON-FPGA-MSc.-\\\\Training Model(Python)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:65\u001b[1;36m\u001b[0m\n\u001b[1;33m    //return res\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import ml_dtypes\n",
    "\n",
    "from keras.src import activations\n",
    "from keras.src import constraints\n",
    "from keras.src import dtype_policies\n",
    "from keras.src import initializers\n",
    "from keras.src import ops\n",
    "from keras.src import quantizers\n",
    "from keras.src import regularizers\n",
    "from keras.src.api_export import keras_export\n",
    "from keras.src.layers.input_spec import InputSpec\n",
    "from keras.src.layers.layer import Layer\n",
    "import numpy \n",
    "#@tf.custom_gradient\n",
    "def bitshift(weight,shift):\n",
    "  res=0\n",
    "  if shift<0:\n",
    "       y=tf.math.abs(shift)\n",
    "       res= tf.bitwise.right_shift(weight,y)\n",
    "  else:\n",
    "       res= tf.bitwise.left_shift(weight,shift)\n",
    "def MatrixBitShift(A,B):\n",
    "    #def grd(dy):\n",
    "     #   G=ops.matmult(dy,ops.transpose(D))\n",
    "      #  return G\n",
    "\n",
    "    A=tf.cast(A,tf.int32)\n",
    "    B=tf.cast(B,tf.int32)\n",
    "    columns2=tf.shape(B)[1]\n",
    "    rows2=tf.shape(B)[0]\n",
    "    rows1=tf.shape(A)[0]\n",
    "    C=tf.zeros(shape=(rows1,columns2),dtype=tf.int32)\n",
    "    for i in range(0,rows1):\n",
    "      for j in range(0,rows2):\n",
    "            for  k in range(0,columns2):\n",
    "                original=C[i][k]\n",
    "                a=A[i][j]\n",
    "                b=B[j][k]\n",
    "                x=bitshift(a,b)\n",
    "                #print(x)\n",
    "                update=original+x\n",
    "                \n",
    "                index=tf.constant([[i,k]])\n",
    "                #u=tf.constant([update],dtype=tf.int32)\n",
    "                C=tf.tensor_scatter_nd_update(C,index,[update])\n",
    "    \n",
    "    return C\n",
    "\n",
    "def Quantizeweights(weights):\n",
    "    #weights=weights.numpy()\n",
    "    weights_absolute=tf.abs(weights)\n",
    "    maxweight=tf.reduce_max(weights_absolute)\n",
    "    #print(maxweight)\n",
    "    scaled_weights=weights/maxweight\n",
    "    #print(scaled_weights)\n",
    "    lq=LQ(scaled_weights,4)\n",
    "    #print(f'aloha {lq}')\n",
    "    return lq\n",
    "#@tf.custom_gradient\n",
    "\n",
    " # def grad(dy):\n",
    "  #     dw=2**shift*dy\n",
    "   #    ds=2**shift*weight*tf.math.log(2)*dy\n",
    "    #   return dw,ds\n",
    "#return res\n",
    "    \n",
    "    #pot_vect=numpy.vectorize(powertwo)\n",
    "    #final_weights=pot_vect(lq,maxweight)\n",
    "    #print(final_weights)\n",
    "\n",
    "\n",
    "\n",
    "def check_integer_zero_and_first_two_decimals_zero(number):\n",
    "    # Check if the integer part is zero\n",
    "    if int(number) != 0:\n",
    "        return False\n",
    "    \n",
    "    # Convert the number to a string\n",
    "    num_str = str(number)\n",
    "    \n",
    "    # Find the decimal point\n",
    "    decimal_point_index = num_str.find('.')\n",
    "    \n",
    "    # Check if there is a decimal point and if the length after the decimal point is at least 2\n",
    "    if decimal_point_index != -1 and len(num_str) > decimal_point_index + 2:\n",
    "        # Get the first two decimal places\n",
    "        first_two_decimals = num_str[decimal_point_index + 1:decimal_point_index + 3]\n",
    "        # Check if the first two decimal places are \"00\"\n",
    "        return first_two_decimals == \"00\"\n",
    "    \n",
    "    # If there are no decimal places or less than two decimal places, return False\n",
    "    return False\n",
    "def clip(weight,bitwidth):\n",
    "    \n",
    "    weight_log=numpy.round(numpy.log2(numpy.absolute(weight)))\n",
    "    bit_pot=-2**bitwidth\n",
    "    if weight_log<bit_pot:\n",
    "        return 0\n",
    "    elif weight_log>=0:\n",
    "        return -1\n",
    "    else:\n",
    "        return weight_log\n",
    "def LQ(tensor, bitwidth):\n",
    "    # Create a mask for weights equal to 0\n",
    "    #rounded_tensor=tf.where(tensor>0,tf.my u4xdcvp]\n",
    "    # [6ath.floor(tensor),tf.math.ceil(tensor))\n",
    "    rounded_weights=tensor*100\n",
    "    rounded_weights=tf.where(rounded_weights>0,tf.math.floor(rounded_weights),tf.math.ceil(rounded_weights))\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    # Compute weight_log using log2\n",
    "    weight_log = tf.math.log(tf.math.abs(tensor)+epsilon) / tf.math.log(2.0)\n",
    "    #print(weight_log)\n",
    "    weight_log=tf.where(weight_log<0,tf.math.ceil(weight_log),tf.math.floor(weight_log))\n",
    "    bit_pot = -2 ** bitwidth\n",
    "    mask_condition = weight_log >= bit_pot\n",
    "    \n",
    "    # Initialize the result tensor with zeros\n",
    "    result = tf.zeros_like(tensor, dtype=tf.float32)\n",
    "    \n",
    "    # Apply the condition where weight_log is valid\n",
    "    result = tf.where(rounded_weights!=0,tf.where(mask_condition, tf.where(tensor > 0, tf.math.abs(weight_log), weight_log), result),result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def powertwo(weight,sf):\n",
    "    pot_weight=(2**weight)*sf\n",
    "    return pot_weight\n",
    "    \n",
    "\n",
    "class QDense(Layer):\n",
    "    \"\"\"Just your regular densely-connected NN layer with Quantized weights and bit shifting.\n",
    "\n",
    "    `Dense` implements the operation:\n",
    "    `output = activation(dot(input, kernel) + bias)`\n",
    "    where `activation` is the element-wise activation function\n",
    "    passed as the `activation` argument, `kernel` is a weights matrix\n",
    "    created by the layer, and `bias` is a bias vector created by the layer\n",
    "    (only applicable if `use_bias` is `True`).\n",
    "\n",
    "    Note: If the input to the layer has a rank greater than 2, `Dense`\n",
    "    computes the dot product between the `inputs` and the `kernel` along the\n",
    "    last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\n",
    "    For example, if input has dimensions `(batch_size, d0, d1)`, then we create\n",
    "    a `kernel` with shape `(d1, units)`, and the `kernel` operates along axis 2\n",
    "    of the `input`, on every sub-tensor of shape `(1, 1, d1)` (there are\n",
    "    `batch_size * d0` such sub-tensors). The output in this case will have\n",
    "    shape `(batch_size, d0, units)`.\n",
    "\n",
    "    Args:\n",
    "        units: Positive integer, dimensionality of the output space.\n",
    "        activation: Activation function to use.\n",
    "            If you don't specify anything, no activation is applied\n",
    "            (ie. \"linear\" activation: `a(x) = x`).\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "        kernel_initializer: Initializer for the `kernel` weights matrix.\n",
    "        bias_initializer: Initializer for the bias vector.\n",
    "        kernel_regularizer: Regularizer function applied to\n",
    "            the `kernel` weights matrix.\n",
    "        bias_regularizer: Regularizer function applied to the bias vector.\n",
    "        activity_regularizer: Regularizer function applied to\n",
    "            the output of the layer (its \"activation\").\n",
    "        kernel_constraint: Constraint function applied to\n",
    "            the `kernel` weights matrix.\n",
    "        bias_constraint: Constraint function applied to the bias vector.\n",
    "        lora_rank: Optional integer. If set, the layer's forward pass\n",
    "            will implement LoRA (Low-Rank Adaptation)\n",
    "            with the provided rank. LoRA sets the layer's kernel\n",
    "            to non-trainable and replaces it with a delta over the\n",
    "            original kernel, obtained via multiplying two lower-rank\n",
    "            trainable matrices. This can be useful to reduce the\n",
    "            computation cost of fine-tuning large dense layers.\n",
    "            You can also enable LoRA on an existing\n",
    "            `Dense` layer by calling `layer.enable_lora(rank)`.\n",
    "\n",
    "    Input shape:\n",
    "        N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
    "        The most common situation would be\n",
    "        a 2D input with shape `(batch_size, input_dim)`.\n",
    "\n",
    "    Output shape:\n",
    "        N-D tensor with shape: `(batch_size, ..., units)`.\n",
    "        For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
    "        the output would have shape `(batch_size, units)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        lora_rank=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_enabled = False\n",
    "        self.input_spec = InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        # We use `self._dtype_policy` to check to avoid issues in torch dynamo\n",
    "        is_quantized = isinstance(\n",
    "            self._dtype_policy, dtype_policies.QuantizedDTypePolicy\n",
    "        )\n",
    "        if is_quantized:\n",
    "            self.quantized_build(\n",
    "                input_shape, mode=self.dtype_policy.quantization_mode\n",
    "            )\n",
    "        if not is_quantized or self.dtype_policy.quantization_mode != \"int8\":\n",
    "            # If the layer is quantized to int8, `self._kernel` will be added\n",
    "            # in `self._int8_build`. Therefore, we skip it here.\n",
    "            self._kernel = self.add_weight(\n",
    "                name=\"kernel\",\n",
    "                shape=(input_dim, self.units),\n",
    "                initializer=self.kernel_initializer,\n",
    "                regularizer=self.kernel_regularizer,\n",
    "                constraint=self.kernel_constraint,\n",
    "            )\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                name=\"bias\",\n",
    "                shape=(self.units,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "            )\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        self.built = True\n",
    "        if self.lora_rank:\n",
    "            self.enable_lora(self.lora_rank)\n",
    "\n",
    "    @property\n",
    "    def kernel(self):\n",
    "        if not self.built:\n",
    "            raise AttributeError(\n",
    "                \"You must build the layer before accessing `kernel`.\"\n",
    "            )\n",
    "        if self.lora_enabled:\n",
    "            return self._kernel + ops.matmul(\n",
    "                self.lora_kernel_a, self.lora_kernel_b\n",
    "            )\n",
    "        return self._kernel\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        quantized_weights=Quantizeweights(self.kernel)\n",
    "        #x = ops.matmul(inputs, self.kernel)\n",
    "        x=MatrixBitShift(inputs,quantized_weights,self.kernel)\n",
    "        if self.bias is not None:\n",
    "            x = ops.add(x, self.bias)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def enable_lora(\n",
    "        self, rank, a_initializer=\"he_uniform\", b_initializer=\"zeros\"\n",
    "    ):\n",
    "        if self.kernel_constraint:\n",
    "            raise ValueError(\n",
    "                \"Lora is incompatible with kernel constraints. \"\n",
    "                \"In order to enable lora on this layer, remove the \"\n",
    "                \"`kernel_constraint` argument.\"\n",
    "            )\n",
    "        if not self.built:\n",
    "            raise ValueError(\n",
    "                \"Cannot enable lora on a layer that isn't yet built.\"\n",
    "            )\n",
    "        if self.lora_enabled:\n",
    "            raise ValueError(\n",
    "                \"lora is already enabled. \"\n",
    "                \"This can only be done once per layer.\"\n",
    "            )\n",
    "        self._tracker.unlock()\n",
    "        self.lora_kernel_a = self.add_weight(\n",
    "            name=\"lora_kernel_a\",\n",
    "            shape=(self.kernel.shape[0], rank),\n",
    "            initializer=initializers.get(a_initializer),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "        )\n",
    "        self.lora_kernel_b = self.add_weight(\n",
    "            name=\"lora_kernel_b\",\n",
    "            shape=(rank, self.kernel.shape[1]),\n",
    "            initializer=initializers.get(b_initializer),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "        )\n",
    "        self._kernel.trainable = False\n",
    "        self._tracker.lock()\n",
    "        self.lora_enabled = True\n",
    "        self.lora_rank = rank\n",
    "\n",
    "    def save_own_variables(self, store):\n",
    "        # Do nothing if the layer isn't yet built\n",
    "        if not self.built:\n",
    "            return\n",
    "        # The keys of the `store` will be saved as determined because the\n",
    "        # default ordering will change after quantization\n",
    "        kernel_value, kernel_scale = self._get_kernel_with_merged_lora()\n",
    "        target_variables = [kernel_value]\n",
    "        if self.use_bias:\n",
    "            target_variables.append(self.bias)\n",
    "        if isinstance(self.dtype_policy, dtype_policies.QuantizedDTypePolicy):\n",
    "            mode = self.dtype_policy.quantization_mode\n",
    "            if mode == \"int8\":\n",
    "                target_variables.append(kernel_scale)\n",
    "            elif mode == \"float8\":\n",
    "                target_variables.append(self.inputs_scale)\n",
    "                target_variables.append(self.inputs_amax_history)\n",
    "                target_variables.append(self.kernel_scale)\n",
    "                target_variables.append(self.kernel_amax_history)\n",
    "                target_variables.append(self.outputs_grad_scale)\n",
    "                target_variables.append(self.outputs_grad_amax_history)\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "                )\n",
    "        for i, variable in enumerate(target_variables):\n",
    "            store[str(i)] = variable\n",
    "\n",
    "    def load_own_variables(self, store):\n",
    "        if not self.lora_enabled:\n",
    "            self._check_load_own_variables(store)\n",
    "        # Do nothing if the layer isn't yet built\n",
    "        if not self.built:\n",
    "            return\n",
    "        # The keys of the `store` will be saved as determined because the\n",
    "        # default ordering will change after quantization\n",
    "        target_variables = [self._kernel]\n",
    "        if self.use_bias:\n",
    "            target_variables.append(self.bias)\n",
    "        if isinstance(self.dtype_policy, dtype_policies.QuantizedDTypePolicy):\n",
    "            mode = self.dtype_policy.quantization_mode\n",
    "            if mode == \"int8\":\n",
    "                target_variables.append(self.kernel_scale)\n",
    "            elif mode == \"float8\":\n",
    "                target_variables.append(self.inputs_scale)\n",
    "                target_variables.append(self.inputs_amax_history)\n",
    "                target_variables.append(self.kernel_scale)\n",
    "                target_variables.append(self.kernel_amax_history)\n",
    "                target_variables.append(self.outputs_grad_scale)\n",
    "                target_variables.append(self.outputs_grad_amax_history)\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "                )\n",
    "        for i, variable in enumerate(target_variables):\n",
    "            variable.assign(store[str(i)])\n",
    "        if self.lora_enabled:\n",
    "            self.lora_kernel_a.assign(ops.zeros(self.lora_kernel_a.shape))\n",
    "            self.lora_kernel_b.assign(ops.zeros(self.lora_kernel_b.shape))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        config = {\n",
    "            \"units\": self.units,\n",
    "            \"activation\": activations.serialize(self.activation),\n",
    "            \"use_bias\": self.use_bias,\n",
    "            \"kernel_initializer\": initializers.serialize(\n",
    "                self.kernel_initializer\n",
    "            ),\n",
    "            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n",
    "            \"kernel_regularizer\": regularizers.serialize(\n",
    "                self.kernel_regularizer\n",
    "            ),\n",
    "            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n",
    "            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n",
    "            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n",
    "        }\n",
    "        if self.lora_rank:\n",
    "            config[\"lora_rank\"] = self.lora_rank\n",
    "        return {**base_config, **config}\n",
    "\n",
    "    def _check_load_own_variables(self, store):\n",
    "        all_vars = self._trainable_variables + self._non_trainable_variables\n",
    "        if len(store.keys()) != len(all_vars):\n",
    "            if len(all_vars) == 0 and not self.built:\n",
    "                raise ValueError(\n",
    "                    f\"Layer '{self.name}' was never built \"\n",
    "                    \"and thus it doesn't have any variables. \"\n",
    "                    f\"However the weights file lists {len(store.keys())} \"\n",
    "                    \"variables for this layer.\\n\"\n",
    "                    \"In most cases, this error indicates that either:\\n\\n\"\n",
    "                    \"1. The layer is owned by a parent layer that \"\n",
    "                    \"implements a `build()` method, but calling the \"\n",
    "                    \"parent's `build()` method did NOT create the state of \"\n",
    "                    f\"the child layer '{self.name}'. A `build()` method \"\n",
    "                    \"must create ALL state for the layer, including \"\n",
    "                    \"the state of any children layers.\\n\\n\"\n",
    "                    \"2. You need to implement \"\n",
    "                    \"the `def build_from_config(self, config)` method \"\n",
    "                    f\"on layer '{self.name}', to specify how to rebuild \"\n",
    "                    \"it during loading. \"\n",
    "                    \"In this case, you might also want to implement the \"\n",
    "                    \"method that generates the build config at saving time, \"\n",
    "                    \"`def get_build_config(self)`. \"\n",
    "                    \"The method `build_from_config()` is meant \"\n",
    "                    \"to create the state \"\n",
    "                    \"of the layer (i.e. its variables) upon deserialization.\",\n",
    "                )\n",
    "            raise ValueError(\n",
    "                f\"Layer '{self.name}' expected {len(all_vars)} variables, \"\n",
    "                \"but received \"\n",
    "                f\"{len(store.keys())} variables during loading. \"\n",
    "                f\"Expected: {[v.name for v in all_vars]}\"\n",
    "            )\n",
    "\n",
    "    \"\"\"Quantization-related (int8 and float8) methods\"\"\"\n",
    "\n",
    "    QUANTIZATION_MODE_ERROR_TEMPLATE = (\n",
    "        f\"Invalid quantization mode. Expected one of \"\n",
    "        f\"{dtype_policies.QUANTIZATION_MODES}. \"\n",
    "        \"Received: quantization_mode={mode}\"\n",
    "    )\n",
    "\n",
    "    def quantized_build(self, input_shape, mode):\n",
    "        if mode == \"int8\":\n",
    "            input_dim = input_shape[-1]\n",
    "            kernel_shape = (input_dim, self.units)\n",
    "            self._int8_build(kernel_shape)\n",
    "        elif mode == \"float8\":\n",
    "            self._float8_build()\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "            )\n",
    "\n",
    "    def _int8_build(\n",
    "        self,\n",
    "        kernel_shape,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        kernel_scale_initializer=\"ones\",\n",
    "    ):\n",
    "        self.inputs_quantizer = quantizers.AbsMaxQuantizer(axis=-1)\n",
    "        self._kernel = self.add_weight(\n",
    "            name=\"kernel\",\n",
    "            shape=kernel_shape,\n",
    "            initializer=kernel_initializer,\n",
    "            dtype=\"int8\",\n",
    "            trainable=False,\n",
    "        )\n",
    "        self.kernel_scale = self.add_weight(\n",
    "            name=\"kernel_scale\",\n",
    "            shape=(self.units,),\n",
    "            initializer=kernel_scale_initializer,\n",
    "            trainable=False,\n",
    "        )\n",
    "        self._is_quantized = True\n",
    "\n",
    "    def _float8_build(self):\n",
    "        if not isinstance(\n",
    "            self.dtype_policy, dtype_policies.QuantizedFloat8DTypePolicy\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"`self.dtype_policy` must be the type of \"\n",
    "                f\"QuantizedFloat8DTypePolicy. Received {self.dtype_policy}\"\n",
    "            )\n",
    "        amax_history_length = self.dtype_policy.amax_history_length\n",
    "        # We set `trainable=True` because we will use the gradients to overwrite\n",
    "        # these variables\n",
    "        scale_kwargs = {\n",
    "            \"shape\": (),\n",
    "            \"initializer\": \"ones\",\n",
    "            \"dtype\": \"float32\",  # Always be float32\n",
    "            \"trainable\": True,\n",
    "            \"autocast\": False,\n",
    "        }\n",
    "        amax_history_kwargs = {\n",
    "            \"shape\": (amax_history_length,),\n",
    "            \"initializer\": \"zeros\",\n",
    "            \"dtype\": \"float32\",  # Always be float32\n",
    "            \"trainable\": True,\n",
    "            \"autocast\": False,\n",
    "        }\n",
    "        self.inputs_scale = self.add_weight(name=\"inputs_scale\", **scale_kwargs)\n",
    "        self.inputs_amax_history = self.add_weight(\n",
    "            name=\"inputs_amax_history\", **amax_history_kwargs\n",
    "        )\n",
    "        self.kernel_scale = self.add_weight(name=\"kernel_scale\", **scale_kwargs)\n",
    "        self.kernel_amax_history = self.add_weight(\n",
    "            name=\"kernel_amax_history\", **amax_history_kwargs\n",
    "        )\n",
    "        self.outputs_grad_scale = self.add_weight(\n",
    "            name=\"outputs_grad_scale\", **scale_kwargs\n",
    "        )\n",
    "        self.outputs_grad_amax_history = self.add_weight(\n",
    "            name=\"outputs_grad_amax_history\", **amax_history_kwargs\n",
    "        )\n",
    "        # We need to set `overwrite_with_gradient=True` to instruct the\n",
    "        # optimizer to directly overwrite these variables with their computed\n",
    "        # gradients during training\n",
    "        self.inputs_scale.overwrite_with_gradient = True\n",
    "        self.inputs_amax_history.overwrite_with_gradient = True\n",
    "        self.kernel_scale.overwrite_with_gradient = True\n",
    "        self.kernel_amax_history.overwrite_with_gradient = True\n",
    "        self.outputs_grad_scale.overwrite_with_gradient = True\n",
    "        self.outputs_grad_amax_history.overwrite_with_gradient = True\n",
    "        self._is_quantized = True\n",
    "\n",
    "    def quantized_call(self, inputs):\n",
    "        if self.dtype_policy.quantization_mode == \"int8\":\n",
    "            return self._int8_call(inputs)\n",
    "        elif self.dtype_policy.quantization_mode == \"float8\":\n",
    "            return self._float8_call(inputs)\n",
    "        else:\n",
    "            mode = self.dtype_policy.quantization_mode\n",
    "            raise NotImplementedError(\n",
    "                self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "            )\n",
    "\n",
    "    def _int8_call(self, inputs):\n",
    "        @ops.custom_gradient\n",
    "        def matmul_with_inputs_gradient(inputs, kernel, kernel_scale):\n",
    "            def grad_fn(*args, upstream=None):\n",
    "                if upstream is None:\n",
    "                    (upstream,) = args\n",
    "                float_kernel = ops.divide(\n",
    "                    ops.cast(kernel, dtype=self.compute_dtype),\n",
    "                    kernel_scale,\n",
    "                )\n",
    "                inputs_grad = ops.matmul(upstream, ops.transpose(float_kernel))\n",
    "                return (inputs_grad, None, None)\n",
    "\n",
    "            inputs, inputs_scale = self.inputs_quantizer(inputs)\n",
    "            x = ops.matmul(inputs, kernel)\n",
    "            # De-scale outputs\n",
    "            x = ops.cast(x, self.compute_dtype)\n",
    "            x = ops.divide(x, ops.multiply(inputs_scale, kernel_scale))\n",
    "            return x, grad_fn\n",
    "\n",
    "        x = matmul_with_inputs_gradient(\n",
    "            inputs,\n",
    "            ops.convert_to_tensor(self._kernel),\n",
    "            ops.convert_to_tensor(self.kernel_scale),\n",
    "        )\n",
    "        if self.lora_enabled:\n",
    "            lora_x = ops.matmul(inputs, self.lora_kernel_a)\n",
    "            lora_x = ops.matmul(lora_x, self.lora_kernel_b)\n",
    "            x = ops.add(x, lora_x)\n",
    "        if self.bias is not None:\n",
    "            x = ops.add(x, self.bias)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def _float8_call(self, inputs):\n",
    "        if self.lora_enabled:\n",
    "            raise NotImplementedError(\n",
    "                \"Currently, `_float8_call` doesn't support LoRA\"\n",
    "            )\n",
    "\n",
    "        @ops.custom_gradient\n",
    "        def quantized_dequantize_inputs(inputs, scale, amax_history):\n",
    "            new_scale = quantizers.compute_float8_scale(\n",
    "                ops.max(amax_history, axis=0),\n",
    "                scale,\n",
    "                ops.cast(\n",
    "                    float(ml_dtypes.finfo(\"float8_e4m3fn\").max), \"float32\"\n",
    "                ),\n",
    "            )\n",
    "            qdq_inputs = quantizers.quantize_and_dequantize(\n",
    "                inputs, scale, \"float8_e4m3fn\", self.compute_dtype\n",
    "            )\n",
    "            new_amax_history = quantizers.compute_float8_amax_history(\n",
    "                inputs, amax_history\n",
    "            )\n",
    "\n",
    "            def grad(*args, upstream=None, variables=None):\n",
    "                if upstream is None:\n",
    "                    (upstream,) = args\n",
    "                return upstream, new_scale, new_amax_history\n",
    "\n",
    "            return qdq_inputs, grad\n",
    "\n",
    "        @ops.custom_gradient\n",
    "        def quantized_dequantize_outputs(outputs, scale, amax_history):\n",
    "            \"\"\"Quantize-dequantize the output gradient but not the output.\"\"\"\n",
    "\n",
    "            def grad(*args, upstream=None, variables=None):\n",
    "                if upstream is None:\n",
    "                    (upstream,) = args\n",
    "                new_scale = quantizers.compute_float8_scale(\n",
    "                    ops.max(amax_history, axis=0),\n",
    "                    scale,\n",
    "                    ops.cast(\n",
    "                        float(ml_dtypes.finfo(\"float8_e5m2\").max), \"float32\"\n",
    "                    ),\n",
    "                )\n",
    "                qdq_upstream = quantizers.quantize_and_dequantize(\n",
    "                    upstream, scale, \"float8_e5m2\", self.compute_dtype\n",
    "                )\n",
    "                new_amax_history = quantizers.compute_float8_amax_history(\n",
    "                    upstream, amax_history\n",
    "                )\n",
    "                return qdq_upstream, new_scale, new_amax_history\n",
    "\n",
    "            return outputs, grad\n",
    "\n",
    "        x = ops.matmul(\n",
    "            quantized_dequantize_inputs(\n",
    "                inputs,\n",
    "                ops.convert_to_tensor(self.inputs_scale),\n",
    "                ops.convert_to_tensor(self.inputs_amax_history),\n",
    "            ),\n",
    "            quantized_dequantize_inputs(\n",
    "                ops.convert_to_tensor(self._kernel),\n",
    "                ops.convert_to_tensor(self.kernel_scale),\n",
    "                ops.convert_to_tensor(self.kernel_amax_history),\n",
    "            ),\n",
    "        )\n",
    "        # `quantized_dequantize_outputs` is placed immediately after\n",
    "        # `ops.matmul` for the sake of pattern matching in gemm_rewrite. That\n",
    "        # way, the qdq will be adjacent to the corresponding matmul_bprop in the\n",
    "        # bprop.\n",
    "        x = quantized_dequantize_outputs(\n",
    "            x,\n",
    "            ops.convert_to_tensor(self.outputs_grad_scale),\n",
    "            ops.convert_to_tensor(self.outputs_grad_amax_history),\n",
    "        )\n",
    "        if self.bias is not None:\n",
    "            # Under non-mixed precision cases, F32 bias has to be converted to\n",
    "            # BF16 first to get the biasAdd fusion support. ref. PR\n",
    "            # https://github.com/tensorflow/tensorflow/pull/60306\n",
    "            bias = self.bias\n",
    "            if self.dtype_policy.compute_dtype == \"float32\":\n",
    "                bias_bf16 = ops.cast(bias, \"bfloat16\")\n",
    "                bias = ops.cast(bias_bf16, bias.dtype)\n",
    "            x = ops.add(x, bias)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def quantize(self, mode):\n",
    "        import gc\n",
    "\n",
    "        # Prevent quantization of the subclasses\n",
    "        if type(self) is not Dense:\n",
    "            raise NotImplementedError(\n",
    "                f\"Layer {self.__class__.__name__} does not have a `quantize()` \"\n",
    "                \"method implemented.\"\n",
    "            )\n",
    "        self._check_quantize_args(mode, self.compute_dtype)\n",
    "\n",
    "        # Set new dtype policy\n",
    "        if not isinstance(\n",
    "            self.dtype_policy, dtype_policies.QuantizedDTypePolicy\n",
    "        ):\n",
    "            quantized_dtype = f\"{mode}_from_{self.dtype_policy.name}\"\n",
    "            # We set the internal `self._dtype_policy` instead of using the\n",
    "            # setter to avoid double `quantize` call\n",
    "            self._dtype_policy = dtype_policies.get(quantized_dtype)\n",
    "\n",
    "        self._tracker.unlock()\n",
    "        if mode == \"int8\":\n",
    "            # Quantize `self._kernel` to int8 and compute corresponding scale\n",
    "            kernel_value, kernel_scale = quantizers.abs_max_quantize(\n",
    "                self._kernel, axis=0\n",
    "            )\n",
    "            kernel_scale = ops.squeeze(kernel_scale, axis=0)\n",
    "            self._untrack_variable(self._kernel)\n",
    "            kernel_shape = self._kernel.shape\n",
    "            del self._kernel\n",
    "            # Utilize a lambda expression as an initializer to prevent adding a\n",
    "            # large constant to the computation graph.\n",
    "            self._int8_build(\n",
    "                kernel_shape,\n",
    "                lambda shape, dtype: kernel_value,\n",
    "                lambda shape, dtype: kernel_scale,\n",
    "            )\n",
    "        elif mode == \"float8\":\n",
    "            self._float8_build()\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                self.QUANTIZATION_MODE_ERROR_TEMPLATE.format(mode)\n",
    "            )\n",
    "        self._tracker.lock()\n",
    "\n",
    "        # Release memory manually because sometimes the backend doesn't\n",
    "        gc.collect()\n",
    "\n",
    "    def _get_kernel_with_merged_lora(self):\n",
    "        if isinstance(self.dtype_policy, dtype_policies.QuantizedDTypePolicy):\n",
    "            kernel_value = self._kernel\n",
    "            kernel_scale = self.kernel_scale\n",
    "            if self.lora_enabled:\n",
    "                # Dequantize & quantize to merge lora weights into int8 kernel\n",
    "                # Note that this is a lossy compression\n",
    "                kernel_value = ops.divide(kernel_value, kernel_scale)\n",
    "                kernel_value = ops.add(\n",
    "                    kernel_value,\n",
    "                    ops.matmul(self.lora_kernel_a, self.lora_kernel_b),\n",
    "                )\n",
    "                kernel_value, kernel_scale = quantizers.abs_max_quantize(\n",
    "                    kernel_value, axis=0\n",
    "                )\n",
    "                kernel_scale = ops.squeeze(kernel_scale, axis=0)\n",
    "            return kernel_value, kernel_scale\n",
    "        return self.kernel, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv1liteQuantized.add(QDense(units=4,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ q_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QDense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m32,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m65,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ q_dense (\u001b[38;5;33mQDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,744</span> (491.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m125,744\u001b[0m (491.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,832</span> (479.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,832\u001b[0m (479.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,912</span> (11.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,912\u001b[0m (11.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobilenetv1liteQuantized.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenetv1liteQuantized.layers[:-1]:\n",
    "   layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ q_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QDense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1_relu (\u001b[38;5;33mReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_1_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m144\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_2_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_3_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_4_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_5_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m576\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_6_relu (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m32,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_12_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ depthwise_conv2d_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_dw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m65,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_pw_13_relu (\u001b[38;5;33mReLU\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ q_dense (\u001b[38;5;33mQDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">125,744</span> (491.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m125,744\u001b[0m (491.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,832</span> (479.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,832\u001b[0m (479.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,912</span> (11.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,912\u001b[0m (11.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobilenetv1liteQuantized.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv1liteQuantized.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"Air Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Enable eager execution\n",
    "tf.config.run_functions_eagerly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitshift2(weight,shift):\n",
    "    if shift<0:\n",
    "       y=tf.math.abs(shift)\n",
    "       return tf.bitwise.right_shift(weight,shift)\n",
    "    else:\n",
    "       return tf.bitwise.left_shift(weight,shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixBitShift(A,B):\n",
    "    A=tf.cast(A,tf.int32)\n",
    "    B=tf.cast(B,tf.int32)\n",
    "    columns2=tf.shape(B)[1]\n",
    "    rows2=tf.shape(B)[0]\n",
    "    rows1=tf.shape(A)[0]\n",
    "    print(rows1)\n",
    "    C=tf.zeros(shape=(rows1,columns2),dtype=tf.int32)\n",
    "    for i in range(0,rows1):\n",
    "      for j in range(0,rows2):\n",
    "            for  k in range(0,columns2):\n",
    "                original=C[i][k]\n",
    "                a=A[i][j]\n",
    "                b=B[j][k]\n",
    "                x=bitshift2(a,b)\n",
    "                #print(x)\n",
    "                update=original+x\n",
    "                \n",
    "                index=tf.constant([[i,k]])\n",
    "                #u=tf.constant([update],dtype=tf.int32)\n",
    "                C=tf.tensor_scatter_nd_update(C,index,[update])\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[14 14 14]\n",
      " [14 14 14]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[1, 1, 2, 3],[1,1,2,3]])\n",
    "tens2=tf.constant([[1,1,1],[1,1,1],[1,1,1],[1,1,1]])\n",
    "C=MatrixBitShift(tensor,tens2)\n",
    "print(C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
